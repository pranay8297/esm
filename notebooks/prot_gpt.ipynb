{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_K1abCY5l_W3",
        "YH9JZxpwoP9l",
        "N66aKBO9mC41",
        "f5IA6CH4eCAa",
        "54SsKIXlIhY_",
        "3qeJdYnbLwSH",
        "UGKQmVuYbkfn",
        "szAQ6WsJbqTv",
        "ycrl_LMbB8kV",
        "Mb0BbRd8myAg"
      ],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP4iAgvznCkCis3lHsiKNcv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c2f1d8a27c5b434597f11181bc312205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e04bb258c25e4f309761fb08b466a86d",
              "IPY_MODEL_4bbcc302a48147638233aa3e0512a8df",
              "IPY_MODEL_57977b5c1bdb48a68b227033162103eb"
            ],
            "layout": "IPY_MODEL_7f9ee1f789df43ce86b7591e0437c109"
          }
        },
        "e04bb258c25e4f309761fb08b466a86d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb4c4bba20074734b0c8017aa65d266e",
            "placeholder": "​",
            "style": "IPY_MODEL_1654defc86e54071b9e6b8504f8f6e67",
            "value": "config.json: 100%"
          }
        },
        "4bbcc302a48147638233aa3e0512a8df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3261ab26220494ca0f33c77b30e67c7",
            "max": 779,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e03420b818884b978f6172f0030ede19",
            "value": 779
          }
        },
        "57977b5c1bdb48a68b227033162103eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86b067a3766c4e58936c26682d19a65c",
            "placeholder": "​",
            "style": "IPY_MODEL_389576f8d5f04260ace6054986addbe5",
            "value": " 779/779 [00:00&lt;00:00, 52.2kB/s]"
          }
        },
        "7f9ee1f789df43ce86b7591e0437c109": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb4c4bba20074734b0c8017aa65d266e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1654defc86e54071b9e6b8504f8f6e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3261ab26220494ca0f33c77b30e67c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e03420b818884b978f6172f0030ede19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86b067a3766c4e58936c26682d19a65c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "389576f8d5f04260ace6054986addbe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c9f8a1299384f05b41c9838451b55d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_870d4ee788f44b68a192bcec9f046af6",
              "IPY_MODEL_9b4cd34cc32d40ac9fdd0e52a586a3ea",
              "IPY_MODEL_bba620350c924188be8df1ce95d8ccf9"
            ],
            "layout": "IPY_MODEL_9a431fe307214433962ae16c1cac98af"
          }
        },
        "870d4ee788f44b68a192bcec9f046af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30a05a6096ef4c3486a0f3597ff275e5",
            "placeholder": "​",
            "style": "IPY_MODEL_276da034e30c4bd8a7127cb64404360d",
            "value": "pytorch_model.bin.index.json: 100%"
          }
        },
        "9b4cd34cc32d40ac9fdd0e52a586a3ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_714c89453630484dac57deef3c7528b2",
            "max": 55493,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2253db2ae5d4492d865b0facd4e7c964",
            "value": 55493
          }
        },
        "bba620350c924188be8df1ce95d8ccf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af21216351d34538aa76d47893d2be8a",
            "placeholder": "​",
            "style": "IPY_MODEL_39acd9ef439f46b28d42d3e6a1414cda",
            "value": " 55.5k/55.5k [00:00&lt;00:00, 3.74MB/s]"
          }
        },
        "9a431fe307214433962ae16c1cac98af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30a05a6096ef4c3486a0f3597ff275e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "276da034e30c4bd8a7127cb64404360d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "714c89453630484dac57deef3c7528b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2253db2ae5d4492d865b0facd4e7c964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af21216351d34538aa76d47893d2be8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39acd9ef439f46b28d42d3e6a1414cda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9414cbc483c547e1bde1d408e69fd3ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4b0fff28c174d1ab16557e9019a5cff",
              "IPY_MODEL_3cbd536b9b0047dd9481e7ca6f410c8a",
              "IPY_MODEL_e8abdede0d224faf83e30549bef3456e"
            ],
            "layout": "IPY_MODEL_4d47d490d7424500ac90fa7f8c3cf636"
          }
        },
        "b4b0fff28c174d1ab16557e9019a5cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0670f1f53765425199fe3344226a4dcc",
            "placeholder": "​",
            "style": "IPY_MODEL_8de043ed186b44c4b8095cd69a890ae9",
            "value": "Downloading shards: 100%"
          }
        },
        "3cbd536b9b0047dd9481e7ca6f410c8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce870d1661f8488b9cabcb810e3d1004",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ece47022a2740d0a406373f0dbcd2fc",
            "value": 2
          }
        },
        "e8abdede0d224faf83e30549bef3456e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_563767e661cd42709974bca2799ea5cb",
            "placeholder": "​",
            "style": "IPY_MODEL_86f94e8b92a3489cba04c71958ae9ea2",
            "value": " 2/2 [01:35&lt;00:00, 41.29s/it]"
          }
        },
        "4d47d490d7424500ac90fa7f8c3cf636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0670f1f53765425199fe3344226a4dcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8de043ed186b44c4b8095cd69a890ae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce870d1661f8488b9cabcb810e3d1004": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ece47022a2740d0a406373f0dbcd2fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "563767e661cd42709974bca2799ea5cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86f94e8b92a3489cba04c71958ae9ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fca58953369476bae4e2bd856f1d2c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26e52e1c5b0c4682ae9b66dd32a8430c",
              "IPY_MODEL_29e78797d5a2479a82ba3587f98bd6c6",
              "IPY_MODEL_59df157413544235bf0db1c9ecc25d63"
            ],
            "layout": "IPY_MODEL_16da9543e1a64641841bf6e9b29803ca"
          }
        },
        "26e52e1c5b0c4682ae9b66dd32a8430c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c1991f644ba4325903135ac2e636f83",
            "placeholder": "​",
            "style": "IPY_MODEL_4e0af0a7ea7a42dda5e13df9b62b92fe",
            "value": "pytorch_model-00001-of-00002.bin: 100%"
          }
        },
        "29e78797d5a2479a82ba3587f98bd6c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f83acc00f3c40c481e4d8430fbf3289",
            "max": 9976735419,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9651319b74e4e6f84e3215304f18599",
            "value": 9976735419
          }
        },
        "59df157413544235bf0db1c9ecc25d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bfc2b089db94b2eaeef3400edbd98a5",
            "placeholder": "​",
            "style": "IPY_MODEL_ad5c09cdf7944553afa9c72ed23248f4",
            "value": " 9.98G/9.98G [01:22&lt;00:00, 113MB/s]"
          }
        },
        "16da9543e1a64641841bf6e9b29803ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c1991f644ba4325903135ac2e636f83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e0af0a7ea7a42dda5e13df9b62b92fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f83acc00f3c40c481e4d8430fbf3289": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9651319b74e4e6f84e3215304f18599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bfc2b089db94b2eaeef3400edbd98a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad5c09cdf7944553afa9c72ed23248f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe34ecf463054cbaa14a474c16a3c91c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_353fc9b5fc844872bbd52fab562f39fd",
              "IPY_MODEL_6053f1b5d93b4954acc76d9b948e384c",
              "IPY_MODEL_2c3e089e969448ce8a423ff56c76edf6"
            ],
            "layout": "IPY_MODEL_7d0423edea1348f19f631bd1f3a6cc35"
          }
        },
        "353fc9b5fc844872bbd52fab562f39fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94b115e95f27477f850d1c59777ee4d3",
            "placeholder": "​",
            "style": "IPY_MODEL_10664e0db73749e2867016b8f5b47420",
            "value": "pytorch_model-00002-of-00002.bin: 100%"
          }
        },
        "6053f1b5d93b4954acc76d9b948e384c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4238315c637a42868fc191edfd20c5c3",
            "max": 1390347055,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49c534e524754d4da14d7e18ef9b5806",
            "value": 1390347055
          }
        },
        "2c3e089e969448ce8a423ff56c76edf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64f6b249d72941c5906709868557948a",
            "placeholder": "​",
            "style": "IPY_MODEL_a4193e70b3c9425c9ac2a95580b1e0da",
            "value": " 1.39G/1.39G [00:11&lt;00:00, 83.7MB/s]"
          }
        },
        "7d0423edea1348f19f631bd1f3a6cc35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94b115e95f27477f850d1c59777ee4d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10664e0db73749e2867016b8f5b47420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4238315c637a42868fc191edfd20c5c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49c534e524754d4da14d7e18ef9b5806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64f6b249d72941c5906709868557948a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4193e70b3c9425c9ac2a95580b1e0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c9118190d3b4935b617bb95a6390952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_721fe60549a6406aaef62a449928b8b8",
              "IPY_MODEL_d8e4f72c11a44db68ae0d145622a51e4",
              "IPY_MODEL_a45f713a329a411591c31cbdf568b6f0"
            ],
            "layout": "IPY_MODEL_d153a8fb15da450abfcde04ba340cca8"
          }
        },
        "721fe60549a6406aaef62a449928b8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b4644a3628a413a9f0c9c0739dd9820",
            "placeholder": "​",
            "style": "IPY_MODEL_5717e97331184b3dad798cd9c849f61e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d8e4f72c11a44db68ae0d145622a51e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48c0461d3f8d419781fcd3a973434a4f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbcede4d86d242ec8c4a27c2cbc13cf4",
            "value": 2
          }
        },
        "a45f713a329a411591c31cbdf568b6f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b053a6058f9459d9dba9f1ec4e72b2e",
            "placeholder": "​",
            "style": "IPY_MODEL_57b4d745cb614f74829e1baced11188d",
            "value": " 2/2 [00:00&lt;00:00,  2.61it/s]"
          }
        },
        "d153a8fb15da450abfcde04ba340cca8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b4644a3628a413a9f0c9c0739dd9820": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5717e97331184b3dad798cd9c849f61e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48c0461d3f8d419781fcd3a973434a4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbcede4d86d242ec8c4a27c2cbc13cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b053a6058f9459d9dba9f1ec4e72b2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57b4d745cb614f74829e1baced11188d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74bde2573c86457eb117f775fb10e714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9907018085442e0a0b0591e1c026b23",
              "IPY_MODEL_d9bf68087d574e969f3d139d41b6f008",
              "IPY_MODEL_23b3ae1fadda4e68926eed7aa5680d19"
            ],
            "layout": "IPY_MODEL_95e827ec796545dc91fd6e7350c758ee"
          }
        },
        "f9907018085442e0a0b0591e1c026b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4632b43b9fe7494fbc970c7510d511eb",
            "placeholder": "​",
            "style": "IPY_MODEL_8e2129c3a13647b6bc6aaa5dce864153",
            "value": "Downloading builder script: 100%"
          }
        },
        "d9bf68087d574e969f3d139d41b6f008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_259cf2779a514a6781d3ad0af8969899",
            "max": 4203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_575d1999d95942908de33e9adf5f21cf",
            "value": 4203
          }
        },
        "23b3ae1fadda4e68926eed7aa5680d19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18be7f45c41e4a56a0a0f8f925904f76",
            "placeholder": "​",
            "style": "IPY_MODEL_c361abf0f2f9467e97c82f2fc46cf22f",
            "value": " 4.20k/4.20k [00:00&lt;00:00, 355kB/s]"
          }
        },
        "95e827ec796545dc91fd6e7350c758ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4632b43b9fe7494fbc970c7510d511eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e2129c3a13647b6bc6aaa5dce864153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "259cf2779a514a6781d3ad0af8969899": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "575d1999d95942908de33e9adf5f21cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18be7f45c41e4a56a0a0f8f925904f76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c361abf0f2f9467e97c82f2fc46cf22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c7eefa772814c0d94b1cdebd8e42c32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fd1cd86c5344932a7d68b7da4e89c4d",
              "IPY_MODEL_cc36752274be4f88b5ea15029a717755",
              "IPY_MODEL_2543169c369647dba087013c3b1f3fa2"
            ],
            "layout": "IPY_MODEL_641726821c2e40c3b5c260f4185223f7"
          }
        },
        "0fd1cd86c5344932a7d68b7da4e89c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8553cc615aa1408bbe8eaeaa5f1ab9d5",
            "placeholder": "​",
            "style": "IPY_MODEL_cbc139ab6f3249a4ba53cd53ba3d7fdf",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "cc36752274be4f88b5ea15029a717755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d3cfe2c696c4a19a0427792b8449112",
            "max": 95,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a60bbf5a7df428e9e30dba35209008f",
            "value": 95
          }
        },
        "2543169c369647dba087013c3b1f3fa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce9487c70b4646c69ea6c5e36a544c0f",
            "placeholder": "​",
            "style": "IPY_MODEL_3964a7c9c762407aba7a8dd41556cc69",
            "value": " 95.0/95.0 [00:00&lt;00:00, 1.17kB/s]"
          }
        },
        "641726821c2e40c3b5c260f4185223f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8553cc615aa1408bbe8eaeaa5f1ab9d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbc139ab6f3249a4ba53cd53ba3d7fdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d3cfe2c696c4a19a0427792b8449112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a60bbf5a7df428e9e30dba35209008f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce9487c70b4646c69ea6c5e36a544c0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3964a7c9c762407aba7a8dd41556cc69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01f986b1b58a407ba8baa75cc1af20b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a537f269af08414dbdf1d0a41cd40658",
              "IPY_MODEL_da24fac9c6c341d6ae3136e96f219707",
              "IPY_MODEL_3e4e436d275d4edba6b792d2e8090bf9"
            ],
            "layout": "IPY_MODEL_92ef0c609b08409fa229cd3beffa6b4d"
          }
        },
        "a537f269af08414dbdf1d0a41cd40658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09897e70d01f46d3aaff5665501d68e7",
            "placeholder": "​",
            "style": "IPY_MODEL_7188dccc3fe64b1c8ed07dbb2b441d92",
            "value": "vocab.txt: 100%"
          }
        },
        "da24fac9c6c341d6ae3136e96f219707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdb8d90707c8487bab2525054c2c4040",
            "max": 93,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4df224e075864ac5bb482ba2d51da077",
            "value": 93
          }
        },
        "3e4e436d275d4edba6b792d2e8090bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ada5dda78cf648f98a9b7720852eb837",
            "placeholder": "​",
            "style": "IPY_MODEL_f2987b1ba2ee479d808483c15bb43988",
            "value": " 93.0/93.0 [00:00&lt;00:00, 650B/s]"
          }
        },
        "92ef0c609b08409fa229cd3beffa6b4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09897e70d01f46d3aaff5665501d68e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7188dccc3fe64b1c8ed07dbb2b441d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdb8d90707c8487bab2525054c2c4040": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4df224e075864ac5bb482ba2d51da077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ada5dda78cf648f98a9b7720852eb837": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2987b1ba2ee479d808483c15bb43988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b772e3ee8c4847ba897faea4fe4b3bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97da354c44cc4ce4b95af09de4be7fac",
              "IPY_MODEL_05aa498de88349ddb8bb7f78ffb7a20b",
              "IPY_MODEL_f169a40c39de414fb3a82e89f3c0fe17"
            ],
            "layout": "IPY_MODEL_ddbd7cf1f73c40d7ab50b93055c8c48e"
          }
        },
        "97da354c44cc4ce4b95af09de4be7fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e355a162c64e47e5851514306f46f725",
            "placeholder": "​",
            "style": "IPY_MODEL_cdfb4696696c476b9b09209f564d39b6",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "05aa498de88349ddb8bb7f78ffb7a20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76afb53068264ac0b2c87252c50a6b6c",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f51966b17224eba9dd9d7ae88be8e14",
            "value": 125
          }
        },
        "f169a40c39de414fb3a82e89f3c0fe17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20c774c177f74603928945e4095edac3",
            "placeholder": "​",
            "style": "IPY_MODEL_b0a1fbb1679d48a8a171b838511fd89f",
            "value": " 125/125 [00:00&lt;00:00, 2.10kB/s]"
          }
        },
        "ddbd7cf1f73c40d7ab50b93055c8c48e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e355a162c64e47e5851514306f46f725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdfb4696696c476b9b09209f564d39b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76afb53068264ac0b2c87252c50a6b6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f51966b17224eba9dd9d7ae88be8e14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20c774c177f74603928945e4095edac3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0a1fbb1679d48a8a171b838511fd89f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0c8cad50200467192b825db2af4a70c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fdd82e782e1a461f89fb73fe8b977e4d",
              "IPY_MODEL_0ea28c92d30d4cecbe2055d7d3142774",
              "IPY_MODEL_86ea1454d74442c3b1540ce5d954c7f7"
            ],
            "layout": "IPY_MODEL_0e535805a1f34aaca1014b574edc8651"
          }
        },
        "fdd82e782e1a461f89fb73fe8b977e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59dcc50aa123411a953b29ecdfb29c9e",
            "placeholder": "​",
            "style": "IPY_MODEL_4b4225e9c5774b2ca120ea28734699e6",
            "value": "config.json: 100%"
          }
        },
        "0ea28c92d30d4cecbe2055d7d3142774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_741156d69d9a4a1e83c3d4c5350702ee",
            "max": 722,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_931a4d8fa1834b928059d57b05405da5",
            "value": 722
          }
        },
        "86ea1454d74442c3b1540ce5d954c7f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53706201159f4749aacfe812e30c5d10",
            "placeholder": "​",
            "style": "IPY_MODEL_1babc086b67f47ea9beff72673784d63",
            "value": " 722/722 [00:00&lt;00:00, 10.2kB/s]"
          }
        },
        "0e535805a1f34aaca1014b574edc8651": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59dcc50aa123411a953b29ecdfb29c9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b4225e9c5774b2ca120ea28734699e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "741156d69d9a4a1e83c3d4c5350702ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "931a4d8fa1834b928059d57b05405da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53706201159f4749aacfe812e30c5d10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1babc086b67f47ea9beff72673784d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e93989b2299437abfc01a7c23aecdb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53e449e71b68464d923f28d3f712bef2",
              "IPY_MODEL_20710483fb9f425cafcca0f6fbfce464",
              "IPY_MODEL_71b884ea9a07453c8d522c9ef19e1725"
            ],
            "layout": "IPY_MODEL_e024fb01fe664dd6b9ee1c2bd551340d"
          }
        },
        "53e449e71b68464d923f28d3f712bef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85917f38624544c78c148abe67ac1e51",
            "placeholder": "​",
            "style": "IPY_MODEL_197d3748f2ff4048862a681101627fba",
            "value": "model.safetensors: 100%"
          }
        },
        "20710483fb9f425cafcca0f6fbfce464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0938753c0ab4bc2b4481f9c6324ca90",
            "max": 1817061136,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e41cfe4f5ae54ec1b94f69e8c4c99f81",
            "value": 1817061136
          }
        },
        "71b884ea9a07453c8d522c9ef19e1725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07db942bac554280b725979a01d08792",
            "placeholder": "​",
            "style": "IPY_MODEL_44f71fb6ba2249d1b976cc14b7c328e1",
            "value": " 1.82G/1.82G [00:27&lt;00:00, 66.0MB/s]"
          }
        },
        "e024fb01fe664dd6b9ee1c2bd551340d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85917f38624544c78c148abe67ac1e51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "197d3748f2ff4048862a681101627fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0938753c0ab4bc2b4481f9c6324ca90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e41cfe4f5ae54ec1b94f69e8c4c99f81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07db942bac554280b725979a01d08792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44f71fb6ba2249d1b976cc14b7c328e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db4576f305764d6593e8a24a59a77a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17c7fef1c7284293973271d6686bde93",
              "IPY_MODEL_3090ba498f6546c0a7a36a3bebdea477",
              "IPY_MODEL_6a6640a52a144813a02e7b77cfdd7adf"
            ],
            "layout": "IPY_MODEL_4141cc67457b4cf8bf22c45134a7c250"
          }
        },
        "17c7fef1c7284293973271d6686bde93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6da8a84681f94033a18d3bd9cdd108bf",
            "placeholder": "​",
            "style": "IPY_MODEL_8043a081ccc6482e8d5123cd5c084620",
            "value": "generation_config.json: 100%"
          }
        },
        "3090ba498f6546c0a7a36a3bebdea477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84a609bad51b47efbe988bda12be86c5",
            "max": 133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d58c657332724ebca7c27a4cb5e9be00",
            "value": 133
          }
        },
        "6a6640a52a144813a02e7b77cfdd7adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_294af594e7184f8b8ba067aa884dfc34",
            "placeholder": "​",
            "style": "IPY_MODEL_fc87a83a7cc242bdb5ed49de351d7532",
            "value": " 133/133 [00:00&lt;00:00, 2.16kB/s]"
          }
        },
        "4141cc67457b4cf8bf22c45134a7c250": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6da8a84681f94033a18d3bd9cdd108bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8043a081ccc6482e8d5123cd5c084620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84a609bad51b47efbe988bda12be86c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d58c657332724ebca7c27a4cb5e9be00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "294af594e7184f8b8ba067aa884dfc34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc87a83a7cc242bdb5ed49de351d7532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5b4b52ea11d4ab6878e92f009f742d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_683a860232484adda21d338b41e222f6",
              "IPY_MODEL_0371e55d87294183a97f2002b973f45f",
              "IPY_MODEL_852ee3354dca47e292fcbab4a747d98a"
            ],
            "layout": "IPY_MODEL_d4d851c4c942455a8e33d1ea610aaf51"
          }
        },
        "683a860232484adda21d338b41e222f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43e742c77e834019bd2ba3b00381e01a",
            "placeholder": "​",
            "style": "IPY_MODEL_d09a557ef67e44d8b7f39760e2c71f4b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0371e55d87294183a97f2002b973f45f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59cea722308f4c3e87c7362d2eae800b",
            "max": 25318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a462bde184cd41229edf04f5599e4218",
            "value": 25318
          }
        },
        "852ee3354dca47e292fcbab4a747d98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d235c7cd299747c7a5550ca8e3c1b5a8",
            "placeholder": "​",
            "style": "IPY_MODEL_c6b7fc99f08a49e1a81454dd8f1aaf0a",
            "value": " 25.3k/25.3k [00:00&lt;00:00, 1.88MB/s]"
          }
        },
        "d4d851c4c942455a8e33d1ea610aaf51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43e742c77e834019bd2ba3b00381e01a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d09a557ef67e44d8b7f39760e2c71f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59cea722308f4c3e87c7362d2eae800b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a462bde184cd41229edf04f5599e4218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d235c7cd299747c7a5550ca8e3c1b5a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6b7fc99f08a49e1a81454dd8f1aaf0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36698dfc3899413ea749ace946fb9643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31ebaeecbb7847a49ef763aea90e3e11",
              "IPY_MODEL_b38d50691d2e421db9004019f499b1da",
              "IPY_MODEL_b5a77800ad3a443ba79630d6d31781ce"
            ],
            "layout": "IPY_MODEL_ade5f9888a2540ccaf6b347c887070cc"
          }
        },
        "31ebaeecbb7847a49ef763aea90e3e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f49cd6458bbc43138fdc2c7451b7e4bd",
            "placeholder": "​",
            "style": "IPY_MODEL_dd1163f8644d46dd9c22ae5415fd5b17",
            "value": "added_tokens.json: 100%"
          }
        },
        "b38d50691d2e421db9004019f499b1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3d2ac7c9abe40cbae77ce6f3e493f27",
            "max": 3018,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d89c90663154bc19b475c3708d4d347",
            "value": 3018
          }
        },
        "b5a77800ad3a443ba79630d6d31781ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a60e5ea110e8446491f591c57d3d6a57",
            "placeholder": "​",
            "style": "IPY_MODEL_6bb3e051d9cf47fcb7864df19c27efc3",
            "value": " 3.02k/3.02k [00:00&lt;00:00, 252kB/s]"
          }
        },
        "ade5f9888a2540ccaf6b347c887070cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f49cd6458bbc43138fdc2c7451b7e4bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd1163f8644d46dd9c22ae5415fd5b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3d2ac7c9abe40cbae77ce6f3e493f27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d89c90663154bc19b475c3708d4d347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a60e5ea110e8446491f591c57d3d6a57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bb3e051d9cf47fcb7864df19c27efc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7d636f73665415a8ccc94aadc7b5c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7dddfd93147a491096cff7bcdd0a3c10",
              "IPY_MODEL_faed09bfeab746fe9ec03baa3d0ecf27",
              "IPY_MODEL_b18f855c23f549898bd5877a55f2b1ef"
            ],
            "layout": "IPY_MODEL_ff4ddab9b02f490f82870b989977154d"
          }
        },
        "7dddfd93147a491096cff7bcdd0a3c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a8f1412e7bf4ba7bfe3141abf5dc6af",
            "placeholder": "​",
            "style": "IPY_MODEL_9382867b69ee4da18825600d2772d7e8",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "faed09bfeab746fe9ec03baa3d0ecf27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf4e197d38cf4bd2b77b7db06481a39b",
            "max": 2976,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_856d68beaea947e6b972834205b924e9",
            "value": 2976
          }
        },
        "b18f855c23f549898bd5877a55f2b1ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40b4127c6e254413a2370d54aa25b698",
            "placeholder": "​",
            "style": "IPY_MODEL_1eebc106152241a986ecfa060e7e3abc",
            "value": " 2.98k/2.98k [00:00&lt;00:00, 239kB/s]"
          }
        },
        "ff4ddab9b02f490f82870b989977154d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a8f1412e7bf4ba7bfe3141abf5dc6af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9382867b69ee4da18825600d2772d7e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf4e197d38cf4bd2b77b7db06481a39b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "856d68beaea947e6b972834205b924e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40b4127c6e254413a2370d54aa25b698": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1eebc106152241a986ecfa060e7e3abc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranay8297/esm/blob/main/notebooks/prot_gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v3DJoN2tTk42",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "002e5701-f785-4110-c877-db6547e4cae5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting datasets\n",
            "  Using cached datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.15.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.0.1 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting evaluate\n",
            "  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.15.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers evaluate datasets requests pandas sklearn\n",
        "! pip install datasets\n",
        "! pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "\n",
        "# notebook_login()"
      ],
      "metadata": {
        "id": "vyD1rc52Elyn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('token')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHY6iZfYO0YE",
        "outputId": "34d573ee-c7fc-4933-bf32-3855ac2675d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Playground - 1"
      ],
      "metadata": {
        "id": "_K1abCY5l_W3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install git-lfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOQCHxohTrga",
        "outputId": "fd276dfd-f2c1-490e-ecd6-ba4717c6a938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"facebook/esm2_t30_150M_UR50D\""
      ],
      "metadata": {
        "id": "UGwIQBxNUhJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "model_checkpoint = \"facebook/esm2_t36_3B_UR50D\"\n",
        "train_labels = 100; test_labels = 20\n",
        "num_labels = 120  # Add 1 since 0 can be a label\n",
        "hf_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372,
          "referenced_widgets": [
            "c2f1d8a27c5b434597f11181bc312205",
            "e04bb258c25e4f309761fb08b466a86d",
            "4bbcc302a48147638233aa3e0512a8df",
            "57977b5c1bdb48a68b227033162103eb",
            "7f9ee1f789df43ce86b7591e0437c109",
            "eb4c4bba20074734b0c8017aa65d266e",
            "1654defc86e54071b9e6b8504f8f6e67",
            "c3261ab26220494ca0f33c77b30e67c7",
            "e03420b818884b978f6172f0030ede19",
            "86b067a3766c4e58936c26682d19a65c",
            "389576f8d5f04260ace6054986addbe5",
            "0c9f8a1299384f05b41c9838451b55d4",
            "870d4ee788f44b68a192bcec9f046af6",
            "9b4cd34cc32d40ac9fdd0e52a586a3ea",
            "bba620350c924188be8df1ce95d8ccf9",
            "9a431fe307214433962ae16c1cac98af",
            "30a05a6096ef4c3486a0f3597ff275e5",
            "276da034e30c4bd8a7127cb64404360d",
            "714c89453630484dac57deef3c7528b2",
            "2253db2ae5d4492d865b0facd4e7c964",
            "af21216351d34538aa76d47893d2be8a",
            "39acd9ef439f46b28d42d3e6a1414cda",
            "9414cbc483c547e1bde1d408e69fd3ca",
            "b4b0fff28c174d1ab16557e9019a5cff",
            "3cbd536b9b0047dd9481e7ca6f410c8a",
            "e8abdede0d224faf83e30549bef3456e",
            "4d47d490d7424500ac90fa7f8c3cf636",
            "0670f1f53765425199fe3344226a4dcc",
            "8de043ed186b44c4b8095cd69a890ae9",
            "ce870d1661f8488b9cabcb810e3d1004",
            "1ece47022a2740d0a406373f0dbcd2fc",
            "563767e661cd42709974bca2799ea5cb",
            "86f94e8b92a3489cba04c71958ae9ea2",
            "7fca58953369476bae4e2bd856f1d2c2",
            "26e52e1c5b0c4682ae9b66dd32a8430c",
            "29e78797d5a2479a82ba3587f98bd6c6",
            "59df157413544235bf0db1c9ecc25d63",
            "16da9543e1a64641841bf6e9b29803ca",
            "8c1991f644ba4325903135ac2e636f83",
            "4e0af0a7ea7a42dda5e13df9b62b92fe",
            "9f83acc00f3c40c481e4d8430fbf3289",
            "a9651319b74e4e6f84e3215304f18599",
            "6bfc2b089db94b2eaeef3400edbd98a5",
            "ad5c09cdf7944553afa9c72ed23248f4",
            "fe34ecf463054cbaa14a474c16a3c91c",
            "353fc9b5fc844872bbd52fab562f39fd",
            "6053f1b5d93b4954acc76d9b948e384c",
            "2c3e089e969448ce8a423ff56c76edf6",
            "7d0423edea1348f19f631bd1f3a6cc35",
            "94b115e95f27477f850d1c59777ee4d3",
            "10664e0db73749e2867016b8f5b47420",
            "4238315c637a42868fc191edfd20c5c3",
            "49c534e524754d4da14d7e18ef9b5806",
            "64f6b249d72941c5906709868557948a",
            "a4193e70b3c9425c9ac2a95580b1e0da",
            "3c9118190d3b4935b617bb95a6390952",
            "721fe60549a6406aaef62a449928b8b8",
            "d8e4f72c11a44db68ae0d145622a51e4",
            "a45f713a329a411591c31cbdf568b6f0",
            "d153a8fb15da450abfcde04ba340cca8",
            "1b4644a3628a413a9f0c9c0739dd9820",
            "5717e97331184b3dad798cd9c849f61e",
            "48c0461d3f8d419781fcd3a973434a4f",
            "dbcede4d86d242ec8c4a27c2cbc13cf4",
            "9b053a6058f9459d9dba9f1ec4e72b2e",
            "57b4d745cb614f74829e1baced11188d"
          ]
        },
        "id": "pcEKc5BeUqAD",
        "outputId": "07b7dfca-6542-4e4c-c73a-6afa8400a710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/779 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2f1d8a27c5b434597f11181bc312205"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin.index.json:   0%|          | 0.00/55.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c9f8a1299384f05b41c9838451b55d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9414cbc483c547e1bde1d408e69fd3ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fca58953369476bae4e2bd856f1d2c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/1.39G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe34ecf463054cbaa14a474c16a3c91c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c9118190d3b4935b617bb95a6390952"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hf_model.esm.encoder.layer[0].attention.self.attention_head_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXP4pBIs6vrw",
        "outputId": "94d3a7de-95f8-41b4-83f1-16b9ec64b138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ESM.load_pretrained(model_type = 'esm2_t30_150M_UR50D')"
      ],
      "metadata": {
        "id": "aLyH6dMTvdMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = ESM.get_pretrained_config(\"esm2_t30_150M_UR50D\")\n",
        "model = ESM(config)"
      ],
      "metadata": {
        "id": "TO-Z6kH9yzXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    model.esm.final_layer.bias.zero_()\n",
        "model.esm.final_layer.bias.requires_grad = False"
      ],
      "metadata": {
        "id": "TSXVt4NKAjXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Shit"
      ],
      "metadata": {
        "id": "YH9JZxpwoP9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data\n",
        "import requests\n",
        "\n",
        "query_url =\"https://rest.uniprot.org/uniprotkb/stream?compressed=true&fields=accession%2Csequence%2Ccc_subcellular_location&format=tsv&query=%28%28organism_id%3A9606%29%20AND%20%28reviewed%3Atrue%29%20AND%20%28length%3A%5B80%20TO%20500%5D%29%29\"\n",
        "uniprot_request = requests.get(query_url)\n",
        "\n",
        "from io import BytesIO\n",
        "import pandas\n",
        "\n",
        "bio = BytesIO(uniprot_request.content)\n",
        "\n",
        "df = pandas.read_csv(bio, compression='gzip', sep='\\t')\n",
        "df.head()\n",
        "\n",
        "df = df.dropna()\n",
        "cytosolic = df['Subcellular location [CC]'].str.contains(\"Cytosol\") | df['Subcellular location [CC]'].str.contains(\"Cytoplasm\")\n",
        "membrane = df['Subcellular location [CC]'].str.contains(\"Membrane\") | df['Subcellular location [CC]'].str.contains(\"Cell membrane\")\n",
        "cytosolic_df = df[cytosolic & ~membrane]\n",
        "cytosolic_df.head()\n",
        "\n",
        "membrane_df = df[membrane & ~cytosolic]\n",
        "membrane_df.head()\n",
        "\n",
        "cytosolic_sequences = cytosolic_df[\"Sequence\"].tolist()\n",
        "cytosolic_labels = [0 for protein in cytosolic_sequences]\n",
        "membrane_sequences = membrane_df[\"Sequence\"].tolist()\n",
        "membrane_labels = [1 for protein in membrane_sequences]\n",
        "sequences = cytosolic_sequences + membrane_sequences\n",
        "labels = cytosolic_labels + membrane_labels\n",
        "\n",
        "# Quick check to make sure we got it right\n",
        "assert len(sequences) == len(labels)"
      ],
      "metadata": {
        "id": "Mytsmh9dmrjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = 'facebook/esm2_t30_150M_UR50D'\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sequences, test_sequences, train_labels, test_labels = train_test_split(sequences, labels, test_size=0.25, shuffle=True)\n",
        "from transformers import AutoTokenizer\n",
        "esm_tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, padding = 'max_length', max_length = 1026)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6FhU60enwco",
        "outputId": "97259d07-c30f-4d61-b427-32bbeb2810c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences = train_sequences[:10]"
      ],
      "metadata": {
        "id": "KTCk8I-O4NEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer(train_sequences[0])\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "train_tokenized = esm_tokenizer(train_sequences)\n",
        "test_tokenized = esm_tokenizer(test_sequences)\n",
        "\n",
        "padded_train_tokenized = esm_tokenizer.pad(train_tokenized, padding = 'max_length', max_length = 1026)\n",
        "padded_test_tokenized = esm_tokenizer.pad(test_tokenized, padding = 'max_length', max_length = 1026)\n",
        "\n",
        "padded_train_dataset = Dataset.from_dict(padded_train_tokenized)\n",
        "padded_train_dataset = padded_train_dataset.add_column(\"labels\", train_labels[:10])\n",
        "\n",
        "padded_test_dataset = Dataset.from_dict(padded_test_tokenized)\n",
        "padded_test_dataset = padded_test_dataset.add_column(\"labels\", test_labels)\n",
        "print(len(padded_train_dataset[0]['input_ids']), len(padded_train_dataset[1]['input_ids']), len(padded_test_dataset[0]['input_ids']), len(padded_test_dataset[1]['input_ids']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0W8V1PGU-mH",
        "outputId": "c0276bc8-94fe-4a2d-c533-52c403814ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1026 1026 1026 1026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "num_labels = max(train_labels + test_labels) + 1  # Add 1 since 0 can be a label\n",
        "hf_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "batch_size = 8\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"{model_name}-finetuned-localization\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    push_to_hub=True,\n",
        ")\n",
        "\n",
        "from evaluate import load\n",
        "import numpy as np\n",
        "\n",
        "metric = load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "class MyTrainer(Trainer):\n",
        "\n",
        "    def get_train_dataloader(self, batch_size = 2):\n",
        "        if self.train_dataset is None:\n",
        "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
        "        train_sampler = self._get_train_sampler()\n",
        "\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            sampler=train_sampler,\n",
        "            collate_fn=self.data_collator,\n",
        "            drop_last=self.args.dataloader_drop_last,\n",
        "        )\n",
        "\n",
        "trainer = MyTrainer(\n",
        "    hf_model,\n",
        "    args,\n",
        "    train_dataset = padded_train_dataset,\n",
        "    eval_dataset = padded_test_dataset,\n",
        "    tokenizer = esm_tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "train_dl = trainer.get_train_dataloader(2)\n",
        "batch = next(iter(train_dl))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "74bde2573c86457eb117f775fb10e714",
            "f9907018085442e0a0b0591e1c026b23",
            "d9bf68087d574e969f3d139d41b6f008",
            "23b3ae1fadda4e68926eed7aa5680d19",
            "95e827ec796545dc91fd6e7350c758ee",
            "4632b43b9fe7494fbc970c7510d511eb",
            "8e2129c3a13647b6bc6aaa5dce864153",
            "259cf2779a514a6781d3ad0af8969899",
            "575d1999d95942908de33e9adf5f21cf",
            "18be7f45c41e4a56a0a0f8f925904f76",
            "c361abf0f2f9467e97c82f2fc46cf22f"
          ]
        },
        "id": "ecPZBwkiqocr",
        "outputId": "8cdf2e4a-377d-4578-ae86-44ff25e8b7e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t30_150M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74bde2573c86457eb117f775fb10e714"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Playground - 2"
      ],
      "metadata": {
        "id": "N66aKBO9mC41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from dataclasses import dataclass\n",
        "from einops import rearrange, repeat\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "PFGPT_VOCAB_SIZE = 384\n",
        "PFGPT_HF_MODEL_PATH = 'lamm-mit/ProteinForceGPT'\n",
        "\n",
        "@dataclass\n",
        "class LoRAConfig:\n",
        "    lora_r: int = 8\n",
        "    lora_alpha: int = 16\n",
        "    lora_dropout: int = 0.05\n",
        "    lora_query: bool = True\n",
        "    lora_key: bool = False\n",
        "    lora_value: bool = True\n",
        "    lora_projection: bool = False\n",
        "    lora_mlp: bool = False\n",
        "    lora_head: bool = False\n",
        "\n",
        "class LoRALinear(nn.Linear):\n",
        "    def __init__(self, nin, nout, lora_config):\n",
        "        super().__init__(nin, nout)\n",
        "        std_dev = 1 / torch.sqrt(torch.tensor(lora_config.lora_r).float())\n",
        "        self.lora_A = torch.nn.Parameter(torch.randn(nin, lora_config.lora_r) * std_dev)\n",
        "        self.lora_B = torch.nn.Parameter(torch.zeros(lora_config.lora_r, nout))\n",
        "        self.alpha = lora_config.lora_alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        lora_x = self.alpha * (x @ self.lora_A @ self.lora_B)\n",
        "        x = super().forward(x)\n",
        "        return x + lora_x\n",
        "\n",
        "def get_tokenizer():\n",
        "    tokenizer = AutoTokenizer.from_pretrained(PFGPT_HF_MODEL_PATH, trust_remote_code=True)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    return tokenizer\n",
        "\n",
        "def rotate_half(x):\n",
        "    x1, x2 = x.chunk(2, dim=-1)\n",
        "    return torch.cat((-x2, x1), dim=-1)\n",
        "\n",
        "def apply_rotary_pos_emb(x, cos, sin):\n",
        "    cos = cos[:, :, : x.shape[-2], :]\n",
        "    sin = sin[:, :, : x.shape[-2], :]\n",
        "    return (x * cos) + (rotate_half(x) * sin)\n",
        "\n",
        "class RotaryEmbedding(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Rotary position embeddings based on those in\n",
        "    [RoFormer](https://huggingface.co/docs/transformers/model_doc/roformer). Query and keys are transformed by rotation\n",
        "    matrices which depend on their relative positions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim: int):\n",
        "        super().__init__()\n",
        "        # Generate and save the inverse frequency buffer (non trainable)\n",
        "        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2, dtype=torch.int64).float() / dim))\n",
        "        inv_freq = inv_freq\n",
        "        self.register_buffer(\"inv_freq\", inv_freq)\n",
        "\n",
        "        self._seq_len_cached = None\n",
        "        self._cos_cached = None\n",
        "        self._sin_cached = None\n",
        "\n",
        "    def _update_cos_sin_tables(self, x, seq_dimension=2):\n",
        "        seq_len = x.shape[seq_dimension]\n",
        "\n",
        "        # Reset the tables if the sequence length has changed,\n",
        "        # or if we're on a new device (possibly due to tracing for instance)\n",
        "        if seq_len != self._seq_len_cached or self._cos_cached.device != x.device:\n",
        "            self._seq_len_cached = seq_len\n",
        "            t = torch.arange(x.shape[seq_dimension], device=x.device).type_as(self.inv_freq)\n",
        "            freqs = torch.outer(t, self.inv_freq)\n",
        "            emb = torch.cat((freqs, freqs), dim=-1).to(x.device)\n",
        "\n",
        "            self._cos_cached = emb.cos()[None, None, :, :]\n",
        "            self._sin_cached = emb.sin()[None, None, :, :]\n",
        "\n",
        "        return self._cos_cached, self._sin_cached\n",
        "\n",
        "    def forward(self, q: torch.Tensor, k: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        self._cos_cached, self._sin_cached = self._update_cos_sin_tables(k, seq_dimension=-2)\n",
        "\n",
        "        return (\n",
        "            apply_rotary_pos_emb(q, self._cos_cached, self._sin_cached),\n",
        "            apply_rotary_pos_emb(k, self._cos_cached, self._sin_cached)\n",
        "        )\n",
        "\n",
        "class ESMEmbeddings(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.word_embeddings = nn.Embedding(config.vocab_size, config.n_embd)\n",
        "        self.position_embeddings = nn.Embedding(config.block_size, config.n_embd)\n",
        "\n",
        "    def post_model_init(self):\n",
        "        # Merge both the tokenizer vocabs - Battle of Tokenizers\n",
        "        # That is create a new word embedding of pf_gpts vocab size and configs n_embd\n",
        "        # Get pf GPT Tokenizer\n",
        "        pfgpt_tokenizer = AutoTokenizer.from_pretrained(PFGPT_HF_MODEL_PATH, trust_remote_code=True)\n",
        "        pfgpt_tokenizer.pad_token = pfgpt_tokenizer.eos_token\n",
        "        pfgpt_vocab = pfgpt_tokenizer.get_vocab()\n",
        "\n",
        "        # Get ESM Tokenizer\n",
        "        esm_tokenizer = AutoTokenizer.from_pretrained(self.config.pre_trained_model_name, padding='max_length', max_length=1026)\n",
        "        esm_vocab = esm_tokenizer.get_vocab()\n",
        "        new_word_embeddings = nn.Embedding(PFGPT_VOCAB_SIZE, self.config.n_embd)\n",
        "        torch.nn.init.normal_(new_word_embeddings.weight, std = 0.1263)\n",
        "\n",
        "        # Find all the common keys tokens between esm tokenizer and pf_gpt tokenizer\n",
        "        pfgpt_keys = set(pfgpt_vocab.keys())\n",
        "        esm_keys = set(esm_vocab.keys())\n",
        "        common_keys = list(pfgpt_keys.intersection(esm_keys))\n",
        "\n",
        "        # now, copy a particular tokens embedding from ems_embedding to the new embedding that we create here\n",
        "        with torch.no_grad():\n",
        "            indices = []\n",
        "            for key in common_keys:\n",
        "                esm_embd_index = esm_tokenizer.convert_tokens_to_ids(key)\n",
        "                pfg_embd_index = pfgpt_tokenizer.convert_tokens_to_ids(key)\n",
        "                indices.append(pfg_embd_index)\n",
        "                new_word_embeddings.weight[pfg_embd_index] = self.word_embeddings.weight[esm_embd_index]\n",
        "\n",
        "            # Check for embedding equivalance\n",
        "            assert torch.equal(new_word_embeddings.weight[pfgpt_tokenizer.convert_tokens_to_ids(common_keys)],\n",
        "                               self.word_embeddings.weight[esm_tokenizer.convert_tokens_to_ids(common_keys)])\n",
        "\n",
        "        # Create a mask for all the indecis we have copied pretrained embeddings\n",
        "        # and turn requires_grad off to those embeddings that we have copied - This is\n",
        "        # not possible, so instead we store the indecis and zero out the grads before optim.step()\n",
        "        # hence we do not update these embeddings\n",
        "        self.indices = indices\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.word_embeddings = new_word_embeddings\n",
        "        self.word_embeddings.requires_grad_(True)\n",
        "        self.position_embeddings.requires_grad_(True)\n",
        "\n",
        "    def forward(self, x, attention_mask = None):\n",
        "        token_embs = self.word_embeddings(x)\n",
        "        position_embs = self.position_embeddings\n",
        "        pos = torch.arange(0, x.shape[1], dtype = torch.long, device = x.device) # shape (T)\n",
        "        pos_emb = self.position_embeddings(pos)\n",
        "        token_embs = token_embs + pos_emb\n",
        "        # Not required as we are use rotary embeddings - Hence we do not require absolute position embeddings\n",
        "        # position_embs = self.esm.embeddings.position_embeddings(torch.arange(0, x.shape[1], 1, dtype = torch.long))\n",
        "        if attention_mask is not None:\n",
        "            token_embs = (token_embs * attention_mask.unsqueeze(-1)).to(token_embs.dtype)\n",
        "        return token_embs\n",
        "\n",
        "@dataclass\n",
        "class ESMConfig():\n",
        "    block_size: int = 1024\n",
        "    vocab_size: int = 50257\n",
        "    n_layer: int = 12\n",
        "    n_head: int = 12\n",
        "    n_embd: int = 768\n",
        "    hidden_size: int = 4096 # 4 * block_size\n",
        "    dropout: float = 0.0\n",
        "    pre_trained_model_name: str = ''\n",
        "    use_final_proj = False\n",
        "\n",
        "class ESMIntermediateLayer(nn.Module):\n",
        "    def __init__(self, nin, nout, lora_config, dropout = 0.0, ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dense = nn.Linear(nin, nout) if not lora_config.lora_mlp else LoRALinear(nin, nout, lora_config)\n",
        "        self.act = nn.GELU(approximate = 'tanh')\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.act(self.dense(x))\n",
        "\n",
        "class Lin(nn.Module):\n",
        "    def __init__(self, nin, nout):\n",
        "        super().__init__()\n",
        "        self.ln = nn.LayerNorm(nin)\n",
        "        self.act = nn.GELU(approximate='tanh')\n",
        "        self.lin = nn.Linear(nin,nout)\n",
        "    def forward(self, x):\n",
        "        return self.lin(self.act(self.ln(x)))\n",
        "\n",
        "class ESMOutLayer(nn.Module):\n",
        "    def __init__(self, nin, nout, lora_config, dropout = 0.0, inside_attention = False):\n",
        "        super().__init__()\n",
        "\n",
        "        # 2 places used - 1. inisde the attention block  and inside the MLP\n",
        "        # if used inside attention and lora_config.lora_projection is true then dense is a LoRALInear\n",
        "        # elif used in mlp and lora_config.lora_mlp is true then dens is a LoRALinear again\n",
        "        # else its a Linear\n",
        "\n",
        "        if inside_attention == True and lora_config.lora_projection:\n",
        "            self.dense = LoRALinear(nin, nout, lora_config)\n",
        "        elif inside_attention == False and lora_config.lora_mlp:\n",
        "            self.dense = LoRALinear(nin, nout, lora_config)\n",
        "        else:\n",
        "            self.dense = nn.Linear(nin, nout)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, attn_scores):\n",
        "        x = self.dense(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x + attn_scores\n",
        "        return x\n",
        "\n",
        "class ESMSelfAttn(nn.Module): # Verified\n",
        "\n",
        "    def __init__(self, config, lora_config):\n",
        "        super().__init__()\n",
        "\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "\n",
        "        self.query = nn.Linear(config.n_embd, config.n_embd) if not lora_config.lora_query else LoRALinear(config.n_embd, config.n_embd, lora_config)\n",
        "        self.key = nn.Linear(config.n_embd, config.n_embd) if not lora_config.lora_key else LoRALinear(config.n_embd, config.n_embd, lora_config)\n",
        "        self.value = nn.Linear(config.n_embd, config.n_embd) if not lora_config.lora_value else LoRALinear(config.n_embd, config.n_embd, lora_config)\n",
        "        self.n_head = config.n_head\n",
        "\n",
        "        attention_head_size = config.n_embd//config.n_head\n",
        "\n",
        "        # Add a rotary embeddings here\n",
        "        self.rotary_embeddings = RotaryEmbedding(dim = attention_head_size)\n",
        "\n",
        "    def forward(self, x, attention_mask):\n",
        "\n",
        "        # x -> (b, s, e) -> (b s, h, e/h)\n",
        "        k, q, v = self.key(x), self.query(x), self.value(x)\n",
        "\n",
        "        k = rearrange(k, 'b s (h e) -> b h s e', h = self.n_head)\n",
        "        q = rearrange(q, 'b s (h e) -> b h s e', h = self.n_head)\n",
        "        v = rearrange(v, 'b s (h e) -> b h s e', h = self.n_head)\n",
        "\n",
        "        # Add rotary embeddings here for k and q tensors\n",
        "        q, k = self.rotary_embeddings(q, k)\n",
        "\n",
        "        # Attention claculation - # TODO: make is_casual true in case of finetuning - Very important\n",
        "        y = F.scaled_dot_product_attention(q, k, v, attn_mask = attention_mask, is_causal = True) # flash attention\n",
        "        y = rearrange(y, 'b h s e -> b s (h e)', h = self.n_head)\n",
        "        return y\n",
        "\n",
        "class ESMAttn(nn.Module): # Verified\n",
        "\n",
        "    def __init__(self, config, lora_config):\n",
        "        super().__init__() # No activation function at this level\n",
        "        self.self = ESMSelfAttn(config, lora_config)\n",
        "        self.output = ESMOutLayer(config.n_embd, config.n_embd, lora_config, dropout = getattr(config, 'dropout', 0.), inside_attention = True)\n",
        "        self.LayerNorm = nn.LayerNorm(config.n_embd)\n",
        "\n",
        "    def forward(self, x, attention_mask):\n",
        "        inter_x = self.LayerNorm(x)\n",
        "        attn = self.self(inter_x, attention_mask)\n",
        "        out = self.output(attn, x)\n",
        "        return out\n",
        "\n",
        "class ESMLayers(nn.Module): # Both Init and Forward Verified - Done and Dusted\n",
        "\n",
        "    def __init__(self, config, lora_config):\n",
        "        super().__init__()\n",
        "        self.attention = ESMAttn(config, lora_config)\n",
        "        self.intermediate = ESMIntermediateLayer(config.n_embd, config.hidden_size, lora_config) #\n",
        "        self.output = ESMOutLayer(config.hidden_size, config.n_embd, lora_config) #\n",
        "        self.LayerNorm = nn.LayerNorm(config.n_embd)\n",
        "\n",
        "    def forward(self, x, attention_mask):\n",
        "        attention_op = self.attention(x, attention_mask)\n",
        "        attention_op_ln = self.LayerNorm(attention_op) # This will keep the activations in check - Lets see\n",
        "        inter = self.intermediate(attention_op_ln)\n",
        "        out = self.output(inter, attention_op)\n",
        "        return out\n",
        "\n",
        "class ESMEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self, config, lora_config):\n",
        "        super().__init__()\n",
        "\n",
        "        # No activation functions here as well\n",
        "\n",
        "        self.layer = nn.ModuleList([ESMLayers(config, lora_config) for _ in range(config.n_layer)])\n",
        "        self.emb_layer_norm_after = nn.LayerNorm(config.n_embd)\n",
        "\n",
        "    def forward(self, x, attention_mask = None):\n",
        "\n",
        "        for layer in self.layer:\n",
        "            x = layer(x, attention_mask)\n",
        "\n",
        "        return self.emb_layer_norm_after(x)\n",
        "\n",
        "class ESM(nn.Module):\n",
        "\n",
        "    def __init__(self, config, lora_config):\n",
        "\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.esm = nn.ModuleDict(dict(\n",
        "            embeddings = ESMEmbeddings(config),\n",
        "            encoder = ESMEncoder(config, lora_config), # Done, forward - here\n",
        "            final_layer = nn.Linear(config.n_embd, config.vocab_size) if not lora_config.lora_head else\n",
        "                              LoRALinear(config.n_embd, config.vocab_size, lora_config)\n",
        "        ))\n",
        "\n",
        "        self.esm.final_layer.weight = self.esm.embeddings.word_embeddings.weight\n",
        "        if config.use_final_proj:\n",
        "            self.esm.final_proj = nn.Sequential(Lin(config.n_embd, config.n_embd*4), Lin(config.n_embd*4, config.n_embd))\n",
        "            # for layer in self.esm.final_proj:\n",
        "            #     torch.nn.init.zeros_(layer.lin.weight)\n",
        "            #     torch.nn.init.zeros_(layer.lin.bias)\n",
        "\n",
        "        # Final Layer bias initializtion\n",
        "        torch.nn.init.zeros_(self.esm.final_layer.bias) # Set the bias to 0\n",
        "        # Finally one small thing is to decide weather to add an intermediate layer or not? - Thats a future discussion\n",
        "\n",
        "    @classmethod\n",
        "    def get_pretrained_config(cls, model_type = 'esm2_t33_650M_UR50D'):\n",
        "\n",
        "        '''\n",
        "        name                n_layers    n_params\n",
        "        esm2_t48_15B_UR50D\t48\t        15B\n",
        "        esm2_t36_3B_UR50D\t36\t        3B\n",
        "        esm2_t33_650M_UR50D\t33\t        650M\n",
        "        esm2_t30_150M_UR50D\t30\t        150M\n",
        "        esm2_t12_35M_UR50D\t12\t        35M\n",
        "        esm2_t6_8M_UR50D\n",
        "        '''\n",
        "\n",
        "        assert model_type in {'esm2_t36_3B_UR50D', 'esm2_t33_650M_UR50D', 'esm2_t30_150M_UR50D'}\n",
        "\n",
        "        config_args = {\n",
        "            'esm2_t36_3B_UR50D': dict(n_layer=36, n_head = 40, n_embd=2560, hidden_size=10240), # 3B params\n",
        "            'esm2_t33_650M_UR50D': dict(n_layer=33, n_head = 20, n_embd=1280, hidden_size=5120), # 650M params\n",
        "            'esm2_t30_150M_UR50D': dict(n_layer=30, n_head = 20, n_embd=640, hidden_size=2560), # 150M params\n",
        "        }[model_type]\n",
        "\n",
        "        config_args['vocab_size'] = 33 # always 33 for ESM Models\n",
        "        config_args['block_size'] = 1026 # Always constant for ESM Models\n",
        "        config_args['pre_trained_model_name'] = f\"facebook/{model_type}\"\n",
        "\n",
        "        config = ESMConfig(**config_args)\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, lora_config, model_type = 'esm2_t33_650M_UR50D', embedding_post_init = True, use_final_proj = False):\n",
        "\n",
        "        config = cls.get_pretrained_config(model_type)\n",
        "\n",
        "        if use_final_proj: config.use_final_proj = True\n",
        "\n",
        "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
        "\n",
        "        # create a from-scratch initialized minGPT model\n",
        "        model = cls(config, lora_config)\n",
        "        sd = model.state_dict()\n",
        "        sd_keys = sd.keys()\n",
        "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
        "\n",
        "        # init a huggingface/transformers model\n",
        "        from transformers import AutoModelForSequenceClassification\n",
        "        num_labels = 33\n",
        "        model_hf = AutoModelForSequenceClassification.from_pretrained(config.pre_trained_model_name, num_labels = num_labels)\n",
        "        sd_hf = model_hf.state_dict()\n",
        "\n",
        "        # copy while ensuring all of the parameters are aligned and match in names and shapes\n",
        "        sd_keys_hf = sd_hf.keys()\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if 'inv_freq' not in k]\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if 'classifier' not in k]\n",
        "\n",
        "        ignore_keys = ['esm.contact_head.regression.weight', 'esm.contact_head.regression.bias']\n",
        "        for k in sd_keys_hf:\n",
        "\n",
        "            if k in ignore_keys: continue\n",
        "\n",
        "            # vanilla copy over the other parameters\n",
        "            try: assert sd_hf[k].shape == sd[k].shape\n",
        "            except Exception as e:\n",
        "              print(k)\n",
        "              print(f\"Mismatch in the shape of tensor while loading weights - Key: {k}, expected shape: {sd_hf[k].shape}, actual shape: {sd[k].shape if k in sd else k}\")\n",
        "\n",
        "            with torch.no_grad():\n",
        "                sd[k].copy_(sd_hf[k])\n",
        "\n",
        "        # Set the final layers bias as 0 so that it does not affect weight tying scheme\n",
        "        with torch.no_grad():\n",
        "            model.esm.final_layer.bias.zero_()\n",
        "\n",
        "        # Freeze the model\n",
        "        for name, param in model.named_parameters(): # Freezing the entire model\n",
        "            if 'lora_' not in name and 'final_proj' not in name:\n",
        "                param.requires_grad = False\n",
        "\n",
        "        if embedding_post_init:\n",
        "            model.esm.embeddings.post_model_init()\n",
        "            del model.esm.final_layer\n",
        "\n",
        "            #IMP: Here we are assuming that embeddings will never have LoRA attached to it, hence we are going with Linear\n",
        "            model.esm.final_layer = nn.Linear(config.n_embd, model.esm.embeddings.word_embeddings.weight.shape[0])\n",
        "            model.esm.final_layer.weight = model.esm.embeddings.word_embeddings.weight\n",
        "\n",
        "        return model\n",
        "\n",
        "    def get_extended_attn_mask(self, attention_mask, input_shape):\n",
        "\n",
        "        if attention_mask == None: return None\n",
        "        b, s = attention_mask.shape\n",
        "        # Make the attention mask braodcastable for [batch_size, n_heads, seq_len, seq_len]\n",
        "        attention_mask = attention_mask[:, None, None, :]\n",
        "\n",
        "        # Now make sure that it has negetive infinity for all the padded tokens and\n",
        "        # 0 for all attention tokens as we add this mask to attention scores\n",
        "        attn_mask = attention_mask.to(torch.float32)\n",
        "        attn_mask = (1 - attn_mask) * (torch.finfo(torch.float32).min)\n",
        "        attn_mask = attn_mask.expand(b, 1, s, s)\n",
        "        return attn_mask\n",
        "\n",
        "    def forward(self, x, y = None, attention_mask = None, output_encoder_states = True):\n",
        "\n",
        "        # Calculate Embeddings\n",
        "        x = self.esm.embeddings(x, attention_mask) # TODO: Verify the new embeddings function without doing post init and after doing post model init - Ideally both should stay the same\n",
        "\n",
        "        # compute attention_mask for attention scores\n",
        "        extended_attention_mask = self.get_extended_attn_mask(attention_mask, x.shape)\n",
        "\n",
        "        #Do the forward pass\n",
        "        x = self.esm.encoder(x, attention_mask = extended_attention_mask)\n",
        "\n",
        "        if hasattr(self.esm, \"final_proj\"):\n",
        "            x = x + self.esm.final_proj(x)\n",
        "\n",
        "        logits = self.esm.final_layer(x)\n",
        "        output = {'logits': logits}\n",
        "\n",
        "        if output_encoder_states:\n",
        "            output['encoder_output'] = x\n",
        "\n",
        "        if y is not None:\n",
        "            # Calculate loss and send it in output\n",
        "            outputs = logits.view(-1, logits.size(-1))  # (bs*seq_len, 384)\n",
        "            targets = y.view(-1)  # (bs*seq_len)\n",
        "\n",
        "            # Flatten the attention mask\n",
        "            # attention_mask = attention_mask.view(-1)  # (bs*seq_len)\n",
        "\n",
        "            # Calculate cross entropy loss\n",
        "            loss = F.cross_entropy(outputs, targets) # reduction = None)\n",
        "            output['loss'] = loss\n",
        "            # Apply the mask to the loss\n",
        "            # masked_loss = loss * attention_mask\n",
        "\n",
        "            # Calculate the mean loss over the actual tokens (excluding padding)\n",
        "            # total_loss = masked_loss.sum()\n",
        "            # num_tokens = attention_mask.sum()\n",
        "\n",
        "            # actual_loss = total_loss / num_tokens\n",
        "            # output['loss'] = actual_loss\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "9gU8IVUjmDfd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verification of the model equivalence - Done\n",
        "\n",
        "The encoder outputs are verified                                                    "
      ],
      "metadata": {
        "id": "f5IA6CH4eCAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "xgjQkM5qcHUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "hf_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6VqCxI6xslX",
        "outputId": "56bc50a4-7e41-444f-c72d-75bf81bbeb7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t30_150M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hf_model.esm.encoder.layer = nn.ModuleList([hf_model.esm.encoder.layer[0]])\n",
        "# model.esm.encoder.layer = nn.ModuleList([model.esm.encoder.layer[0]])"
      ],
      "metadata": {
        "id": "p1bnKieHYmRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = train_sequences[:2]\n",
        "hf_batch = esm_tokenizer(sequences)\n",
        "hf_batch = esm_tokenizer.pad(hf_batch, padding = 'max_length', max_length = 1026)\n",
        "hf_batch['input_ids'] = torch.tensor(hf_batch['input_ids'], dtype = torch.long)\n",
        "hf_batch['attention_mask'] = torch.tensor(hf_batch['attention_mask'], dtype = torch.int)"
      ],
      "metadata": {
        "id": "R_FIcPXi6AD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the batch for my model\n",
        "tokenizer = get_tokenizer()\n",
        "batch = tokenizer(sequences)\n",
        "batch = tokenizer.pad(batch, padding = 'max_length', max_length = 1026)\n",
        "batch['input_ids'] = torch.tensor(batch['input_ids'], dtype = torch.long)\n",
        "batch['attention_mask'] = torch.tensor(batch['attention_mask'], dtype = torch.int)"
      ],
      "metadata": {
        "id": "31B_vRqW6k6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_model = hf_model.to(device)\n",
        "hf_model = hf_model.eval()\n",
        "hf_model.esm.embeddings.token_dropout = False"
      ],
      "metadata": {
        "id": "EdcfJyRTcUMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove <cls> token at the front\n",
        "hf_batch['input_ids'] = hf_batch['input_ids'][:, 1:]\n",
        "hf_batch['attention_mask'] = hf_batch['attention_mask'][:, 1:]\n",
        "batch['input_ids'] = batch['input_ids'][:, :-1]\n",
        "batch['attention_mask'] = batch['attention_mask'][:, :-1]"
      ],
      "metadata": {
        "id": "-wSc3AAt91wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_batch['input_ids'].shape, hf_batch['attention_mask'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbviZq3S-cO0",
        "outputId": "b33661ca-bd41-4f13-c15a-1c5051a0d87c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 1025]), torch.Size([2, 1025]))"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embs = hf_model.esm.embeddings(hf_batch['input_ids'], attention_mask = hf_batch['attention_mask'])\n",
        "extended_attn_mask = hf_model.esm.get_extended_attention_mask(hf_batch[\"attention_mask\"], hf_batch['input_ids'].shape).to(device)\n",
        "\n",
        "embs.shape, extended_attn_mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGxFQa51uTMs",
        "outputId": "2015f07e-445f-44c6-bee8-c7f51dfa836b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 1025, 640]), torch.Size([2, 1, 1, 1025]))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hf_encoder_output = hf_model.esm.encoder(embs, extended_attn_mask)"
      ],
      "metadata": {
        "id": "W7gvd4txwk03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_encoder_output.last_hidden_state.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyNVME290I6s",
        "outputId": "62b0ff57-40eb-4ad8-de36-cda1cb5ff650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1025, 640])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# out = model(batch['input_ids'].cpu(), batch['attention_mask'].cpu())\n",
        "x = model.esm.embeddings(batch['input_ids'].cpu(), batch['attention_mask'].cpu()) # Verified\n",
        "# compute attention_mask for attention scores\n",
        "attention_mask = model.get_extended_attn_mask(batch['attention_mask'].cpu(), x.shape)\n",
        "x.shape, attention_mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhwCEZO96DJ2",
        "outputId": "e8568b57-8a5e-49d3-ae7e-198aac727f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 1025, 640]), torch.Size([2, 1, 1025, 1025]))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_output = model.esm.encoder(x, attention_mask)\n",
        "encoder_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcbH9CK5-ifP",
        "outputId": "1369d21e-17a6-43d6-f5d5-12d198aa5e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1025, 640])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diff = hf_encoder_output.last_hidden_state.cpu().detach().abs() - encoder_output.detach().abs()"
      ],
      "metadata": {
        "id": "ZcjNNqiEAoB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff.mean(), diff.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgDPkIPFAxZ0",
        "outputId": "d527111f-3d9a-4d70-e7dd-f61b47124ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0004), tensor(0.0181))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Operating at an error rate of 5% at 150M parameter model\n",
        "diff.std()/hf_encoder_output.last_hidden_state.cpu().detach().std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONc3m4VJBnEt",
        "outputId": "21b0b059-f1df-435b-9e52-dfd86f3c9299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0538)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diff.mean()/hf_encoder_output.last_hidden_state.cpu().detach().abs().mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8LVAvhT6l1I",
        "outputId": "44db42c8-717e-4eb5-eb0e-5a06e409807b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.0005)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embs = hf_model.esm.embeddings(hf_batch['input_ids'], attention_mask = hf_batch['attention_mask'])\n",
        "extended_attn_mask = hf_model.esm.get_extended_attention_mask(hf_batch[\"attention_mask\"], hf_batch['input_ids'].shape).to(device)\n",
        "\n",
        "print(embs.shape, extended_attn_mask.shape)\n",
        "hf_output = hf_model.esm.encoder.layer[0].attention.LayerNorm(embs)\n",
        "hf_output_1 = hf_model.esm.encoder.layer[0].attention.self(hf_output, extended_attn_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtfD5T8n-fKc",
        "outputId": "b97a3b5c-1b75-4832-c7dd-cdc6e7b992be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1025, 640]) torch.Size([2, 1, 1, 1025])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = model.esm.embeddings(batch['input_ids'].cpu(), batch['attention_mask'].cpu()) # Verified\n",
        "# compute attention_mask for attention scores\n",
        "attention_mask = model.get_extended_attn_mask(batch['attention_mask'].cpu(), x.shape)\n",
        "\n",
        "diff = (embs.detach().abs() - x.detach().abs())\n",
        "print(x.shape, attention_mask.shape, diff.mean(), diff.std())\n",
        "\n",
        "output = model.esm.encoder.layer[0].attention.LayerNorm(x)\n",
        "output_1 = model.esm.encoder.layer[0].attention.self(output, attention_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CQ6I_w6DNig",
        "outputId": "95e770a2-87a9-43d3-eaf6-0d606cdced8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1025, 640]) torch.Size([2, 1, 1025, 1025]) tensor(4.0795e-05) tensor(0.0054)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diff = hf_output_1[0].detach().abs() - output_1.detach().abs()\n",
        "diff.mean(), diff.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fguKNeGuEgji",
        "outputId": "474070c4-cca4-4d66-e624-c7ed31cf26f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0002), tensor(0.0035))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffrfDtAeEiVO",
        "outputId": "eaff44e9-2dbb-4883-c161-88f8b19734af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1026, 33])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TPJZXSkaEoZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Battle of Tokenizers"
      ],
      "metadata": {
        "id": "54SsKIXlIhY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = 'facebook/esm2_t30_150M_UR50D'\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "esm_tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, padding='max_length', max_length=1026)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "9c7eefa772814c0d94b1cdebd8e42c32",
            "0fd1cd86c5344932a7d68b7da4e89c4d",
            "cc36752274be4f88b5ea15029a717755",
            "2543169c369647dba087013c3b1f3fa2",
            "641726821c2e40c3b5c260f4185223f7",
            "8553cc615aa1408bbe8eaeaa5f1ab9d5",
            "cbc139ab6f3249a4ba53cd53ba3d7fdf",
            "7d3cfe2c696c4a19a0427792b8449112",
            "3a60bbf5a7df428e9e30dba35209008f",
            "ce9487c70b4646c69ea6c5e36a544c0f",
            "3964a7c9c762407aba7a8dd41556cc69",
            "01f986b1b58a407ba8baa75cc1af20b9",
            "a537f269af08414dbdf1d0a41cd40658",
            "da24fac9c6c341d6ae3136e96f219707",
            "3e4e436d275d4edba6b792d2e8090bf9",
            "92ef0c609b08409fa229cd3beffa6b4d",
            "09897e70d01f46d3aaff5665501d68e7",
            "7188dccc3fe64b1c8ed07dbb2b441d92",
            "cdb8d90707c8487bab2525054c2c4040",
            "4df224e075864ac5bb482ba2d51da077",
            "ada5dda78cf648f98a9b7720852eb837",
            "f2987b1ba2ee479d808483c15bb43988",
            "b772e3ee8c4847ba897faea4fe4b3bdf",
            "97da354c44cc4ce4b95af09de4be7fac",
            "05aa498de88349ddb8bb7f78ffb7a20b",
            "f169a40c39de414fb3a82e89f3c0fe17",
            "ddbd7cf1f73c40d7ab50b93055c8c48e",
            "e355a162c64e47e5851514306f46f725",
            "cdfb4696696c476b9b09209f564d39b6",
            "76afb53068264ac0b2c87252c50a6b6c",
            "2f51966b17224eba9dd9d7ae88be8e14",
            "20c774c177f74603928945e4095edac3",
            "b0a1fbb1679d48a8a171b838511fd89f"
          ]
        },
        "id": "NaMYw3qFIiFV",
        "outputId": "e2da9c98-0aba-4026-f459-72d285746327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/95.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c7eefa772814c0d94b1cdebd8e42c32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/93.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01f986b1b58a407ba8baa75cc1af20b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b772e3ee8c4847ba897faea4fe4b3bdf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "ForceGPT_model_name='lamm-mit/ProteinForceGPT'\n",
        "\n",
        "pfg_tokenizer = AutoTokenizer.from_pretrained(ForceGPT_model_name, trust_remote_code=True)\n",
        "pfg_tokenizer.pad_token = pfg_tokenizer.eos_token"
      ],
      "metadata": {
        "id": "Ol0bqVGRdU1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets load PFGPT\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "ForceGPT_model_name='lamm-mit/ProteinForceGPT'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(ForceGPT_model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# model = AutoModelForCausalLM.from_pretrained(\n",
        "#     ForceGPT_model_name,\n",
        "#     trust_remote_code=True\n",
        "# ).to(device)\n",
        "\n",
        "# model.config.use_cache = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "c0c8cad50200467192b825db2af4a70c",
            "fdd82e782e1a461f89fb73fe8b977e4d",
            "0ea28c92d30d4cecbe2055d7d3142774",
            "86ea1454d74442c3b1540ce5d954c7f7",
            "0e535805a1f34aaca1014b574edc8651",
            "59dcc50aa123411a953b29ecdfb29c9e",
            "4b4225e9c5774b2ca120ea28734699e6",
            "741156d69d9a4a1e83c3d4c5350702ee",
            "931a4d8fa1834b928059d57b05405da5",
            "53706201159f4749aacfe812e30c5d10",
            "1babc086b67f47ea9beff72673784d63",
            "3e93989b2299437abfc01a7c23aecdb8",
            "53e449e71b68464d923f28d3f712bef2",
            "20710483fb9f425cafcca0f6fbfce464",
            "71b884ea9a07453c8d522c9ef19e1725",
            "e024fb01fe664dd6b9ee1c2bd551340d",
            "85917f38624544c78c148abe67ac1e51",
            "197d3748f2ff4048862a681101627fba",
            "b0938753c0ab4bc2b4481f9c6324ca90",
            "e41cfe4f5ae54ec1b94f69e8c4c99f81",
            "07db942bac554280b725979a01d08792",
            "44f71fb6ba2249d1b976cc14b7c328e1",
            "db4576f305764d6593e8a24a59a77a1e",
            "17c7fef1c7284293973271d6686bde93",
            "3090ba498f6546c0a7a36a3bebdea477",
            "6a6640a52a144813a02e7b77cfdd7adf",
            "4141cc67457b4cf8bf22c45134a7c250",
            "6da8a84681f94033a18d3bd9cdd108bf",
            "8043a081ccc6482e8d5123cd5c084620",
            "84a609bad51b47efbe988bda12be86c5",
            "d58c657332724ebca7c27a4cb5e9be00",
            "294af594e7184f8b8ba067aa884dfc34",
            "fc87a83a7cc242bdb5ed49de351d7532"
          ]
        },
        "id": "i8jyj4vCUKCJ",
        "outputId": "2dfe9ce9-fe5d-4436-f588-584451802933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/722 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0c8cad50200467192b825db2af4a70c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.82G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e93989b2299437abfc01a7c23aecdb8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/133 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db4576f305764d6593e8a24a59a77a1e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pfgpt_vocab = tokenizer.get_vocab()\n",
        "esm_vocab = esm_tokenizer.get_vocab()"
      ],
      "metadata": {
        "id": "FvxC7lnDjK3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pfgpt_keys = set(pfgpt_vocab.keys())\n",
        "esm_keys = set(esm_vocab)"
      ],
      "metadata": {
        "id": "80hDRuMOj2_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_keys = pfgpt_keys.intersection(esm_keys)"
      ],
      "metadata": {
        "id": "im5UmnMBj-tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "emb_1 = nn.Embedding(33, 10)\n",
        "emb_2 = nn.Embedding(384, 10)"
      ],
      "metadata": {
        "id": "QTlFyOkJkAaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_keys = list(common_keys)"
      ],
      "metadata": {
        "id": "8WcdlHNJlc56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(common_keys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN_W1tvSlqxu",
        "outputId": "1aaa0274-1228-4509-ce94-c7aa21ed9fe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "esm_tokenizer.convert_tokens_to_ids(common_keys[0]), tokenizer.convert_tokens_to_ids(common_keys[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWD1w-NzllKs",
        "outputId": "0195c276-76eb-4563-b103-aeec79889600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23, 70)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "emb2_orig = deepcopy(emb_2)"
      ],
      "metadata": {
        "id": "A1BMJ3r9mrwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "esm_tokenizer.convert_tokens_to_ids(common_keys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8vWhlZKn5cP",
        "outputId": "12e35504-555d-406e-e765-c1d73e968776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[23,\n",
              " 17,\n",
              " 8,\n",
              " 13,\n",
              " 16,\n",
              " 15,\n",
              " 14,\n",
              " 20,\n",
              " 11,\n",
              " 5,\n",
              " 7,\n",
              " 27,\n",
              " 6,\n",
              " 30,\n",
              " 18,\n",
              " 12,\n",
              " 4,\n",
              " 25,\n",
              " 24,\n",
              " 26,\n",
              " 9,\n",
              " 3,\n",
              " 28,\n",
              " 22,\n",
              " 29,\n",
              " 10,\n",
              " 19,\n",
              " 21]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  indecis = []\n",
        "  for key in common_keys:\n",
        "      esm_embd_index = esm_tokenizer.convert_tokens_to_ids(key)\n",
        "      pfg_embd_index = tokenizer.convert_tokens_to_ids(key)\n",
        "      indecis.append(pfg_embd_index)\n",
        "      emb_2.weight[pfg_embd_index] = emb_1.weight[esm_embd_index]"
      ],
      "metadata": {
        "id": "-aUxmWqaldv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.equal( emb2_orig.weight[indecis], emb_2.weight[indecis])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rex19lr7moRD",
        "outputId": "ba0d4df6-4eb2-40c8-bc5e-fd45077b80db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.equal(emb_2.weight[tokenizer.convert_tokens_to_ids(common_keys)], emb_1.weight[esm_tokenizer.convert_tokens_to_ids(common_keys)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsnXWtGGm2Rn",
        "outputId": "73f99d07-1474-42c0-8c48-580e9c5052c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.zeros(384)\n",
        "mask[indecis] = True\n",
        "# emb_2.weight[indecis].requires_grad_(False)"
      ],
      "metadata": {
        "id": "C6W51bN_o0Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the DS"
      ],
      "metadata": {
        "id": "KwAcw2nPhw-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "ds = load_dataset(\"lamm-mit/GPTProteinPretrained\")\n",
        "\n",
        "def get_tokenizer():\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"lamm-mit/GPTProteinPretrained\", trust_remote_code=True)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    return tokenizer\n",
        "\n",
        "tokenizer = get_tokenizer()\n",
        "\n",
        "class ProtDS(Dataset):\n",
        "    def __init__(self, sequences, max_len = 1026):\n",
        "\n",
        "        self.sequences = sequences # list object\n",
        "        self.max_len = max_len\n",
        "        self.eos_token = '</s>' # PFGPT's eos token - End of sequence\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.sequences[idx]\n",
        "        if len(seq) >= self.max_len - 1:\n",
        "            seq = seq[:self.max_len - 1]\n",
        "\n",
        "        label = seq[1:]\n",
        "\n",
        "        return seq, label\n",
        "\n",
        "def seq_collate_fn(data):\n",
        "    # data is a list of tuples\n",
        "    x, y = zip(*data)\n",
        "    train_tokenized = tokenizer(x)\n",
        "    labels_tokenized = tokenizer(y)\n",
        "\n",
        "    padded_train_tokenized = tokenizer.pad(train_tokenized, padding = 'max_length', max_length = 1026)\n",
        "    padded_labels_tokenized = tokenizer.pad(labels_tokenized, padding = 'max_length', max_length = 1026)\n",
        "    padded_train_tokenized['labels'] = padded_labels_tokenized['input_ids']\n",
        "\n",
        "    for k, v in padded_train_tokenized.items():\n",
        "        try:\n",
        "            padded_train_tokenized[k] = torch.tensor(v, dtype = torch.long)\n",
        "        except:\n",
        "            breakpoint()\n",
        "\n",
        "    return padded_train_tokenized"
      ],
      "metadata": {
        "id": "1LE0lvnrh4bk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7e1c3c1-16cf-4baf-fc96-45e49890da87"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Playing with PFGPT"
      ],
      "metadata": {
        "id": "3qeJdYnbLwSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "ForceGPT_model_name = 'lamm-mit/ProteinForceGPT'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(ForceGPT_model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    ForceGPT_model_name,\n",
        "    trust_remote_code=True\n",
        ").to(device)\n",
        "\n",
        "model.config.use_cache = False\n",
        "\n",
        "sequences = ds['train']['text']\n",
        "train_seqs, valid_seqs = train_test_split(sequences, test_size = 0.05, shuffle = True)\n",
        "train_ds, valid_ds = ProtDS(train_seqs), ProtDS(valid_seqs)\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size= batch_size, collate_fn = seq_collate_fn)\n",
        "valid_dl = DataLoader(valid_ds, batch_size= batch_size, collate_fn = seq_collate_fn)"
      ],
      "metadata": {
        "id": "mldK158EsLbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "val_iter = iter(valid_dl)"
      ],
      "metadata": {
        "id": "xPbVk9h2PnZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#benchmarking\n",
        "for i in tqdm(range(1000)):\n",
        "\n",
        "    with torch.no_grad():\n",
        "        batch = next(val_iter)\n",
        "        out = model(batch['input_ids'].to(device), attention_mask = batch['attention_mask'].to(device))\n",
        "        loss = F.cross_entropy(out.logits.view(-1, 384).cpu(), batch['labels'].view(-1))\n",
        "        losses.append(loss.item())\n",
        "\n",
        "np.mean(losses)"
      ],
      "metadata": {
        "id": "7p47vsIvNCuI",
        "outputId": "701aa172-a919-4a12-f7e7-e70f0d2294b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [23:07<00:00,  1.39s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9303220844566822"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "def train(model, train_dl, learning_rate = 3e-04, epochs = 1, grad_accum_steps = 5, stop_after = 100):\n",
        "\n",
        "    # form data loaders\n",
        "    # get all hyper parameters\n",
        "    # get the model\n",
        "    # create optimizer\n",
        "    # loss function\n",
        "    # Do the training\n",
        "\n",
        "    iterations = epochs * len(train_dl) + 5\n",
        "    opt = AdamW(model.parameters(), lr = learning_rate, betas = (0.9, 0.95), eps = 1e-05)\n",
        "\n",
        "    # lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr = 6e-04, total_steps = iterations, final_div_factor=10.0)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, iterations)\n",
        "\n",
        "    steps_processed_after_gradstep = 0\n",
        "    total_tokens_trained = 0\n",
        "    loss = None\n",
        "    losses = []\n",
        "\n",
        "    for i in range(epochs):\n",
        "        c = 0\n",
        "        for ite, batch in enumerate(train_dl):\n",
        "            outputs = model(batch['input_ids'].to(device), attention_mask = batch['attention_mask'].to(device))\n",
        "            total_tokens_trained += batch['attention_mask'].sum()\n",
        "\n",
        "            loss = F.cross_entropy(outputs.logits.view(-1, 384).cpu(), batch['labels'].view(-1))\n",
        "            print(loss)\n",
        "            losses.append(loss.item())\n",
        "            loss = loss/grad_accum_steps\n",
        "            loss.backward()\n",
        "            steps_processed_after_gradstep += 1\n",
        "\n",
        "            if steps_processed_after_gradstep == grad_accum_steps:\n",
        "                # Do a backward pass and optimizer step\n",
        "                norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                opt.step()\n",
        "                lr_scheduler.step()\n",
        "\n",
        "                steps_processed_after_gradstep = 0\n",
        "                progress = (ite/(len(train_dl) if len(train_dl) > stop_after else stop_after))*100\n",
        "                print(f\"Train Progress: {progress:.6f}%, train loss: {np.mean(losses[-5:]):.6f}, norm: {norm:.4f}\")\n",
        "                c += 1\n",
        "\n",
        "            if c >= stop_after:\n",
        "                break"
      ],
      "metadata": {
        "id": "RnmVr97PNCyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, batch_size= 2, collate_fn = seq_collate_fn)\n",
        "learning_rate = 5e-06; epochs = 1; grad_accum_steps = 5; stop_after = 100\n",
        "\n",
        "iterations = epochs * len(train_dl) + 5\n",
        "opt = AdamW(model.parameters(), lr = learning_rate, betas = (0.9, 0.95), eps = 1e-05, fused = True)\n",
        "\n",
        "# lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr = 6e-04, total_steps = iterations, final_div_factor=10.0)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, iterations)\n",
        "\n",
        "steps_processed_after_gradstep = 0\n",
        "total_tokens_trained = 0\n",
        "loss = None\n",
        "losses = []\n",
        "\n",
        "for i in range(epochs):\n",
        "    c = 0\n",
        "    for ite, batch in enumerate(train_dl):\n",
        "        outputs = model(batch['input_ids'].to(device), attention_mask = batch['attention_mask'].to(device))\n",
        "        total_tokens_trained += batch['attention_mask'].sum()\n",
        "\n",
        "        loss = F.cross_entropy(outputs.logits.view(-1, 384), batch['labels'].view(-1).to(device))\n",
        "        losses.append(loss.item())\n",
        "        loss = loss/grad_accum_steps\n",
        "        loss.backward()\n",
        "        steps_processed_after_gradstep += 1\n",
        "\n",
        "        if steps_processed_after_gradstep == grad_accum_steps:\n",
        "            # Do a backward pass and optimizer step\n",
        "            norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            opt.step()\n",
        "            lr_scheduler.step()\n",
        "\n",
        "            steps_processed_after_gradstep = 0\n",
        "            progress = (ite/(len(train_dl) if len(train_dl) > stop_after else stop_after))*100\n",
        "            print(f\"Train Progress: {progress:.6f}%, train loss: {np.mean(losses[-5:]):.6f}, norm: {norm:.4f}\")\n",
        "            c += 1\n",
        "\n",
        "        if c >= stop_after:\n",
        "            break"
      ],
      "metadata": {
        "id": "kpYveC7-WaG4",
        "outputId": "3400b657-bd96-4762-fc84-33e8bf919370",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Progress: 0.001091%, train loss: 1.742596, norm: 2.1877\n",
            "Train Progress: 0.002454%, train loss: 1.762802, norm: 3.1289\n",
            "Train Progress: 0.003818%, train loss: 1.570328, norm: 2.8470\n",
            "Train Progress: 0.005181%, train loss: 1.914623, norm: 3.1979\n",
            "Train Progress: 0.006545%, train loss: 2.551982, norm: 4.2431\n",
            "Train Progress: 0.007908%, train loss: 1.866448, norm: 3.2081\n",
            "Train Progress: 0.009272%, train loss: 1.901909, norm: 3.3866\n",
            "Train Progress: 0.010635%, train loss: 1.029105, norm: 2.1363\n",
            "Train Progress: 0.011998%, train loss: 1.596115, norm: 2.8486\n",
            "Train Progress: 0.013362%, train loss: 2.668385, norm: 4.2979\n",
            "Train Progress: 0.014725%, train loss: 1.483623, norm: 2.8441\n",
            "Train Progress: 0.016089%, train loss: 2.046908, norm: 3.4931\n",
            "Train Progress: 0.017452%, train loss: 1.842543, norm: 3.1457\n",
            "Train Progress: 0.018816%, train loss: 1.976512, norm: 3.5191\n",
            "Train Progress: 0.020179%, train loss: 2.173413, norm: 3.7410\n",
            "Train Progress: 0.021543%, train loss: 1.549139, norm: 2.8922\n",
            "Train Progress: 0.022906%, train loss: 1.585071, norm: 2.9849\n",
            "Train Progress: 0.024270%, train loss: 1.663258, norm: 2.9779\n",
            "Train Progress: 0.025633%, train loss: 1.400437, norm: 2.7344\n",
            "Train Progress: 0.026997%, train loss: 1.783185, norm: 3.1783\n",
            "Train Progress: 0.028360%, train loss: 1.550118, norm: 2.8594\n",
            "Train Progress: 0.029724%, train loss: 1.766676, norm: 3.1866\n",
            "Train Progress: 0.031087%, train loss: 1.484302, norm: 2.7404\n",
            "Train Progress: 0.032450%, train loss: 1.368911, norm: 2.6994\n",
            "Train Progress: 0.033814%, train loss: 1.217391, norm: 2.4524\n",
            "Train Progress: 0.035177%, train loss: 1.384390, norm: 2.6626\n",
            "Train Progress: 0.036541%, train loss: 1.128878, norm: 2.3779\n",
            "Train Progress: 0.037904%, train loss: 1.641050, norm: 3.1472\n",
            "Train Progress: 0.039268%, train loss: 1.626987, norm: 3.0098\n",
            "Train Progress: 0.040631%, train loss: 0.929636, norm: 2.0794\n",
            "Train Progress: 0.041995%, train loss: 1.502774, norm: 2.7915\n",
            "Train Progress: 0.043358%, train loss: 1.758228, norm: 3.0706\n",
            "Train Progress: 0.044722%, train loss: 1.652012, norm: 2.9515\n",
            "Train Progress: 0.046085%, train loss: 1.523059, norm: 2.7435\n",
            "Train Progress: 0.047449%, train loss: 1.809805, norm: 3.0845\n",
            "Train Progress: 0.048812%, train loss: 1.532676, norm: 2.8069\n",
            "Train Progress: 0.050175%, train loss: 1.316197, norm: 2.3928\n",
            "Train Progress: 0.051539%, train loss: 1.401003, norm: 2.5499\n",
            "Train Progress: 0.052902%, train loss: 1.512433, norm: 2.6661\n",
            "Train Progress: 0.054266%, train loss: 1.300262, norm: 2.3108\n",
            "Train Progress: 0.055629%, train loss: 1.512965, norm: 2.6208\n",
            "Train Progress: 0.056993%, train loss: 1.222771, norm: 2.2744\n",
            "Train Progress: 0.058356%, train loss: 0.994133, norm: 2.0044\n",
            "Train Progress: 0.059720%, train loss: 1.293725, norm: 2.2585\n",
            "Train Progress: 0.061083%, train loss: 1.309469, norm: 2.3100\n",
            "Train Progress: 0.062447%, train loss: 0.989591, norm: 1.9567\n",
            "Train Progress: 0.063810%, train loss: 1.085714, norm: 2.0016\n",
            "Train Progress: 0.065174%, train loss: 1.062185, norm: 2.0230\n",
            "Train Progress: 0.066537%, train loss: 1.366160, norm: 2.2985\n",
            "Train Progress: 0.067901%, train loss: 1.591128, norm: 2.4508\n",
            "Train Progress: 0.069264%, train loss: 1.232548, norm: 1.9869\n",
            "Train Progress: 0.070627%, train loss: 1.442079, norm: 2.1553\n",
            "Train Progress: 0.071991%, train loss: 1.131060, norm: 1.9133\n",
            "Train Progress: 0.073354%, train loss: 1.273829, norm: 2.0723\n",
            "Train Progress: 0.074718%, train loss: 1.021656, norm: 1.7467\n",
            "Train Progress: 0.076081%, train loss: 0.903147, norm: 1.7347\n",
            "Train Progress: 0.077445%, train loss: 1.518906, norm: 2.0625\n",
            "Train Progress: 0.078808%, train loss: 1.031111, norm: 1.7840\n",
            "Train Progress: 0.080172%, train loss: 1.149593, norm: 1.7622\n",
            "Train Progress: 0.081535%, train loss: 0.919811, norm: 1.6276\n",
            "Train Progress: 0.082899%, train loss: 0.828358, norm: 1.5121\n",
            "Train Progress: 0.084262%, train loss: 0.998882, norm: 1.5703\n",
            "Train Progress: 0.085626%, train loss: 0.720731, norm: 1.4623\n",
            "Train Progress: 0.086989%, train loss: 1.171932, norm: 1.7265\n",
            "Train Progress: 0.088352%, train loss: 1.024084, norm: 1.5635\n",
            "Train Progress: 0.089716%, train loss: 1.117801, norm: 1.6366\n",
            "Train Progress: 0.091079%, train loss: 0.829371, norm: 1.4214\n",
            "Train Progress: 0.092443%, train loss: 0.572004, norm: 1.3046\n",
            "Train Progress: 0.093806%, train loss: 0.912918, norm: 1.4405\n",
            "Train Progress: 0.095170%, train loss: 0.673620, norm: 1.3542\n",
            "Train Progress: 0.096533%, train loss: 0.779015, norm: 1.3397\n",
            "Train Progress: 0.097897%, train loss: 1.135164, norm: 1.5240\n",
            "Train Progress: 0.099260%, train loss: 1.218740, norm: 1.5131\n",
            "Train Progress: 0.100624%, train loss: 0.966728, norm: 1.3882\n",
            "Train Progress: 0.101987%, train loss: 0.878215, norm: 1.3636\n",
            "Train Progress: 0.103351%, train loss: 0.822356, norm: 1.3122\n",
            "Train Progress: 0.104714%, train loss: 0.952717, norm: 1.3899\n",
            "Train Progress: 0.106078%, train loss: 0.775262, norm: 1.2875\n",
            "Train Progress: 0.107441%, train loss: 0.702695, norm: 1.2541\n",
            "Train Progress: 0.108804%, train loss: 0.861335, norm: 1.2966\n",
            "Train Progress: 0.110168%, train loss: 1.004283, norm: 1.3635\n",
            "Train Progress: 0.111531%, train loss: 1.154838, norm: 1.3046\n",
            "Train Progress: 0.112895%, train loss: 0.599238, norm: 1.2021\n",
            "Train Progress: 0.114258%, train loss: 0.861572, norm: 1.2777\n",
            "Train Progress: 0.115622%, train loss: 1.014222, norm: 1.3294\n",
            "Train Progress: 0.116985%, train loss: 1.046825, norm: 1.3098\n",
            "Train Progress: 0.118349%, train loss: 0.675284, norm: 1.2196\n",
            "Train Progress: 0.119712%, train loss: 1.082173, norm: 2.3192\n",
            "Train Progress: 0.121076%, train loss: 1.003140, norm: 1.8400\n",
            "Train Progress: 0.122439%, train loss: 0.905600, norm: 1.2879\n",
            "Train Progress: 0.123803%, train loss: 0.958528, norm: 1.0992\n",
            "Train Progress: 0.125166%, train loss: 0.904225, norm: 1.1431\n",
            "Train Progress: 0.126529%, train loss: 0.825096, norm: 1.1611\n",
            "Train Progress: 0.127893%, train loss: 0.955380, norm: 1.1926\n",
            "Train Progress: 0.129256%, train loss: 0.725781, norm: 1.1506\n",
            "Train Progress: 0.130620%, train loss: 1.050309, norm: 1.2256\n",
            "Train Progress: 0.131983%, train loss: 0.915741, norm: 1.1696\n",
            "Train Progress: 0.133347%, train loss: 0.581136, norm: 1.1319\n",
            "Train Progress: 0.134710%, train loss: 0.867292, norm: 1.1820\n",
            "Train Progress: 0.136074%, train loss: 0.991797, norm: 1.2167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps_processed_after_gradstep,grad_accum_steps"
      ],
      "metadata": {
        "id": "AUO_Du8fWaMR",
        "outputId": "45773850-a3ae-41a8-d80c-d8e163ba1348",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EtT7C1amWaQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IWUJfKs8WaVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full Models Forward Pass"
      ],
      "metadata": {
        "id": "UGKQmVuYbkfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, batch_size= 2, collate_fn = seq_collate_fn)\n",
        "batch = next(iter(train_dl))"
      ],
      "metadata": {
        "id": "8R4vfKF5k-yS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in batch.items():\n",
        "    batch[k] = torch.tensor(v, dtype = torch.long)"
      ],
      "metadata": {
        "id": "tz_UDe4Ayy0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch['input_ids'][:, :20], batch['labels'][:, :20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEfIuOEi6YYt",
        "outputId": "00559427-0484-435b-db44-01d94d391bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 86, 104, 116, 120, 104, 113, 102, 104,  63,  80,  78,  87,  79,  90,\n",
              "           85,  90,  79,  74,  85,  68],\n",
              "         [ 86, 104, 116, 120, 104, 113, 102, 104,  63,  80,  78,  81,  73,  75,\n",
              "           76,  72,  92,  83,  71,  72]]),\n",
              " tensor([[104, 116, 120, 104, 113, 102, 104,  63,  80,  78,  87,  79,  90,  85,\n",
              "           90,  79,  74,  85,  68,  79],\n",
              "         [104, 116, 120, 104, 113, 102, 104,  63,  80,  78,  81,  73,  75,  76,\n",
              "           72,  92,  83,  71,  72,  74]]))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch['attention_mask']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjYKr0Kb67xY",
        "outputId": "33f115b9-aed9-457d-e1df-058b9d328384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer()\n",
        "model = ESM.from_pretrained(\"esm2_t30_150M_UR50D\") # load the pretrained frozen model\n",
        "print('Models created')\n",
        "# print(model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFRBHUn07i8a",
        "outputId": "6560fb5e-33c3-416a-c678-e8e09a80b3d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading weights from pretrained gpt: esm2_t30_150M_UR50D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t30_150M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = model(batch['input_ids'], y = batch['labels'], attention_mask = batch['attention_mask'])"
      ],
      "metadata": {
        "id": "L-SX6MusNn8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.keys(), out['loss']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X61c7wYN8Ym",
        "outputId": "f1a2dbb7-ca55-468c-f7a5-cf9e3773e34d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dict_keys(['logits', 'encoder_output', 'loss']),\n",
              " tensor(6.5117, grad_fn=<DivBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out['loss'].backward()"
      ],
      "metadata": {
        "id": "X_2JFrWgV0cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.esm.embeddings.word_embeddings.weight.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ul1qpqQwYGBD",
        "outputId": "1f83036c-32b4-4379-9c39-10d64227e3e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.5076e-04, -6.7168e-04,  1.1258e-04,  ..., -1.3667e-04,\n",
              "         -8.8862e-05,  7.6055e-05],\n",
              "        [-1.0316e-03,  3.5895e-04, -4.8191e-04,  ...,  6.3798e-04,\n",
              "         -5.2104e-04,  6.7750e-04],\n",
              "        [ 8.3470e-05, -5.6658e-04, -6.2378e-05,  ..., -1.4281e-04,\n",
              "         -3.4456e-04,  8.1855e-05],\n",
              "        ...,\n",
              "        [ 3.3991e-04, -9.5196e-04,  5.7768e-04,  ..., -4.9824e-04,\n",
              "          1.1677e-04,  1.2066e-04],\n",
              "        [ 2.1030e-04, -3.7372e-04,  1.2371e-04,  ..., -1.5023e-04,\n",
              "          2.4959e-05, -3.2917e-05],\n",
              "        [ 1.7095e-04, -3.1254e-04,  5.4279e-05,  ..., -9.9283e-05,\n",
              "         -3.6376e-05,  8.5545e-05]])"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.esm.embeddings.word_embeddings.weight.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2lj6cMQZjg1",
        "outputId": "d95cb90a-3901-4c26-8a40-a248aa27b092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([384, 640])"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.ones(384, dtype=torch.float32)\n",
        "mask[model.esm.embeddings.indices] = 0.\n",
        "\n",
        "mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsNlz1NIZYgg",
        "outputId": "8888302f-338f-4c80-9f9d-1850056eccf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([384])"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.esm.embeddings.word_embeddings.weight.grad = model.esm.embeddings.word_embeddings.weight.grad * mask[:, None]"
      ],
      "metadata": {
        "id": "d3LKUEUdZe1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.esm.embeddings.word_embeddings.weight.grad[model.esm.embeddings.indices]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7BzT5KwZ3U9",
        "outputId": "f185982e-0144-4fb4-a5c2-3fbec171e91c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0., 0., -0.,  ..., 0., -0., -0.],\n",
              "        [-0., 0., -0.,  ..., 0., 0., -0.],\n",
              "        [0., -0., 0.,  ..., -0., -0., 0.],\n",
              "        ...,\n",
              "        [0., -0., -0.,  ..., -0., -0., 0.],\n",
              "        [-0., 0., -0.,  ..., 0., -0., -0.],\n",
              "        [0., -0., 0.,  ..., -0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LoRA"
      ],
      "metadata": {
        "id": "szAQ6WsJbqTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from dataclasses import dataclass\n",
        "from einops import rearrange, repeat\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "PFGPT_VOCAB_SIZE = 384\n",
        "PFGPT_HF_MODEL_PATH = 'lamm-mit/ProteinForceGPT'"
      ],
      "metadata": {
        "id": "NmrobsXRszl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "PlOqu9wwZ4l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class LoRAConfig:\n",
        "    lora_r: int = 8\n",
        "    lora_alpha: int = 16\n",
        "    lora_dropout: int = 0.05\n",
        "    lora_query: bool = True\n",
        "    lora_key: bool = False\n",
        "    lora_value: bool = True\n",
        "    lora_projection: bool = False\n",
        "    lora_mlp: bool = False\n",
        "    lora_head: bool = False\n",
        "\n",
        "class LoRALinear(nn.Linear):\n",
        "    def __init__(self, nin, nout, lora_config):\n",
        "        super().__init__(nin, nout)\n",
        "        std_dev = 1 / torch.sqrt(torch.tensor(lora_config.lora_r).float())\n",
        "        self.lora_A = torch.nn.Parameter(torch.randn(nin, lora_config.lora_r) * std_dev)\n",
        "        self.lora_B = torch.nn.Parameter(torch.zeros(lora_config.lora_r, nout))\n",
        "        self.alpha = lora_config.lora_alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        lora_x = self.alpha * (x @ self.lora_A @ self.lora_B)\n",
        "        x = super().forward(x)\n",
        "        return x + lora_x\n",
        "\n",
        "def get_tokenizer():\n",
        "    tokenizer = AutoTokenizer.from_pretrained(PFGPT_HF_MODEL_PATH, trust_remote_code=True)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    return tokenizer\n",
        "\n",
        "def rotate_half(x):\n",
        "    x1, x2 = x.chunk(2, dim=-1)\n",
        "    return torch.cat((-x2, x1), dim=-1)\n",
        "\n",
        "def apply_rotary_pos_emb(x, cos, sin):\n",
        "    cos = cos[:, :, : x.shape[-2], :]\n",
        "    sin = sin[:, :, : x.shape[-2], :]\n",
        "\n",
        "    return (x * cos) + (rotate_half(x) * sin)\n",
        "\n",
        "class RotaryEmbedding(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Rotary position embeddings based on those in\n",
        "    [RoFormer](https://huggingface.co/docs/transformers/model_doc/roformer). Query and keys are transformed by rotation\n",
        "    matrices which depend on their relative positions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim: int):\n",
        "        super().__init__()\n",
        "        # Generate and save the inverse frequency buffer (non trainable)\n",
        "        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2, dtype=torch.int64).float() / dim))\n",
        "        inv_freq = inv_freq\n",
        "        self.register_buffer(\"inv_freq\", inv_freq)\n",
        "\n",
        "        self._seq_len_cached = None\n",
        "        self._cos_cached = None\n",
        "        self._sin_cached = None\n",
        "\n",
        "    def _update_cos_sin_tables(self, x, seq_dimension=2):\n",
        "        seq_len = x.shape[seq_dimension]\n",
        "\n",
        "        # Reset the tables if the sequence length has changed,\n",
        "        # or if we're on a new device (possibly due to tracing for instance)\n",
        "        if seq_len != self._seq_len_cached or self._cos_cached.device != x.device:\n",
        "            self._seq_len_cached = seq_len\n",
        "            t = torch.arange(x.shape[seq_dimension], device=x.device).type_as(self.inv_freq)\n",
        "            freqs = torch.outer(t, self.inv_freq)\n",
        "            emb = torch.cat((freqs, freqs), dim=-1).to(x.device)\n",
        "\n",
        "            self._cos_cached = emb.cos()[None, None, :, :]\n",
        "            self._sin_cached = emb.sin()[None, None, :, :]\n",
        "\n",
        "        return self._cos_cached, self._sin_cached\n",
        "\n",
        "    def forward(self, q: torch.Tensor, k: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        self._cos_cached, self._sin_cached = self._update_cos_sin_tables(k, seq_dimension=-2)\n",
        "\n",
        "        return (\n",
        "            apply_rotary_pos_emb(q, self._cos_cached, self._sin_cached),\n",
        "            apply_rotary_pos_emb(k, self._cos_cached, self._sin_cached)\n",
        "        )\n",
        "\n",
        "class ESMEmbeddings(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.word_embeddings = nn.Embedding(config.vocab_size, config.n_embd)\n",
        "        self.position_embeddings = nn.Embedding(config.block_size, config.n_embd)\n",
        "\n",
        "    def post_model_init(self):\n",
        "        # Merge both the tokenizer vocabs - Battle of Tokenizers\n",
        "        # That is create a new word embedding of pf_gpts vocab size and configs n_embd\n",
        "        # Get pf GPT Tokenizer\n",
        "        pfgpt_tokenizer = AutoTokenizer.from_pretrained(PFGPT_HF_MODEL_PATH, trust_remote_code=True)\n",
        "        pfgpt_tokenizer.pad_token = pfgpt_tokenizer.eos_token\n",
        "        pfgpt_vocab = pfgpt_tokenizer.get_vocab()\n",
        "\n",
        "        # Get ESM Tokenizer\n",
        "        esm_tokenizer = AutoTokenizer.from_pretrained(self.config.pre_trained_model_name, padding='max_length', max_length=1026)\n",
        "        esm_vocab = esm_tokenizer.get_vocab()\n",
        "        new_word_embeddings = nn.Embedding(PFGPT_VOCAB_SIZE, self.config.n_embd)\n",
        "        torch.nn.init.normal_(new_word_embeddings.weight, std = 0.1263)\n",
        "\n",
        "        # Find all the common keys tokens between esm tokenizer and pf_gpt tokenizer\n",
        "        pfgpt_keys = set(pfgpt_vocab.keys())\n",
        "        esm_keys = set(esm_vocab.keys())\n",
        "        common_keys = list(pfgpt_keys.intersection(esm_keys))\n",
        "\n",
        "        # now, copy a particular tokens embedding from ems_embedding to the new embedding that we create here\n",
        "        with torch.no_grad():\n",
        "            indices = []\n",
        "            for key in common_keys:\n",
        "                esm_embd_index = esm_tokenizer.convert_tokens_to_ids(key)\n",
        "                pfg_embd_index = pfgpt_tokenizer.convert_tokens_to_ids(key)\n",
        "                indices.append(pfg_embd_index)\n",
        "                new_word_embeddings.weight[pfg_embd_index] = self.word_embeddings.weight[esm_embd_index]\n",
        "\n",
        "            # Check for embedding equivalance\n",
        "            assert torch.equal(new_word_embeddings.weight[pfgpt_tokenizer.convert_tokens_to_ids(common_keys)],\n",
        "                               self.word_embeddings.weight[esm_tokenizer.convert_tokens_to_ids(common_keys)])\n",
        "\n",
        "        # Create a mask for all the indecis we have copied pretrained embeddings\n",
        "        # and turn requires_grad off to those embeddings that we have copied - This is\n",
        "        # not possible, so instead we store the indecis and zero out the grads before optim.step()\n",
        "        # hence we do not update these embeddings\n",
        "        self.indices = indices\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.word_embeddings = new_word_embeddings\n",
        "        self.word_embeddings.requires_grad_(True)\n",
        "\n",
        "    def forward(self, x, attention_mask = None):\n",
        "        token_embs = self.word_embeddings(x)\n",
        "        # Not required as we are use rotary embeddings - Hence we do not require absolute position embeddings\n",
        "        # position_embs = self.esm.embeddings.position_embeddings(torch.arange(0, x.shape[1], 1, dtype = torch.long))\n",
        "        if attention_mask is not None:\n",
        "            token_embs = (token_embs * attention_mask.unsqueeze(-1)).to(token_embs.dtype)\n",
        "        return token_embs\n",
        "\n",
        "@dataclass\n",
        "class ESMConfig():\n",
        "    block_size: int = 1024\n",
        "    vocab_size: int = 50257\n",
        "    n_layer: int = 12\n",
        "    n_head: int = 12\n",
        "    n_embd: int = 768\n",
        "    hidden_size: int = 4096 # 4 * block_size\n",
        "    dropout: float = 0.0\n",
        "    pre_trained_model_name: str = ''\n",
        "\n",
        "class ESMIntermediateLayer(nn.Module):\n",
        "    def __init__(self, nin, nout, lora_config, dropout = 0.0, ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dense = nn.Linear(nin, nout) if not lora_config.lora_mlp else LoRALinear(nin, nout, lora_config)\n",
        "        self.act = nn.GELU(approximate = 'tanh')\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.act(self.dense(x))\n",
        "\n",
        "class ESMOutLayer(nn.Module):\n",
        "    def __init__(self, nin, nout, lora_config, dropout = 0.0, inside_attention = False):\n",
        "        super().__init__()\n",
        "\n",
        "        # 2 places used - 1. inisde the attention block  and inside the MLP\n",
        "        # if used inside attention and lora_config.lora_projection is true then dense is a LoRALInear\n",
        "        # elif used in mlp and lora_config.lora_mlp is true then dens is a LoRALinear again\n",
        "        # else its a Linear\n",
        "\n",
        "        if inside_attention == True and lora_config.lora_projection:\n",
        "            self.dens = LoRALinear(nin, nout, lora_config)\n",
        "        elif inside_attention == False and lora_config.lora_mlp:\n",
        "            self.dens = LoRALinear(nin, nout, lora_config)\n",
        "        else:\n",
        "            self.dense = nn.Linear(nin, nout)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, attn_scores):\n",
        "        x = self.dense(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x + attn_scores\n",
        "        return x\n",
        "\n",
        "class ESMSelfAttn(nn.Module): # Verified\n",
        "\n",
        "    def __init__(self, config, lora_config):\n",
        "        super().__init__()\n",
        "\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "\n",
        "        self.query = nn.Linear(config.n_embd, config.n_embd) if not lora_config.lora_query else LoRALinear(config.n_embd, config.n_embd, lora_config)\n",
        "        self.key = nn.Linear(config.n_embd, config.n_embd) if not lora_config.lora_key else LoRALinear(config.n_embd, config.n_embd, lora_config)\n",
        "        self.value = nn.Linear(config.n_embd, config.n_embd) if not lora_config.lora_value else LoRALinear(config.n_embd, config.n_embd, lora_config)\n",
        "        self.n_head = config.n_head\n",
        "\n",
        "        attention_head_size = config.n_embd//config.n_head\n",
        "\n",
        "        # Add a rotary embeddings here\n",
        "        self.rotary_embeddings = RotaryEmbedding(dim = attention_head_size)\n",
        "\n",
        "    def forward(self, x, attention_mask):\n",
        "\n",
        "        # x -> (b, s, e) -> (b s, h, e/h)\n",
        "        k, q, v = self.key(x), self.query(x), self.value(x)\n",
        "\n",
        "        k = rearrange(k, 'b s (h e) -> b h s e', h = self.n_head)\n",
        "        q = rearrange(q, 'b s (h e) -> b h s e', h = self.n_head)\n",
        "        v = rearrange(v, 'b s (h e) -> b h s e', h = self.n_head)\n",
        "\n",
        "        # Add rotary embeddings here for k and q tensors\n",
        "        q, k = self.rotary_embeddings(q, k)\n",
        "\n",
        "        # Attention claculation - # TODO: make is_casual true in case of finetuning - Very important\n",
        "        y = F.scaled_dot_product_attention(q, k, v, attn_mask = attention_mask, is_causal = True) # flash attention\n",
        "        y = rearrange(y, 'b h s e -> b s (h e)', h = self.n_head)\n",
        "        return y\n",
        "\n",
        "class ESMAttn(nn.Module): # Verified\n",
        "\n",
        "    def __init__(self, config, lora_config):\n",
        "        super().__init__() # No activation function at this level\n",
        "        self.self = ESMSelfAttn(config, lora_config)\n",
        "        self.output = ESMOutLayer(config.n_embd, config.n_embd, lora_config, dropout = getattr(config, 'dropout', 0.), inside_attention = True)\n",
        "        self.LayerNorm = nn.LayerNorm(config.n_embd)\n",
        "\n",
        "    def forward(self, x, attention_mask):\n",
        "        inter_x = self.LayerNorm(x)\n",
        "        attn = self.self(inter_x, attention_mask)\n",
        "        out = self.output(attn, x)\n",
        "        return out\n",
        "\n",
        "class ESMLayers(nn.Module): # Both Init and Forward Verified - Done and Dusted\n",
        "\n",
        "    def __init__(self, config, lora_config):\n",
        "        super().__init__()\n",
        "        self.attention = ESMAttn(config, lora_config)\n",
        "        self.intermediate = ESMIntermediateLayer(config.n_embd, config.hidden_size, lora_config) #\n",
        "        self.output = ESMOutLayer(config.hidden_size, config.n_embd, lora_config) #\n",
        "        self.LayerNorm = nn.LayerNorm(config.n_embd)\n",
        "\n",
        "    def forward(self, x, attention_mask):\n",
        "        attention_op = self.attention(x, attention_mask)\n",
        "        attention_op_ln = self.LayerNorm(attention_op) # This will keep the activations in check - Lets see\n",
        "        inter = self.intermediate(attention_op_ln)\n",
        "        out = self.output(inter, attention_op)\n",
        "        return out\n",
        "\n",
        "class ESMEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self, config, lora_config):\n",
        "        super().__init__()\n",
        "\n",
        "        # No activation functions here as well\n",
        "\n",
        "        self.layer = nn.ModuleList([ESMLayers(config, lora_config) for _ in range(config.n_layer)])\n",
        "        self.emb_layer_norm_after = nn.LayerNorm(config.n_embd)\n",
        "\n",
        "    def forward(self, x, attention_mask = None):\n",
        "\n",
        "        for layer in self.layer:\n",
        "            x = layer(x, attention_mask)\n",
        "\n",
        "        return self.emb_layer_norm_after(x)\n",
        "\n",
        "class ESM(nn.Module):\n",
        "\n",
        "    def __init__(self, config, lora_config):\n",
        "\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.esm = nn.ModuleDict(dict(\n",
        "            embeddings = ESMEmbeddings(config),\n",
        "            encoder = ESMEncoder(config, lora_config), # Done, forward - here\n",
        "            final_layer = nn.Linear(config.n_embd, config.vocab_size) if not lora_config.lora_head else\n",
        "                              LoRALinear(config.n_embd, config.vocab_size, lora_config)\n",
        "        ))\n",
        "        self.esm.final_layer.weight = self.esm.embeddings.word_embeddings.weight\n",
        "\n",
        "        # Final Layer bias initializtion\n",
        "        torch.nn.init.zeros_(self.esm.final_layer.bias) # Set the bias to 0\n",
        "        # Finally one small thing is to decide weather to add an intermediate layer or not? - Thats a future discussion\n",
        "\n",
        "    @classmethod\n",
        "    def get_pretrained_config(cls, model_type = 'esm2_t33_650M_UR50D'):\n",
        "\n",
        "        '''\n",
        "        name                n_layers    n_params\n",
        "        esm2_t48_15B_UR50D\t48\t        15B\n",
        "        esm2_t36_3B_UR50D\t36\t        3B\n",
        "        esm2_t33_650M_UR50D\t33\t        650M\n",
        "        esm2_t30_150M_UR50D\t30\t        150M\n",
        "        esm2_t12_35M_UR50D\t12\t        35M\n",
        "        esm2_t6_8M_UR50D\n",
        "        '''\n",
        "\n",
        "        assert model_type in {'esm2_t36_3B_UR50D', 'esm2_t33_650M_UR50D', 'esm2_t30_150M_UR50D'}\n",
        "\n",
        "        config_args = {\n",
        "            'esm2_t36_3B_UR50D': dict(n_layer=36, n_head = 40, n_embd=2560, hidden_size=10240), # 3B params\n",
        "            'esm2_t33_650M_UR50D': dict(n_layer=33, n_head = 20, n_embd=1280, hidden_size=5120), # 650M params\n",
        "            'esm2_t30_150M_UR50D': dict(n_layer=30, n_head = 20, n_embd=640, hidden_size=2560), # 150M params\n",
        "        }[model_type]\n",
        "\n",
        "        config_args['vocab_size'] = 33 # always 33 for ESM Models\n",
        "        config_args['block_size'] = 1026 # Always constant for ESM Models\n",
        "        config_args['pre_trained_model_name'] = f\"facebook/{model_type}\"\n",
        "\n",
        "        config = ESMConfig(**config_args)\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, lora_config, model_type = 'esm2_t33_650M_UR50D', embedding_post_init = True):\n",
        "\n",
        "        config = cls.get_pretrained_config(model_type)\n",
        "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
        "\n",
        "        # create a from-scratch initialized minGPT model\n",
        "        model = cls(config, lora_config)\n",
        "        sd = model.state_dict()\n",
        "        sd_keys = sd.keys()\n",
        "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
        "\n",
        "        # init a huggingface/transformers model\n",
        "        from transformers import AutoModelForSequenceClassification\n",
        "        num_labels = 33\n",
        "        model_hf = AutoModelForSequenceClassification.from_pretrained(config.pre_trained_model_name, num_labels = num_labels)\n",
        "        sd_hf = model_hf.state_dict()\n",
        "\n",
        "        # copy while ensuring all of the parameters are aligned and match in names and shapes\n",
        "        sd_keys_hf = sd_hf.keys()\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if 'inv_freq' not in k]\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if 'classifier' not in k]\n",
        "\n",
        "        ignore_keys = ['esm.contact_head.regression.weight', 'esm.contact_head.regression.bias']\n",
        "        for k in sd_keys_hf:\n",
        "\n",
        "            if k in ignore_keys: continue\n",
        "\n",
        "            # vanilla copy over the other parameters\n",
        "            try: assert sd_hf[k].shape == sd[k].shape\n",
        "            except Exception as e:\n",
        "              print(k)\n",
        "              print(f\"Mismatch in the shape of tensor while loading weights - Key: {k}, expected shape: {sd_hf[k].shape}, actual shape: {sd[k].shape if k in sd else k}\")\n",
        "\n",
        "            with torch.no_grad():\n",
        "                sd[k].copy_(sd_hf[k])\n",
        "\n",
        "        # Set the final layers bias as 0 so that it does not affect weight tying scheme\n",
        "        with torch.no_grad():\n",
        "            model.esm.final_layer.bias.zero_()\n",
        "\n",
        "        # Freeze the model\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'lora_' not in name:\n",
        "                param.requires_grad = False\n",
        "\n",
        "        if embedding_post_init:\n",
        "            model.esm.embeddings.post_model_init()\n",
        "            del model.esm.final_layer\n",
        "\n",
        "            #IMP: Here we are assuming that embeddings will never have LoRA attached to it, hence we are going with Linear\n",
        "            model.esm.final_layer = nn.Linear(config.n_embd, model.esm.embeddings.word_embeddings.weight.shape[0])\n",
        "\n",
        "            model.esm.final_layer.weight = model.esm.embeddings.word_embeddings.weight\n",
        "\n",
        "        return model\n",
        "\n",
        "    def get_extended_attn_mask(self, attention_mask, input_shape):\n",
        "\n",
        "        if attention_mask == None: return None\n",
        "        b, s = attention_mask.shape\n",
        "        # Make the attention mask braodcastable for [batch_size, n_heads, seq_len, seq_len]\n",
        "        attention_mask = attention_mask[:, None, None, :]\n",
        "\n",
        "        # Now make sure that it has negetive infinity for all the padded tokens and\n",
        "        # 0 for all attention tokens as we add this mask to attention scores\n",
        "        attn_mask = attention_mask.to(torch.float32)\n",
        "        attn_mask = (1 - attn_mask) * (torch.finfo(torch.float32).min)\n",
        "        attn_mask = attn_mask.expand(b, 1, s, s)\n",
        "        return attn_mask\n",
        "\n",
        "    def forward(self, x, y = None, attention_mask = None, output_encoder_states = True):\n",
        "\n",
        "        # Calculate Embeddings\n",
        "        x = self.esm.embeddings(x, attention_mask) # TODO: Verify the new embeddings function without doing post init and after doing post model init - Ideally both should stay the same\n",
        "\n",
        "        # compute attention_mask for attention scores\n",
        "        extended_attention_mask = self.get_extended_attn_mask(attention_mask, x.shape)\n",
        "\n",
        "        #Do the forward pass\n",
        "        x = self.esm.encoder(x, attention_mask = extended_attention_mask)\n",
        "        logits = self.esm.final_layer(x)\n",
        "        output = {'logits': logits}\n",
        "\n",
        "        if output_encoder_states:\n",
        "            output['encoder_output'] = x\n",
        "        if y is not None:\n",
        "            # Calculate loss and send it in output\n",
        "            outputs = logits.view(-1, logits.size(-1))  # (bs*seq_len, 384)\n",
        "            targets = y.view(-1)  # (bs*seq_len)\n",
        "\n",
        "            # Flatten the attention mask\n",
        "            attention_mask = attention_mask.view(-1)  # (bs*seq_len)\n",
        "\n",
        "            # Calculate cross entropy loss\n",
        "            loss = F.cross_entropy(outputs, targets, reduction='none')\n",
        "\n",
        "            # Apply the mask to the loss\n",
        "            masked_loss = loss * attention_mask\n",
        "\n",
        "            # Calculate the mean loss over the actual tokens (excluding padding)\n",
        "            total_loss = masked_loss.sum()\n",
        "            num_tokens = attention_mask.sum()\n",
        "\n",
        "            actual_loss = total_loss / num_tokens\n",
        "            output['loss'] = actual_loss\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "CuBYhtqMXbFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config = ESM.get_pretrained_config('esm2_t30_150M_UR50D')\n",
        "lora_config = LoRAConfig()\n",
        "model = ESM.from_pretrained(lora_config, 'esm2_t30_150M_UR50D')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "a5b4b52ea11d4ab6878e92f009f742d1",
            "683a860232484adda21d338b41e222f6",
            "0371e55d87294183a97f2002b973f45f",
            "852ee3354dca47e292fcbab4a747d98a",
            "d4d851c4c942455a8e33d1ea610aaf51",
            "43e742c77e834019bd2ba3b00381e01a",
            "d09a557ef67e44d8b7f39760e2c71f4b",
            "59cea722308f4c3e87c7362d2eae800b",
            "a462bde184cd41229edf04f5599e4218",
            "d235c7cd299747c7a5550ca8e3c1b5a8",
            "c6b7fc99f08a49e1a81454dd8f1aaf0a",
            "36698dfc3899413ea749ace946fb9643",
            "31ebaeecbb7847a49ef763aea90e3e11",
            "b38d50691d2e421db9004019f499b1da",
            "b5a77800ad3a443ba79630d6d31781ce",
            "ade5f9888a2540ccaf6b347c887070cc",
            "f49cd6458bbc43138fdc2c7451b7e4bd",
            "dd1163f8644d46dd9c22ae5415fd5b17",
            "a3d2ac7c9abe40cbae77ce6f3e493f27",
            "7d89c90663154bc19b475c3708d4d347",
            "a60e5ea110e8446491f591c57d3d6a57",
            "6bb3e051d9cf47fcb7864df19c27efc3",
            "f7d636f73665415a8ccc94aadc7b5c4f",
            "7dddfd93147a491096cff7bcdd0a3c10",
            "faed09bfeab746fe9ec03baa3d0ecf27",
            "b18f855c23f549898bd5877a55f2b1ef",
            "ff4ddab9b02f490f82870b989977154d",
            "4a8f1412e7bf4ba7bfe3141abf5dc6af",
            "9382867b69ee4da18825600d2772d7e8",
            "cf4e197d38cf4bd2b77b7db06481a39b",
            "856d68beaea947e6b972834205b924e9",
            "40b4127c6e254413a2370d54aa25b698",
            "1eebc106152241a986ecfa060e7e3abc"
          ]
        },
        "id": "0Xngybci0x24",
        "outputId": "6474a0f4-b6fc-4d9a-d74e-8903727643ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading weights from pretrained gpt: esm2_t30_150M_UR50D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t30_150M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5b4b52ea11d4ab6878e92f009f742d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/3.02k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36698dfc3899413ea749ace946fb9643"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.98k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7d636f73665415a8ccc94aadc7b5c4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-MdkSA92DOk",
        "outputId": "c1012e63-fc77-4631-c0c2-76659faabf62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ESM(\n",
              "  (esm): ModuleDict(\n",
              "    (embeddings): ESMEmbeddings(\n",
              "      (word_embeddings): Embedding(384, 640)\n",
              "      (position_embeddings): Embedding(1026, 640)\n",
              "    )\n",
              "    (encoder): ESMEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-29): 30 x ESMLayers(\n",
              "          (attention): ESMAttn(\n",
              "            (self): ESMSelfAttn(\n",
              "              (query): LoRALinear(in_features=640, out_features=640, bias=True)\n",
              "              (key): Linear(in_features=640, out_features=640, bias=True)\n",
              "              (value): LoRALinear(in_features=640, out_features=640, bias=True)\n",
              "              (rotary_embeddings): RotaryEmbedding()\n",
              "            )\n",
              "            (output): ESMOutLayer(\n",
              "              (dense): Linear(in_features=640, out_features=640, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (LayerNorm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (intermediate): ESMIntermediateLayer(\n",
              "            (dense): Linear(in_features=640, out_features=2560, bias=True)\n",
              "            (act): GELU(approximate='tanh')\n",
              "          )\n",
              "          (output): ESMOutLayer(\n",
              "            (dense): Linear(in_features=2560, out_features=640, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (LayerNorm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (emb_layer_norm_after): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (final_layer): Linear(in_features=640, out_features=384, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LoRA Verification\n",
        "layer = LoRALinear(640, 640, lora_config)\n",
        "lin = nn.Linear(640, 640)\n",
        "layer.weight = lin.weight\n",
        "layer.bias = lin.bias\n",
        "\n",
        "data = torch.randn(2, 10, 640)\n",
        "out = layer(data)\n",
        "out1 = lin(data)\n",
        "assert torch.equal(out, out1)"
      ],
      "metadata": {
        "id": "UEIZ1sIa2avd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Legacy Code"
      ],
      "metadata": {
        "id": "arwiVAVzpP5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "from torch.optim import AdamW\n",
        "\n",
        "sequences = ds['train']['text']\n",
        "train_seqs, valid_seqs = train_test_split(sequences, test_size = 0.05, shuffle = True)\n",
        "train_ds, valid_ds = ProtDS(train_seqs), ProtDS(valid_seqs)\n",
        "\n",
        "tokens_for_grad_update = 10000\n",
        "epochs = 2\n",
        "batch_size = 8\n",
        "grad_accum_steps = 10\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size= batch_size, collate_fn = seq_collate_fn)\n",
        "valid_dl = DataLoader(valid_ds, batch_size= batch_size, collate_fn = seq_collate_fn)\n",
        "iterations = epochs * len(train_dl) + 5\n",
        "\n",
        "opt = AdamW(model.parameters(), lr = 3e-04, betas = (0.9, 0.95), eps = 1e-05)\n",
        "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr = 6e-04, total_steps = iterations, final_div_factor=10.0)\n",
        "\n",
        "steps_processed_after_gradstep = 0\n",
        "loss = None\n",
        "losses = []\n",
        "for i in range(epochs):\n",
        "    for iter, batch in enumerate(train_dl):\n",
        "\n",
        "        outputs = model(batch['input_ids'].to(device), y = batch['labels'].to(device), attention_mask = batch['attention_mask'].to(device))\n",
        "\n",
        "        losses.append(outputs['loss'].item())\n",
        "\n",
        "        outputs['loss'] = outputs['loss']/grad_accum_steps\n",
        "        outputs['loss'].backward()\n",
        "        steps_processed_after_gradstep += 1\n",
        "\n",
        "        if steps_processed_after_gradstep == grad_accum_steps:\n",
        "            # Do a backward pass and optimizer step\n",
        "            norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            opt.step()\n",
        "            lr_scheduler.step()\n",
        "\n",
        "            steps_processed_after_gradstep = 0\n",
        "            print(f\"Train Loss: {losses[-1]}\")\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Do a validation pass for 20 epochs and calculate loss\n",
        "        vl_loss = None\n",
        "        for vl_batch in valid_dl:\n",
        "            outputs = model(vl_batch['input_ids'].to(device), y = vl_batch['labels'].to(device), attention_mask = vl_batch['attention_mask'].to(device))\n",
        "\n",
        "            if vl_loss is not None: vl_loss += outputs['loss']\n",
        "            else: vl_loss = outputs['loss']\n",
        "        print(f'Validation Loss: {vl_loss.item()//len(valid_dl)}')"
      ],
      "metadata": {
        "id": "aAt4AmddpPVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "ycrl_LMbB8kV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "g3n8b8F4IAjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/karpathy/build-nanogpt/blob/master/train_gpt2.py\n",
        "\n",
        "# Read and incorprate\n",
        "model = None\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "_644D376Ergm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ESM.from_pretrained(LoRAConfig(lora_r = 64, lora_key = True, lora_mlp = True, lora_projection = True, lora_alpha = 32), 'esm2_t30_150M_UR50D')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubcB5KEMe6vS",
        "outputId": "c207a00d-7ad1-468b-98e7-d605ca1dd1e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t30_150M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch.optim import AdamW\n",
        "\n",
        "tokens_for_grad_update = 30000\n",
        "epochs = 1\n",
        "batch_size = 8\n",
        "grad_accum_steps = 5\n",
        "\n",
        "sequences = ds['train']['text']\n",
        "train_seqs, valid_seqs = train_test_split(sequences, test_size = 0.05, shuffle = True)\n",
        "train_ds, valid_ds = ProtDS(train_seqs), ProtDS(valid_seqs)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size = batch_size, collate_fn = seq_collate_fn)\n",
        "valid_dl = DataLoader(valid_ds, batch_size = batch_size, collate_fn = seq_collate_fn)\n",
        "iterations = epochs * len(train_dl) + 5\n",
        "\n",
        "opt = AdamW(model.parameters(), lr = 3e-04, betas = (0.9, 0.95), eps = 1e-05, fused = True)\n",
        "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr = 3e-04, total_steps = iterations, final_div_factor=10.0)\n",
        "\n",
        "steps_processed_after_gradstep = 0\n",
        "total_tokens_trained = 0\n",
        "loss = None\n",
        "losses = []\n",
        "\n",
        "vl_losses_track = {0: -np.log(1/384)} # Ideal loss at epoch 0 before any finetuning\n",
        "vl_losses_all = []\n",
        "\n",
        "for i in range(epochs):\n",
        "    c = 0\n",
        "    for iter, batch in enumerate(train_dl):\n",
        "\n",
        "        outputs = model(batch['input_ids'].to(device), y = batch['labels'].to(device), attention_mask = batch['attention_mask'].to(device))\n",
        "        total_tokens_trained += batch['attention_mask'].sum()\n",
        "\n",
        "        losses.append(outputs['loss'].item())\n",
        "        outputs['loss'] = outputs['loss']/grad_accum_steps\n",
        "        outputs['loss'].backward()\n",
        "        steps_processed_after_gradstep += 1\n",
        "\n",
        "        if steps_processed_after_gradstep == grad_accum_steps:\n",
        "            # Do a backward pass and optimizer step\n",
        "            norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            opt.step()\n",
        "            lr_scheduler.step()\n",
        "\n",
        "            steps_processed_after_gradstep = 0\n",
        "            progress = (iter/len(train_dl))*100\n",
        "            print(f\"Train Progress: {progress:.6f}%, train loss: {losses[-1]:.6f}, norm: {norm:.4f}\")\n",
        "            c += 1\n",
        "\n",
        "        if c >= 5: # approximately for every 400k tokens trained on, lets calculate the validation loss\n",
        "            c = 0\n",
        "            vl_losses = []\n",
        "            v_iter = 0\n",
        "            with torch.no_grad():\n",
        "                for vl_batch in valid_dl:\n",
        "                    vl_outputs = model(vl_batch['input_ids'].to(device), y = vl_batch['labels'].to(device), attention_mask = vl_batch['attention_mask'].to(device))\n",
        "                    vl_losses.append(vl_outputs['loss'].item())\n",
        "                    v_iter += 1\n",
        "\n",
        "                    if v_iter%10 == 0: break\n",
        "\n",
        "            vl_losses_all += vl_losses\n",
        "            vl_losses_track[total_tokens_trained] = np.mean(vl_losses)\n",
        "            print(f\"valid loss: {vl_losses_all[-1]:.6f}\")"
      ],
      "metadata": {
        "id": "grzY3Kn2h0T7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch.optim import AdamW\n",
        "\n",
        "tokens_for_grad_update = 30000\n",
        "epochs = 1\n",
        "batch_size = 8\n",
        "grad_accum_steps = 5\n",
        "\n",
        "sequences = ds['train']['text']\n",
        "train_seqs, valid_seqs = train_test_split(sequences, test_size = 0.05, shuffle = True)\n",
        "train_ds, valid_ds = ProtDS(train_seqs), ProtDS(valid_seqs)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size = batch_size, collate_fn = seq_collate_fn)\n",
        "valid_dl = DataLoader(valid_ds, batch_size = batch_size, collate_fn = seq_collate_fn)\n",
        "iterations = epochs * len(train_dl) + 5\n",
        "\n",
        "# opt = AdamW(model.parameters(), lr = 3e-04, betas = (0.9, 0.95), eps = 1e-05)\n",
        "# lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr = 6e-04, total_steps = iterations, final_div_factor=10.0)\n",
        "\n",
        "steps_processed_after_gradstep = 0\n",
        "total_tokens_trained = 0\n",
        "loss = None\n",
        "losses = []\n",
        "\n",
        "vl_losses_track = {0: -np.log(1/384)} # Ideal loss at epoch 0 before any finetuning\n",
        "vl_losses_all = []"
      ],
      "metadata": {
        "id": "bfF7r2CP5Lmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('drive/MyDrive/esm/model_finetune_v5.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW4FcqMeBO-0",
        "outputId": "f9a6824b-2fda-4c54-d02c-633ca2470a41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-6547dad6ac1b>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = torch.load('drive/MyDrive/esm/model_finetune_v5.pt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "opt = AdamW(model.parameters(), lr = 3e-05, betas = (0.9, 0.95), eps = 1e-05)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, iterations)"
      ],
      "metadata": {
        "id": "QW1n_VRd0k6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skip_step_percentage = 0.099881\n",
        "# scaler = torch.amp.GradScaler()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "for i in range(epochs):\n",
        "    c = 0\n",
        "    for iter, batch in enumerate(train_dl):\n",
        "\n",
        "        progress = iter/len(train_dl)\n",
        "        if progress < skip_step_percentage: continue # ensures that it does not train on data it already trained on\n",
        "\n",
        "        # with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
        "        outputs = model(batch['input_ids'].to(device), y = batch['labels'].to(device), attention_mask = batch['attention_mask'].to(device))\n",
        "\n",
        "        total_tokens_trained += batch['attention_mask'].sum()\n",
        "\n",
        "        losses.append(outputs['loss'].item())\n",
        "        outputs['loss'] = outputs['loss']/grad_accum_steps\n",
        "        outputs['loss'].backward()\n",
        "        # scaler.scale(outputs['loss']).backward()\n",
        "        steps_processed_after_gradstep += 1\n",
        "\n",
        "        if steps_processed_after_gradstep == grad_accum_steps:\n",
        "            # Do a backward pass and optimizer step\n",
        "            norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            opt.step()\n",
        "            # scaler.step(opt)\n",
        "            # scaler.update()\n",
        "            lr_scheduler.step()\n",
        "            opt.zero_grad() # zero out the gradiants\n",
        "\n",
        "            steps_processed_after_gradstep = 0\n",
        "            print(f\"Train Progress: {progress:.6f}%, train loss: {losses[-1]:.6f}, norm: {norm:.4f}\")\n",
        "            c += 1\n",
        "\n",
        "        if c >= 5: # approximately for every 400k tokens trained on, lets calculate the validation loss\n",
        "            c = 0\n",
        "            vl_losses = []\n",
        "            v_iter = 0\n",
        "            with torch.no_grad():\n",
        "                for vl_batch in valid_dl:\n",
        "                    vl_outputs = model(vl_batch['input_ids'].to(device), y = vl_batch['labels'].to(device), attention_mask = vl_batch['attention_mask'].to(device))\n",
        "                    vl_losses.append(vl_outputs['loss'].item())\n",
        "                    v_iter += 1\n",
        "\n",
        "                    if v_iter%10 == 0: break\n",
        "\n",
        "            vl_losses_all += vl_losses\n",
        "            vl_losses_track[total_tokens_trained.item()] = np.mean(vl_losses)\n",
        "            print(f\"valid loss: {vl_losses_all[-1]:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkLocyPsukD8",
        "outputId": "a48ac98b-a468-429a-e0e6-394f7c4c4644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Progress: 0.099925%, train loss: 2.722149, norm: 1.5560\n",
            "Train Progress: 0.099979%, train loss: 2.406107, norm: 2.3766\n",
            "Train Progress: 0.100034%, train loss: 2.746398, norm: 1.6512\n",
            "Train Progress: 0.100088%, train loss: 2.723006, norm: 1.5645\n",
            "Train Progress: 0.100143%, train loss: 2.689671, norm: 2.4772\n",
            "valid loss: 2.706636\n",
            "Train Progress: 0.100197%, train loss: 2.735070, norm: 1.7142\n",
            "Train Progress: 0.100252%, train loss: 2.704497, norm: 1.4094\n",
            "Train Progress: 0.100307%, train loss: 2.753490, norm: 2.0476\n",
            "Train Progress: 0.100361%, train loss: 2.773293, norm: 2.0727\n",
            "Train Progress: 0.100416%, train loss: 2.750763, norm: 1.9284\n",
            "valid loss: 2.709348\n",
            "Train Progress: 0.100470%, train loss: 2.663413, norm: 1.5126\n",
            "Train Progress: 0.100525%, train loss: 2.743007, norm: 1.4293\n",
            "Train Progress: 0.100579%, train loss: 2.747785, norm: 2.1961\n",
            "Train Progress: 0.100634%, train loss: 2.763330, norm: 1.0207\n",
            "Train Progress: 0.100688%, train loss: 2.727410, norm: 1.3165\n",
            "valid loss: 2.707886\n",
            "Train Progress: 0.100743%, train loss: 2.470881, norm: 2.3092\n",
            "Train Progress: 0.100797%, train loss: 2.617025, norm: 1.9470\n",
            "Train Progress: 0.100852%, train loss: 2.704036, norm: 1.8785\n",
            "Train Progress: 0.100906%, train loss: 2.716294, norm: 2.4744\n",
            "Train Progress: 0.100961%, train loss: 2.730014, norm: 1.7559\n",
            "valid loss: 2.704783\n",
            "Train Progress: 0.101015%, train loss: 2.773495, norm: 1.2763\n",
            "Train Progress: 0.101070%, train loss: 2.704692, norm: 1.5856\n",
            "Train Progress: 0.101125%, train loss: 2.728553, norm: 1.3601\n",
            "Train Progress: 0.101179%, train loss: 2.729436, norm: 1.5737\n",
            "Train Progress: 0.101234%, train loss: 2.751714, norm: 1.7044\n",
            "valid loss: 2.701860\n",
            "Train Progress: 0.101288%, train loss: 2.764987, norm: 1.7760\n",
            "Train Progress: 0.101343%, train loss: 2.746693, norm: 1.9174\n",
            "Train Progress: 0.101397%, train loss: 2.760253, norm: 1.9655\n",
            "Train Progress: 0.101452%, train loss: 2.689490, norm: 1.3526\n",
            "Train Progress: 0.101506%, train loss: 2.642845, norm: 1.4248\n",
            "valid loss: 2.698799\n",
            "Train Progress: 0.101561%, train loss: 2.650026, norm: 1.9618\n",
            "Train Progress: 0.101615%, train loss: 2.607435, norm: 2.0494\n",
            "Train Progress: 0.101670%, train loss: 2.578963, norm: 1.7276\n",
            "Train Progress: 0.101724%, train loss: 2.745508, norm: 1.6471\n",
            "Train Progress: 0.101779%, train loss: 2.710041, norm: 1.6568\n",
            "valid loss: 2.695239\n",
            "Train Progress: 0.101834%, train loss: 2.792742, norm: 1.6917\n",
            "Train Progress: 0.101888%, train loss: 2.736633, norm: 1.8301\n",
            "Train Progress: 0.101943%, train loss: 2.744941, norm: 1.2924\n",
            "Train Progress: 0.101997%, train loss: 2.697077, norm: 1.4527\n",
            "Train Progress: 0.102052%, train loss: 2.753386, norm: 1.5112\n",
            "valid loss: 2.698976\n",
            "Train Progress: 0.102106%, train loss: 2.717691, norm: 1.4076\n",
            "Train Progress: 0.102161%, train loss: 2.753837, norm: 1.5544\n",
            "Train Progress: 0.102215%, train loss: 2.707430, norm: 1.2519\n",
            "Train Progress: 0.102270%, train loss: 2.569585, norm: 1.7966\n",
            "Train Progress: 0.102324%, train loss: 2.532652, norm: 2.1171\n",
            "valid loss: 2.698699\n",
            "Train Progress: 0.102379%, train loss: 2.740447, norm: 1.3661\n",
            "Train Progress: 0.102433%, train loss: 2.450235, norm: 1.8390\n",
            "Train Progress: 0.102488%, train loss: 2.740134, norm: 2.1328\n",
            "Train Progress: 0.102543%, train loss: 2.788909, norm: 1.5201\n",
            "Train Progress: 0.102597%, train loss: 2.692085, norm: 1.6058\n",
            "valid loss: 2.696687\n",
            "Train Progress: 0.102652%, train loss: 2.660860, norm: 1.7755\n",
            "Train Progress: 0.102706%, train loss: 2.768813, norm: 1.1669\n",
            "Train Progress: 0.102761%, train loss: 2.597701, norm: 1.8359\n",
            "Train Progress: 0.102815%, train loss: 2.707815, norm: 1.5814\n",
            "Train Progress: 0.102870%, train loss: 2.707241, norm: 1.6099\n",
            "valid loss: 2.695332\n",
            "Train Progress: 0.102924%, train loss: 2.758924, norm: 1.4980\n",
            "Train Progress: 0.102979%, train loss: 2.703724, norm: 1.6456\n",
            "Train Progress: 0.103033%, train loss: 2.678233, norm: 1.5871\n",
            "Train Progress: 0.103088%, train loss: 2.750909, norm: 1.7174\n",
            "Train Progress: 0.103142%, train loss: 2.634603, norm: 1.8704\n",
            "valid loss: 2.699334\n",
            "Train Progress: 0.103197%, train loss: 2.689188, norm: 1.7733\n",
            "Train Progress: 0.103252%, train loss: 2.768320, norm: 1.6728\n",
            "Train Progress: 0.103306%, train loss: 2.712283, norm: 1.7011\n",
            "Train Progress: 0.103361%, train loss: 2.700963, norm: 1.5643\n",
            "Train Progress: 0.103415%, train loss: 2.693840, norm: 1.6511\n",
            "valid loss: 2.697434\n",
            "Train Progress: 0.103470%, train loss: 2.744455, norm: 1.3610\n",
            "Train Progress: 0.103524%, train loss: 2.739494, norm: 2.0543\n",
            "Train Progress: 0.103579%, train loss: 2.590618, norm: 2.5356\n",
            "Train Progress: 0.103633%, train loss: 2.539392, norm: 1.9311\n",
            "Train Progress: 0.103688%, train loss: 2.781597, norm: 1.4817\n",
            "valid loss: 2.695503\n",
            "Train Progress: 0.103742%, train loss: 2.719645, norm: 1.6314\n",
            "Train Progress: 0.103797%, train loss: 2.693577, norm: 1.4237\n",
            "Train Progress: 0.103851%, train loss: 2.679013, norm: 2.4007\n",
            "Train Progress: 0.103906%, train loss: 2.696871, norm: 1.5543\n",
            "Train Progress: 0.103961%, train loss: 2.752921, norm: 1.5671\n",
            "valid loss: 2.697514\n",
            "Train Progress: 0.104015%, train loss: 2.721956, norm: 2.5647\n",
            "Train Progress: 0.104070%, train loss: 2.637798, norm: 1.9770\n",
            "Train Progress: 0.104124%, train loss: 2.711479, norm: 2.2209\n",
            "Train Progress: 0.104179%, train loss: 2.538614, norm: 1.7484\n",
            "Train Progress: 0.104233%, train loss: 2.667225, norm: 1.9648\n",
            "valid loss: 2.694608\n",
            "Train Progress: 0.104288%, train loss: 2.693970, norm: 1.2930\n",
            "Train Progress: 0.104342%, train loss: 2.708886, norm: 1.6990\n",
            "Train Progress: 0.104397%, train loss: 2.691389, norm: 2.0903\n",
            "Train Progress: 0.104451%, train loss: 2.719362, norm: 1.7470\n",
            "Train Progress: 0.104506%, train loss: 2.769258, norm: 2.2974\n",
            "valid loss: 2.697364\n",
            "Train Progress: 0.104560%, train loss: 2.584368, norm: 1.6949\n",
            "Train Progress: 0.104615%, train loss: 2.755715, norm: 1.7159\n",
            "Train Progress: 0.104670%, train loss: 2.735412, norm: 1.9051\n",
            "Train Progress: 0.104724%, train loss: 2.675027, norm: 1.4941\n",
            "Train Progress: 0.104779%, train loss: 2.730248, norm: 1.0261\n",
            "valid loss: 2.696278\n",
            "Train Progress: 0.104833%, train loss: 2.755631, norm: 2.1307\n",
            "Train Progress: 0.104888%, train loss: 2.738597, norm: 1.5239\n",
            "Train Progress: 0.104942%, train loss: 2.718244, norm: 1.3106\n",
            "Train Progress: 0.104997%, train loss: 2.642106, norm: 1.6255\n",
            "Train Progress: 0.105051%, train loss: 2.710698, norm: 2.0943\n",
            "valid loss: 2.697798\n",
            "Train Progress: 0.105106%, train loss: 2.747853, norm: 2.1555\n",
            "Train Progress: 0.105160%, train loss: 2.683816, norm: 1.8378\n",
            "Train Progress: 0.105215%, train loss: 2.780174, norm: 1.2893\n",
            "Train Progress: 0.105269%, train loss: 2.654353, norm: 1.9229\n",
            "Train Progress: 0.105324%, train loss: 2.627117, norm: 1.7287\n",
            "valid loss: 2.695426\n",
            "Train Progress: 0.105379%, train loss: 2.737168, norm: 2.2992\n",
            "Train Progress: 0.105433%, train loss: 2.802333, norm: 1.6439\n",
            "Train Progress: 0.105488%, train loss: 2.769626, norm: 1.7496\n",
            "Train Progress: 0.105542%, train loss: 2.754347, norm: 2.3138\n",
            "Train Progress: 0.105597%, train loss: 2.658205, norm: 1.7913\n",
            "valid loss: 2.700243\n",
            "Train Progress: 0.105651%, train loss: 2.755820, norm: 2.1516\n",
            "Train Progress: 0.105706%, train loss: 2.762312, norm: 1.2451\n",
            "Train Progress: 0.105760%, train loss: 2.669072, norm: 1.5126\n",
            "Train Progress: 0.105815%, train loss: 2.663865, norm: 2.1192\n",
            "Train Progress: 0.105869%, train loss: 2.753318, norm: 2.5728\n",
            "valid loss: 2.690211\n",
            "Train Progress: 0.105924%, train loss: 2.615702, norm: 1.4202\n",
            "Train Progress: 0.105978%, train loss: 2.728527, norm: 1.6027\n",
            "Train Progress: 0.106033%, train loss: 2.373498, norm: 2.0352\n",
            "Train Progress: 0.106088%, train loss: 2.733506, norm: 1.6822\n",
            "Train Progress: 0.106142%, train loss: 2.746327, norm: 1.7307\n",
            "valid loss: 2.693222\n",
            "Train Progress: 0.106197%, train loss: 2.819843, norm: 1.4751\n",
            "Train Progress: 0.106251%, train loss: 2.632279, norm: 2.2001\n",
            "Train Progress: 0.106306%, train loss: 2.735856, norm: 1.5213\n",
            "Train Progress: 0.106360%, train loss: 2.707703, norm: 1.4187\n",
            "Train Progress: 0.106415%, train loss: 2.688839, norm: 3.6004\n",
            "valid loss: 2.687486\n",
            "Train Progress: 0.106469%, train loss: 2.682692, norm: 1.6305\n",
            "Train Progress: 0.106524%, train loss: 2.638364, norm: 1.6082\n",
            "Train Progress: 0.106578%, train loss: 2.672663, norm: 1.8600\n",
            "Train Progress: 0.106633%, train loss: 2.732739, norm: 1.5218\n",
            "Train Progress: 0.106687%, train loss: 2.710973, norm: 1.5044\n",
            "valid loss: 2.691164\n",
            "Train Progress: 0.106742%, train loss: 2.720357, norm: 2.6650\n",
            "Train Progress: 0.106797%, train loss: 2.696828, norm: 1.6317\n",
            "Train Progress: 0.106851%, train loss: 2.717581, norm: 2.2679\n",
            "Train Progress: 0.106906%, train loss: 2.654500, norm: 2.0787\n",
            "Train Progress: 0.106960%, train loss: 2.698195, norm: 2.1543\n",
            "valid loss: 2.691963\n",
            "Train Progress: 0.107015%, train loss: 2.758117, norm: 1.2454\n",
            "Train Progress: 0.107069%, train loss: 2.648474, norm: 1.8317\n",
            "Train Progress: 0.107124%, train loss: 2.755559, norm: 1.4279\n",
            "Train Progress: 0.107178%, train loss: 2.722971, norm: 1.4611\n",
            "Train Progress: 0.107233%, train loss: 2.773820, norm: 1.3791\n",
            "valid loss: 2.692074\n",
            "Train Progress: 0.107287%, train loss: 2.634473, norm: 1.4769\n",
            "Train Progress: 0.107342%, train loss: 2.723730, norm: 1.5007\n",
            "Train Progress: 0.107396%, train loss: 2.687361, norm: 1.6056\n",
            "Train Progress: 0.107451%, train loss: 2.651787, norm: 2.0416\n",
            "Train Progress: 0.107506%, train loss: 2.682573, norm: 1.9936\n",
            "valid loss: 2.694402\n",
            "Train Progress: 0.107560%, train loss: 2.382517, norm: 1.9663\n",
            "Train Progress: 0.107615%, train loss: 2.719403, norm: 1.8625\n",
            "Train Progress: 0.107669%, train loss: 2.714857, norm: 1.7028\n",
            "Train Progress: 0.107724%, train loss: 2.675372, norm: 1.4029\n",
            "Train Progress: 0.107778%, train loss: 2.744674, norm: 1.4387\n",
            "valid loss: 2.687259\n",
            "Train Progress: 0.107833%, train loss: 2.720590, norm: 1.7922\n",
            "Train Progress: 0.107887%, train loss: 2.696962, norm: 2.3704\n",
            "Train Progress: 0.107942%, train loss: 2.680706, norm: 1.5183\n",
            "Train Progress: 0.107996%, train loss: 2.760397, norm: 2.3778\n",
            "Train Progress: 0.108051%, train loss: 2.716573, norm: 2.0669\n",
            "valid loss: 2.694345\n",
            "Train Progress: 0.108105%, train loss: 2.716255, norm: 2.0979\n",
            "Train Progress: 0.108160%, train loss: 2.691154, norm: 2.0898\n",
            "Train Progress: 0.108215%, train loss: 2.761512, norm: 1.2308\n",
            "Train Progress: 0.108269%, train loss: 2.704931, norm: 1.7010\n",
            "Train Progress: 0.108324%, train loss: 2.609694, norm: 2.1294\n",
            "valid loss: 2.695079\n",
            "Train Progress: 0.108378%, train loss: 2.754573, norm: 1.3885\n",
            "Train Progress: 0.108433%, train loss: 2.676652, norm: 1.7012\n",
            "Train Progress: 0.108487%, train loss: 2.634372, norm: 2.0263\n",
            "Train Progress: 0.108542%, train loss: 2.679111, norm: 1.6156\n",
            "Train Progress: 0.108596%, train loss: 2.726740, norm: 1.4396\n",
            "valid loss: 2.693961\n",
            "Train Progress: 0.108651%, train loss: 2.731982, norm: 1.8426\n",
            "Train Progress: 0.108705%, train loss: 2.731797, norm: 2.1985\n",
            "Train Progress: 0.108760%, train loss: 2.686374, norm: 2.7388\n",
            "Train Progress: 0.108814%, train loss: 2.622273, norm: 1.5415\n",
            "Train Progress: 0.108869%, train loss: 2.767487, norm: 2.3806\n",
            "valid loss: 2.693000\n",
            "Train Progress: 0.108924%, train loss: 2.638711, norm: 2.0917\n",
            "Train Progress: 0.108978%, train loss: 2.616375, norm: 1.3507\n",
            "Train Progress: 0.109033%, train loss: 2.744238, norm: 1.5007\n",
            "Train Progress: 0.109087%, train loss: 2.706461, norm: 1.5444\n",
            "Train Progress: 0.109142%, train loss: 2.620197, norm: 1.7583\n",
            "valid loss: 2.690670\n",
            "Train Progress: 0.109196%, train loss: 2.473134, norm: 2.6241\n",
            "Train Progress: 0.109251%, train loss: 2.787984, norm: 1.6372\n",
            "Train Progress: 0.109305%, train loss: 2.764659, norm: 2.2324\n",
            "Train Progress: 0.109360%, train loss: 2.616542, norm: 3.2127\n",
            "Train Progress: 0.109414%, train loss: 2.747477, norm: 1.6917\n",
            "valid loss: 2.690542\n",
            "Train Progress: 0.109469%, train loss: 2.723945, norm: 2.5086\n",
            "Train Progress: 0.109523%, train loss: 2.737340, norm: 1.6400\n",
            "Train Progress: 0.109578%, train loss: 2.712095, norm: 2.2467\n",
            "Train Progress: 0.109633%, train loss: 2.550015, norm: 2.3629\n",
            "Train Progress: 0.109687%, train loss: 2.691115, norm: 2.8911\n",
            "valid loss: 2.686888\n",
            "Train Progress: 0.109742%, train loss: 2.639623, norm: 2.3638\n",
            "Train Progress: 0.109796%, train loss: 2.653485, norm: 2.4765\n",
            "Train Progress: 0.109851%, train loss: 2.572601, norm: 2.1377\n",
            "Train Progress: 0.109905%, train loss: 2.653979, norm: 1.5501\n",
            "Train Progress: 0.109960%, train loss: 2.742482, norm: 1.8057\n",
            "valid loss: 2.689273\n",
            "Train Progress: 0.110014%, train loss: 2.705436, norm: 1.6189\n",
            "Train Progress: 0.110069%, train loss: 2.675627, norm: 1.9641\n",
            "Train Progress: 0.110123%, train loss: 2.742955, norm: 1.6681\n",
            "Train Progress: 0.110178%, train loss: 2.678545, norm: 1.5342\n",
            "Train Progress: 0.110232%, train loss: 2.698944, norm: 1.5000\n",
            "valid loss: 2.689642\n",
            "Train Progress: 0.110287%, train loss: 2.753872, norm: 1.2970\n",
            "Train Progress: 0.110342%, train loss: 2.577701, norm: 1.9974\n",
            "Train Progress: 0.110396%, train loss: 2.724752, norm: 1.9156\n",
            "Train Progress: 0.110451%, train loss: 2.529283, norm: 1.9183\n",
            "Train Progress: 0.110505%, train loss: 2.378099, norm: 1.9150\n",
            "valid loss: 2.692990\n",
            "Train Progress: 0.110560%, train loss: 2.766582, norm: 1.8537\n",
            "Train Progress: 0.110614%, train loss: 2.438152, norm: 2.5341\n",
            "Train Progress: 0.110669%, train loss: 2.733233, norm: 1.5098\n",
            "Train Progress: 0.110723%, train loss: 2.649824, norm: 2.0861\n",
            "Train Progress: 0.110778%, train loss: 2.742508, norm: 1.8741\n",
            "valid loss: 2.690665\n",
            "Train Progress: 0.110832%, train loss: 2.735391, norm: 1.5517\n",
            "Train Progress: 0.110887%, train loss: 2.730672, norm: 1.5064\n",
            "Train Progress: 0.110941%, train loss: 2.640405, norm: 2.1723\n",
            "Train Progress: 0.110996%, train loss: 2.674124, norm: 2.0906\n",
            "Train Progress: 0.111051%, train loss: 2.696680, norm: 2.1254\n",
            "valid loss: 2.693252\n",
            "Train Progress: 0.111105%, train loss: 2.724631, norm: 2.4223\n",
            "Train Progress: 0.111160%, train loss: 2.732278, norm: 1.4231\n",
            "Train Progress: 0.111214%, train loss: 2.581840, norm: 1.6028\n",
            "Train Progress: 0.111269%, train loss: 2.550514, norm: 2.7325\n",
            "Train Progress: 0.111323%, train loss: 2.776091, norm: 1.3712\n",
            "valid loss: 2.693998\n",
            "Train Progress: 0.111378%, train loss: 2.732424, norm: 1.4921\n",
            "Train Progress: 0.111432%, train loss: 2.690989, norm: 1.4731\n",
            "Train Progress: 0.111487%, train loss: 2.653047, norm: 1.7695\n",
            "Train Progress: 0.111541%, train loss: 2.725460, norm: 1.5924\n",
            "Train Progress: 0.111596%, train loss: 2.550057, norm: 1.8446\n",
            "valid loss: 2.695191\n",
            "Train Progress: 0.111650%, train loss: 2.724926, norm: 1.4352\n",
            "Train Progress: 0.111705%, train loss: 2.569210, norm: 2.7030\n",
            "Train Progress: 0.111760%, train loss: 2.789361, norm: 2.0371\n",
            "Train Progress: 0.111814%, train loss: 2.754146, norm: 2.1867\n",
            "Train Progress: 0.111869%, train loss: 2.725204, norm: 1.8901\n",
            "valid loss: 2.691874\n",
            "Train Progress: 0.111923%, train loss: 2.763189, norm: 1.7644\n",
            "Train Progress: 0.111978%, train loss: 2.732484, norm: 1.3877\n",
            "Train Progress: 0.112032%, train loss: 2.705752, norm: 2.3681\n",
            "Train Progress: 0.112087%, train loss: 2.692933, norm: 2.2840\n",
            "Train Progress: 0.112141%, train loss: 2.776908, norm: 1.5375\n",
            "valid loss: 2.694188\n",
            "Train Progress: 0.112196%, train loss: 2.666160, norm: 1.8196\n",
            "Train Progress: 0.112250%, train loss: 2.679012, norm: 1.5329\n",
            "Train Progress: 0.112305%, train loss: 2.787040, norm: 1.7467\n",
            "Train Progress: 0.112359%, train loss: 2.520023, norm: 2.6125\n",
            "Train Progress: 0.112414%, train loss: 2.691386, norm: 2.6268\n",
            "valid loss: 2.697402\n",
            "Train Progress: 0.112469%, train loss: 2.750423, norm: 1.9064\n",
            "Train Progress: 0.112523%, train loss: 2.703200, norm: 2.2938\n",
            "Train Progress: 0.112578%, train loss: 2.529687, norm: 1.7186\n",
            "Train Progress: 0.112632%, train loss: 2.638129, norm: 2.1117\n",
            "Train Progress: 0.112687%, train loss: 2.512595, norm: 2.3768\n",
            "valid loss: 2.697075\n",
            "Train Progress: 0.112741%, train loss: 2.657188, norm: 2.2023\n",
            "Train Progress: 0.112796%, train loss: 2.649541, norm: 2.0297\n",
            "Train Progress: 0.112850%, train loss: 2.613726, norm: 2.5894\n",
            "Train Progress: 0.112905%, train loss: 2.706800, norm: 2.3356\n",
            "Train Progress: 0.112959%, train loss: 2.662497, norm: 1.5296\n",
            "valid loss: 2.693163\n",
            "Train Progress: 0.113014%, train loss: 2.722476, norm: 1.9205\n",
            "Train Progress: 0.113068%, train loss: 2.659984, norm: 1.9126\n",
            "Train Progress: 0.113123%, train loss: 2.746525, norm: 1.5348\n",
            "Train Progress: 0.113177%, train loss: 2.634226, norm: 1.8218\n",
            "Train Progress: 0.113232%, train loss: 2.694857, norm: 2.0492\n",
            "valid loss: 2.698681\n",
            "Train Progress: 0.113287%, train loss: 2.681206, norm: 1.6309\n",
            "Train Progress: 0.113341%, train loss: 2.733134, norm: 2.3065\n",
            "Train Progress: 0.113396%, train loss: 2.803342, norm: 1.6394\n",
            "Train Progress: 0.113450%, train loss: 2.683633, norm: 1.8289\n",
            "Train Progress: 0.113505%, train loss: 2.638486, norm: 1.8455\n",
            "valid loss: 2.692957\n",
            "Train Progress: 0.113559%, train loss: 2.691739, norm: 1.7221\n",
            "Train Progress: 0.113614%, train loss: 2.673870, norm: 2.6797\n",
            "Train Progress: 0.113668%, train loss: 2.669144, norm: 2.6866\n",
            "Train Progress: 0.113723%, train loss: 2.539177, norm: 1.8147\n",
            "Train Progress: 0.113777%, train loss: 2.765843, norm: 2.3004\n",
            "valid loss: 2.694709\n",
            "Train Progress: 0.113832%, train loss: 2.770456, norm: 1.8524\n",
            "Train Progress: 0.113886%, train loss: 2.683900, norm: 2.3850\n",
            "Train Progress: 0.113941%, train loss: 2.668625, norm: 2.5003\n",
            "Train Progress: 0.113996%, train loss: 2.656547, norm: 2.1036\n",
            "Train Progress: 0.114050%, train loss: 2.646651, norm: 1.9967\n",
            "valid loss: 2.693513\n",
            "Train Progress: 0.114105%, train loss: 2.632931, norm: 1.3033\n",
            "Train Progress: 0.114159%, train loss: 2.688464, norm: 1.9614\n",
            "Train Progress: 0.114214%, train loss: 2.719384, norm: 1.4805\n",
            "Train Progress: 0.114268%, train loss: 2.597170, norm: 1.8463\n",
            "Train Progress: 0.114323%, train loss: 2.773475, norm: 1.5526\n",
            "valid loss: 2.695899\n",
            "Train Progress: 0.114377%, train loss: 2.735631, norm: 1.7134\n",
            "Train Progress: 0.114432%, train loss: 2.578490, norm: 2.2802\n",
            "Train Progress: 0.114486%, train loss: 2.692469, norm: 2.2720\n",
            "Train Progress: 0.114541%, train loss: 2.701395, norm: 2.5688\n",
            "Train Progress: 0.114595%, train loss: 2.789660, norm: 1.7473\n",
            "valid loss: 2.693312\n",
            "Train Progress: 0.114650%, train loss: 2.694539, norm: 1.3660\n",
            "Train Progress: 0.114705%, train loss: 2.689324, norm: 1.9941\n",
            "Train Progress: 0.114759%, train loss: 2.712834, norm: 2.6404\n",
            "Train Progress: 0.114814%, train loss: 2.695543, norm: 1.6120\n",
            "Train Progress: 0.114868%, train loss: 2.474752, norm: 2.2930\n",
            "valid loss: 2.699688\n",
            "Train Progress: 0.114923%, train loss: 2.733763, norm: 2.2657\n",
            "Train Progress: 0.114977%, train loss: 2.733761, norm: 2.1343\n",
            "Train Progress: 0.115032%, train loss: 2.760345, norm: 2.0907\n",
            "Train Progress: 0.115086%, train loss: 2.693385, norm: 2.6014\n",
            "Train Progress: 0.115141%, train loss: 2.747580, norm: 1.6395\n",
            "valid loss: 2.694415\n",
            "Train Progress: 0.115195%, train loss: 2.666662, norm: 2.1166\n",
            "Train Progress: 0.115250%, train loss: 2.770002, norm: 1.4066\n",
            "Train Progress: 0.115304%, train loss: 2.632727, norm: 2.7510\n",
            "Train Progress: 0.115359%, train loss: 2.669418, norm: 1.6729\n",
            "Train Progress: 0.115414%, train loss: 2.681705, norm: 2.7557\n",
            "valid loss: 2.692190\n",
            "Train Progress: 0.115468%, train loss: 2.668850, norm: 2.3062\n",
            "Train Progress: 0.115523%, train loss: 2.692662, norm: 2.4932\n",
            "Train Progress: 0.115577%, train loss: 2.625021, norm: 2.4092\n",
            "Train Progress: 0.115632%, train loss: 2.720989, norm: 2.0239\n",
            "Train Progress: 0.115686%, train loss: 2.581958, norm: 2.0943\n",
            "valid loss: 2.689225\n",
            "Train Progress: 0.115741%, train loss: 2.715363, norm: 1.8189\n",
            "Train Progress: 0.115795%, train loss: 2.719035, norm: 2.2554\n",
            "Train Progress: 0.115850%, train loss: 2.711056, norm: 1.8512\n",
            "Train Progress: 0.115904%, train loss: 2.669911, norm: 1.4414\n",
            "Train Progress: 0.115959%, train loss: 2.805436, norm: 1.6333\n",
            "valid loss: 2.692644\n",
            "Train Progress: 0.116013%, train loss: 2.660400, norm: 1.4842\n",
            "Train Progress: 0.116068%, train loss: 2.469868, norm: 2.2331\n",
            "Train Progress: 0.116123%, train loss: 2.640482, norm: 1.9469\n",
            "Train Progress: 0.116177%, train loss: 2.717258, norm: 1.6456\n",
            "Train Progress: 0.116232%, train loss: 2.713609, norm: 1.6253\n",
            "valid loss: 2.688676\n",
            "Train Progress: 0.116286%, train loss: 2.757512, norm: 1.7311\n",
            "Train Progress: 0.116341%, train loss: 2.728503, norm: 1.8383\n",
            "Train Progress: 0.116395%, train loss: 2.637418, norm: 1.4635\n",
            "Train Progress: 0.116450%, train loss: 2.692206, norm: 1.9219\n",
            "Train Progress: 0.116504%, train loss: 2.612566, norm: 2.4198\n",
            "valid loss: 2.689290\n",
            "Train Progress: 0.116559%, train loss: 2.541750, norm: 1.7435\n",
            "Train Progress: 0.116613%, train loss: 2.756105, norm: 1.6009\n",
            "Train Progress: 0.116668%, train loss: 2.729343, norm: 2.1246\n",
            "Train Progress: 0.116722%, train loss: 2.707726, norm: 1.9551\n",
            "Train Progress: 0.116777%, train loss: 2.791888, norm: 1.4517\n",
            "valid loss: 2.688442\n",
            "Train Progress: 0.116832%, train loss: 2.708503, norm: 1.8149\n",
            "Train Progress: 0.116886%, train loss: 2.700962, norm: 1.8201\n",
            "Train Progress: 0.116941%, train loss: 2.609398, norm: 2.2338\n",
            "Train Progress: 0.116995%, train loss: 2.724484, norm: 2.1014\n",
            "Train Progress: 0.117050%, train loss: 2.693078, norm: 2.0046\n",
            "valid loss: 2.692828\n",
            "Train Progress: 0.117104%, train loss: 2.722060, norm: 1.6455\n",
            "Train Progress: 0.117159%, train loss: 2.682906, norm: 2.2857\n",
            "Train Progress: 0.117213%, train loss: 2.617909, norm: 2.2751\n",
            "Train Progress: 0.117268%, train loss: 2.462965, norm: 1.9176\n",
            "Train Progress: 0.117322%, train loss: 2.753192, norm: 2.0637\n",
            "valid loss: 2.693707\n",
            "Train Progress: 0.117377%, train loss: 2.699272, norm: 1.6725\n",
            "Train Progress: 0.117431%, train loss: 2.755553, norm: 1.4215\n",
            "Train Progress: 0.117486%, train loss: 2.765672, norm: 2.3779\n",
            "Train Progress: 0.117541%, train loss: 2.717035, norm: 2.0525\n",
            "Train Progress: 0.117595%, train loss: 2.789340, norm: 1.8537\n",
            "valid loss: 2.694793\n",
            "Train Progress: 0.117650%, train loss: 2.610400, norm: 1.9851\n",
            "Train Progress: 0.117704%, train loss: 2.698883, norm: 2.1752\n",
            "Train Progress: 0.117759%, train loss: 2.755657, norm: 2.1629\n",
            "Train Progress: 0.117813%, train loss: 2.733496, norm: 1.4021\n",
            "Train Progress: 0.117868%, train loss: 2.714845, norm: 2.2190\n",
            "valid loss: 2.689541\n",
            "Train Progress: 0.117922%, train loss: 2.220777, norm: 3.7238\n",
            "Train Progress: 0.117977%, train loss: 2.771739, norm: 2.4960\n",
            "Train Progress: 0.118031%, train loss: 2.713152, norm: 1.9716\n",
            "Train Progress: 0.118086%, train loss: 2.708294, norm: 1.8945\n",
            "Train Progress: 0.118140%, train loss: 2.423014, norm: 3.1454\n",
            "valid loss: 2.689247\n",
            "Train Progress: 0.118195%, train loss: 2.706788, norm: 1.6730\n",
            "Train Progress: 0.118250%, train loss: 2.669734, norm: 2.1943\n",
            "Train Progress: 0.118304%, train loss: 2.701325, norm: 2.6712\n",
            "Train Progress: 0.118359%, train loss: 2.614939, norm: 1.6450\n",
            "Train Progress: 0.118413%, train loss: 2.182346, norm: 1.8491\n",
            "valid loss: 2.688171\n",
            "Train Progress: 0.118468%, train loss: 2.599627, norm: 2.1016\n",
            "Train Progress: 0.118522%, train loss: 2.657768, norm: 2.8509\n",
            "Train Progress: 0.118577%, train loss: 2.636275, norm: 2.6202\n",
            "Train Progress: 0.118631%, train loss: 2.646115, norm: 2.1928\n",
            "Train Progress: 0.118686%, train loss: 2.716456, norm: 2.1930\n",
            "valid loss: 2.686805\n",
            "Train Progress: 0.118740%, train loss: 2.691348, norm: 2.0018\n",
            "Train Progress: 0.118795%, train loss: 2.502284, norm: 2.7112\n",
            "Train Progress: 0.118849%, train loss: 2.684776, norm: 2.0752\n",
            "Train Progress: 0.118904%, train loss: 2.710529, norm: 1.5693\n",
            "Train Progress: 0.118959%, train loss: 2.763882, norm: 2.6622\n",
            "valid loss: 2.684418\n",
            "Train Progress: 0.119013%, train loss: 2.607449, norm: 2.4946\n",
            "Train Progress: 0.119068%, train loss: 2.697880, norm: 2.7168\n",
            "Train Progress: 0.119122%, train loss: 2.594678, norm: 2.4821\n",
            "Train Progress: 0.119177%, train loss: 2.723291, norm: 1.6053\n",
            "Train Progress: 0.119231%, train loss: 2.742670, norm: 2.3130\n",
            "valid loss: 2.686889\n",
            "Train Progress: 0.119286%, train loss: 2.707156, norm: 2.1440\n",
            "Train Progress: 0.119340%, train loss: 2.738482, norm: 1.9486\n",
            "Train Progress: 0.119395%, train loss: 2.680280, norm: 1.8858\n",
            "Train Progress: 0.119449%, train loss: 2.769303, norm: 1.9641\n",
            "Train Progress: 0.119504%, train loss: 2.738982, norm: 1.6058\n",
            "valid loss: 2.686526\n",
            "Train Progress: 0.119558%, train loss: 2.733041, norm: 1.5080\n",
            "Train Progress: 0.119613%, train loss: 2.740950, norm: 2.7336\n",
            "Train Progress: 0.119668%, train loss: 2.549196, norm: 2.3144\n",
            "Train Progress: 0.119722%, train loss: 2.665878, norm: 1.7560\n",
            "Train Progress: 0.119777%, train loss: 2.744363, norm: 1.5876\n",
            "valid loss: 2.689014\n",
            "Train Progress: 0.119831%, train loss: 2.729280, norm: 1.7657\n",
            "Train Progress: 0.119886%, train loss: 2.692671, norm: 2.3600\n",
            "Train Progress: 0.119940%, train loss: 2.715852, norm: 1.7534\n",
            "Train Progress: 0.119995%, train loss: 2.688016, norm: 1.4879\n",
            "Train Progress: 0.120049%, train loss: 2.679631, norm: 1.3294\n",
            "valid loss: 2.687945\n",
            "Train Progress: 0.120104%, train loss: 2.444955, norm: 1.6751\n",
            "Train Progress: 0.120158%, train loss: 2.699695, norm: 1.5030\n",
            "Train Progress: 0.120213%, train loss: 2.716288, norm: 1.5953\n",
            "Train Progress: 0.120267%, train loss: 2.705137, norm: 2.0561\n",
            "Train Progress: 0.120322%, train loss: 2.602401, norm: 2.3970\n",
            "valid loss: 2.689585\n",
            "Train Progress: 0.120377%, train loss: 2.692636, norm: 1.8053\n",
            "Train Progress: 0.120431%, train loss: 2.775934, norm: 2.0671\n",
            "Train Progress: 0.120486%, train loss: 2.701566, norm: 1.9573\n",
            "Train Progress: 0.120540%, train loss: 2.757150, norm: 1.6904\n",
            "Train Progress: 0.120595%, train loss: 2.630459, norm: 2.0815\n",
            "valid loss: 2.685419\n",
            "Train Progress: 0.120649%, train loss: 2.261292, norm: 1.9939\n",
            "Train Progress: 0.120704%, train loss: 2.735648, norm: 1.7645\n",
            "Train Progress: 0.120758%, train loss: 2.453639, norm: 2.3669\n",
            "Train Progress: 0.120813%, train loss: 2.552495, norm: 2.8432\n",
            "Train Progress: 0.120867%, train loss: 2.744822, norm: 1.6329\n",
            "valid loss: 2.685587\n",
            "Train Progress: 0.120922%, train loss: 2.665211, norm: 2.0115\n",
            "Train Progress: 0.120976%, train loss: 2.698632, norm: 3.2310\n",
            "Train Progress: 0.121031%, train loss: 2.786071, norm: 1.9660\n",
            "Train Progress: 0.121086%, train loss: 2.620669, norm: 2.1158\n",
            "Train Progress: 0.121140%, train loss: 2.650186, norm: 2.3428\n",
            "valid loss: 2.685199\n",
            "Train Progress: 0.121195%, train loss: 2.719995, norm: 1.5132\n",
            "Train Progress: 0.121249%, train loss: 2.736976, norm: 2.0025\n",
            "Train Progress: 0.121304%, train loss: 2.733536, norm: 2.2981\n",
            "Train Progress: 0.121358%, train loss: 2.677575, norm: 1.7212\n",
            "Train Progress: 0.121413%, train loss: 2.574896, norm: 2.1082\n",
            "valid loss: 2.687088\n",
            "Train Progress: 0.121467%, train loss: 2.661327, norm: 2.7310\n",
            "Train Progress: 0.121522%, train loss: 2.754687, norm: 1.8247\n",
            "Train Progress: 0.121576%, train loss: 2.462330, norm: 2.0040\n",
            "Train Progress: 0.121631%, train loss: 2.747049, norm: 2.7970\n",
            "Train Progress: 0.121685%, train loss: 2.772588, norm: 2.1475\n",
            "valid loss: 2.686860\n",
            "Train Progress: 0.121740%, train loss: 2.674064, norm: 2.1723\n",
            "Train Progress: 0.121795%, train loss: 2.765417, norm: 2.0338\n",
            "Train Progress: 0.121849%, train loss: 2.731972, norm: 1.5675\n",
            "Train Progress: 0.121904%, train loss: 2.668882, norm: 1.7495\n",
            "Train Progress: 0.121958%, train loss: 2.400971, norm: 2.8458\n",
            "valid loss: 2.686070\n",
            "Train Progress: 0.122013%, train loss: 2.693854, norm: 2.3979\n",
            "Train Progress: 0.122067%, train loss: 2.658636, norm: 2.5738\n",
            "Train Progress: 0.122122%, train loss: 2.694095, norm: 2.0191\n",
            "Train Progress: 0.122176%, train loss: 2.554968, norm: 2.5395\n",
            "Train Progress: 0.122231%, train loss: 2.706056, norm: 1.8549\n",
            "valid loss: 2.684505\n",
            "Train Progress: 0.122285%, train loss: 2.735144, norm: 2.3650\n",
            "Train Progress: 0.122340%, train loss: 2.735291, norm: 1.5209\n",
            "Train Progress: 0.122394%, train loss: 2.735588, norm: 2.2704\n",
            "Train Progress: 0.122449%, train loss: 2.719764, norm: 1.8561\n",
            "Train Progress: 0.122504%, train loss: 2.717326, norm: 1.9339\n",
            "valid loss: 2.686186\n",
            "Train Progress: 0.122558%, train loss: 2.721378, norm: 1.5345\n",
            "Train Progress: 0.122613%, train loss: 2.654061, norm: 2.5393\n",
            "Train Progress: 0.122667%, train loss: 2.760442, norm: 2.6210\n",
            "Train Progress: 0.122722%, train loss: 2.726358, norm: 4.4635\n",
            "Train Progress: 0.122776%, train loss: 2.608423, norm: 2.8057\n",
            "valid loss: 2.686780\n",
            "Train Progress: 0.122831%, train loss: 2.763395, norm: 2.4164\n",
            "Train Progress: 0.122885%, train loss: 2.623553, norm: 1.9364\n",
            "Train Progress: 0.122940%, train loss: 2.673699, norm: 1.6982\n",
            "Train Progress: 0.122994%, train loss: 2.507382, norm: 1.7694\n",
            "Train Progress: 0.123049%, train loss: 2.619101, norm: 2.5486\n",
            "valid loss: 2.685292\n",
            "Train Progress: 0.123103%, train loss: 2.741572, norm: 2.4696\n",
            "Train Progress: 0.123158%, train loss: 2.683552, norm: 2.2470\n",
            "Train Progress: 0.123213%, train loss: 2.519783, norm: 2.7082\n",
            "Train Progress: 0.123267%, train loss: 2.702064, norm: 2.8242\n",
            "Train Progress: 0.123322%, train loss: 2.685697, norm: 2.9313\n",
            "valid loss: 2.689973\n",
            "Train Progress: 0.123376%, train loss: 2.768157, norm: 1.9836\n",
            "Train Progress: 0.123431%, train loss: 2.763994, norm: 2.8973\n",
            "Train Progress: 0.123485%, train loss: 2.767232, norm: 1.3073\n",
            "Train Progress: 0.123540%, train loss: 2.655984, norm: 2.0871\n",
            "Train Progress: 0.123594%, train loss: 2.424222, norm: 2.0440\n",
            "valid loss: 2.690126\n",
            "Train Progress: 0.123649%, train loss: 2.732265, norm: 1.5406\n",
            "Train Progress: 0.123703%, train loss: 2.682923, norm: 2.1484\n",
            "Train Progress: 0.123758%, train loss: 2.730348, norm: 2.3393\n",
            "Train Progress: 0.123812%, train loss: 2.751644, norm: 1.8333\n",
            "Train Progress: 0.123867%, train loss: 2.721237, norm: 2.2851\n",
            "valid loss: 2.689616\n",
            "Train Progress: 0.123922%, train loss: 2.575460, norm: 2.4074\n",
            "Train Progress: 0.123976%, train loss: 2.637487, norm: 1.9940\n",
            "Train Progress: 0.124031%, train loss: 2.742929, norm: 2.1236\n",
            "Train Progress: 0.124085%, train loss: 2.725538, norm: 1.8858\n",
            "Train Progress: 0.124140%, train loss: 2.605598, norm: 2.2635\n",
            "valid loss: 2.687104\n",
            "Train Progress: 0.124194%, train loss: 2.719651, norm: 1.8370\n",
            "Train Progress: 0.124249%, train loss: 2.589581, norm: 1.7660\n",
            "Train Progress: 0.124303%, train loss: 2.592367, norm: 2.4429\n",
            "Train Progress: 0.124358%, train loss: 2.687692, norm: 2.1790\n",
            "Train Progress: 0.124412%, train loss: 2.699468, norm: 1.8238\n",
            "valid loss: 2.691433\n",
            "Train Progress: 0.124467%, train loss: 2.703071, norm: 2.1464\n",
            "Train Progress: 0.124521%, train loss: 2.723428, norm: 1.7139\n",
            "Train Progress: 0.124576%, train loss: 2.609448, norm: 1.8187\n",
            "Train Progress: 0.124631%, train loss: 2.573474, norm: 3.8537\n",
            "Train Progress: 0.124685%, train loss: 2.693652, norm: 2.3597\n",
            "valid loss: 2.690245\n",
            "Train Progress: 0.124740%, train loss: 2.776100, norm: 1.2942\n",
            "Train Progress: 0.124794%, train loss: 2.436721, norm: 3.2806\n",
            "Train Progress: 0.124849%, train loss: 2.682530, norm: 2.9118\n",
            "Train Progress: 0.124903%, train loss: 2.779445, norm: 1.6402\n",
            "Train Progress: 0.124958%, train loss: 2.659788, norm: 2.5510\n",
            "valid loss: 2.693227\n",
            "Train Progress: 0.125012%, train loss: 2.644048, norm: 3.2871\n",
            "Train Progress: 0.125067%, train loss: 2.675303, norm: 5.2677\n",
            "Train Progress: 0.125121%, train loss: 2.724889, norm: 2.8384\n",
            "Train Progress: 0.125176%, train loss: 2.778069, norm: 1.3809\n",
            "Train Progress: 0.125230%, train loss: 2.726597, norm: 2.7681\n",
            "valid loss: 2.689486\n",
            "Train Progress: 0.125285%, train loss: 2.755563, norm: 2.3741\n",
            "Train Progress: 0.125339%, train loss: 2.667646, norm: 5.1598\n",
            "Train Progress: 0.125394%, train loss: 2.758933, norm: 1.5251\n",
            "Train Progress: 0.125449%, train loss: 2.680895, norm: 1.7928\n",
            "Train Progress: 0.125503%, train loss: 2.734132, norm: 2.3618\n",
            "valid loss: 2.689638\n",
            "Train Progress: 0.125558%, train loss: 2.644348, norm: 2.6188\n",
            "Train Progress: 0.125612%, train loss: 2.786409, norm: 2.6750\n",
            "Train Progress: 0.125667%, train loss: 2.531789, norm: 2.2336\n",
            "Train Progress: 0.125721%, train loss: 2.673566, norm: 2.0412\n",
            "Train Progress: 0.125776%, train loss: 2.737991, norm: 1.7986\n",
            "valid loss: 2.689612\n",
            "Train Progress: 0.125830%, train loss: 2.739653, norm: 2.5546\n",
            "Train Progress: 0.125885%, train loss: 2.467108, norm: 2.8664\n",
            "Train Progress: 0.125939%, train loss: 2.664710, norm: 2.6322\n",
            "Train Progress: 0.125994%, train loss: 2.703171, norm: 2.3962\n",
            "Train Progress: 0.126048%, train loss: 2.750301, norm: 2.1350\n",
            "valid loss: 2.689994\n",
            "Train Progress: 0.126103%, train loss: 2.750586, norm: 2.5529\n",
            "Train Progress: 0.126158%, train loss: 2.699930, norm: 2.2597\n",
            "Train Progress: 0.126212%, train loss: 2.633343, norm: 2.7338\n",
            "Train Progress: 0.126267%, train loss: 2.707396, norm: 2.2965\n",
            "Train Progress: 0.126321%, train loss: 2.746644, norm: 1.8416\n",
            "valid loss: 2.688531\n",
            "Train Progress: 0.126376%, train loss: 2.693372, norm: 3.0198\n",
            "Train Progress: 0.126430%, train loss: 2.648023, norm: 2.1679\n",
            "Train Progress: 0.126485%, train loss: 2.706907, norm: 1.4274\n",
            "Train Progress: 0.126539%, train loss: 2.701580, norm: 1.8703\n",
            "Train Progress: 0.126594%, train loss: 2.699090, norm: 1.8158\n",
            "valid loss: 2.689577\n",
            "Train Progress: 0.126648%, train loss: 2.398411, norm: 2.3237\n",
            "Train Progress: 0.126703%, train loss: 2.500493, norm: 2.5907\n",
            "Train Progress: 0.126757%, train loss: 2.687172, norm: 2.0173\n",
            "Train Progress: 0.126812%, train loss: 2.470085, norm: 2.5246\n",
            "Train Progress: 0.126867%, train loss: 2.753547, norm: 1.6473\n",
            "valid loss: 2.692151\n",
            "Train Progress: 0.126921%, train loss: 2.578598, norm: 2.8312\n",
            "Train Progress: 0.126976%, train loss: 2.618038, norm: 2.9421\n",
            "Train Progress: 0.127030%, train loss: 2.683421, norm: 2.7058\n",
            "Train Progress: 0.127085%, train loss: 2.699214, norm: 2.1460\n",
            "Train Progress: 0.127139%, train loss: 2.642951, norm: 1.9231\n",
            "valid loss: 2.691407\n",
            "Train Progress: 0.127194%, train loss: 2.746328, norm: 1.6701\n",
            "Train Progress: 0.127248%, train loss: 2.574162, norm: 2.4107\n",
            "Train Progress: 0.127303%, train loss: 2.712616, norm: 2.2428\n",
            "Train Progress: 0.127357%, train loss: 2.622608, norm: 2.0438\n",
            "Train Progress: 0.127412%, train loss: 2.417833, norm: 3.2638\n",
            "valid loss: 2.690997\n",
            "Train Progress: 0.127466%, train loss: 2.667936, norm: 2.0213\n",
            "Train Progress: 0.127521%, train loss: 2.665020, norm: 2.7597\n",
            "Train Progress: 0.127576%, train loss: 2.672668, norm: 1.9981\n",
            "Train Progress: 0.127630%, train loss: 2.786226, norm: 1.6172\n",
            "Train Progress: 0.127685%, train loss: 2.767502, norm: 1.5360\n",
            "valid loss: 2.690695\n",
            "Train Progress: 0.127739%, train loss: 2.763006, norm: 1.6605\n",
            "Train Progress: 0.127794%, train loss: 2.661066, norm: 1.8562\n",
            "Train Progress: 0.127848%, train loss: 2.725835, norm: 1.9981\n",
            "Train Progress: 0.127903%, train loss: 2.694399, norm: 2.9705\n",
            "Train Progress: 0.127957%, train loss: 2.647653, norm: 2.4517\n",
            "valid loss: 2.697500\n",
            "Train Progress: 0.128012%, train loss: 2.755550, norm: 2.5770\n",
            "Train Progress: 0.128066%, train loss: 2.700687, norm: 2.7151\n",
            "Train Progress: 0.128121%, train loss: 2.681250, norm: 2.5907\n",
            "Train Progress: 0.128175%, train loss: 2.751208, norm: 1.8036\n",
            "Train Progress: 0.128230%, train loss: 2.751326, norm: 1.8311\n",
            "valid loss: 2.692317\n",
            "Train Progress: 0.128285%, train loss: 2.676709, norm: 1.8788\n",
            "Train Progress: 0.128339%, train loss: 2.638523, norm: 1.5117\n",
            "Train Progress: 0.128394%, train loss: 2.739568, norm: 1.8228\n",
            "Train Progress: 0.128448%, train loss: 2.735040, norm: 2.0672\n",
            "Train Progress: 0.128503%, train loss: 2.689506, norm: 2.5324\n",
            "valid loss: 2.691876\n",
            "Train Progress: 0.128557%, train loss: 2.727534, norm: 2.0981\n",
            "Train Progress: 0.128612%, train loss: 2.743686, norm: 2.6545\n",
            "Train Progress: 0.128666%, train loss: 2.787332, norm: 3.0358\n",
            "Train Progress: 0.128721%, train loss: 2.700743, norm: 1.7828\n",
            "Train Progress: 0.128775%, train loss: 2.735377, norm: 2.2544\n",
            "valid loss: 2.684897\n",
            "Train Progress: 0.128830%, train loss: 2.768255, norm: 2.5229\n",
            "Train Progress: 0.128884%, train loss: 2.626526, norm: 2.2245\n",
            "Train Progress: 0.128939%, train loss: 2.771757, norm: 1.8116\n",
            "Train Progress: 0.128994%, train loss: 2.618976, norm: 2.6483\n",
            "Train Progress: 0.129048%, train loss: 2.695811, norm: 1.7875\n",
            "valid loss: 2.684595\n",
            "Train Progress: 0.129103%, train loss: 2.637602, norm: 1.9285\n",
            "Train Progress: 0.129157%, train loss: 2.559169, norm: 2.6439\n",
            "Train Progress: 0.129212%, train loss: 2.729666, norm: 2.4123\n",
            "Train Progress: 0.129266%, train loss: 2.701961, norm: 2.3031\n",
            "Train Progress: 0.129321%, train loss: 2.545444, norm: 2.0306\n",
            "valid loss: 2.684331\n",
            "Train Progress: 0.129375%, train loss: 2.630874, norm: 2.0504\n",
            "Train Progress: 0.129430%, train loss: 2.726080, norm: 1.5843\n",
            "Train Progress: 0.129484%, train loss: 2.701144, norm: 2.3676\n",
            "Train Progress: 0.129539%, train loss: 2.591225, norm: 2.2108\n",
            "Train Progress: 0.129593%, train loss: 2.742872, norm: 2.4823\n",
            "valid loss: 2.689851\n",
            "Train Progress: 0.129648%, train loss: 2.741137, norm: 2.2503\n",
            "Train Progress: 0.129703%, train loss: 2.717641, norm: 2.7260\n",
            "Train Progress: 0.129757%, train loss: 2.681966, norm: 2.3551\n",
            "Train Progress: 0.129812%, train loss: 2.644251, norm: 2.1185\n",
            "Train Progress: 0.129866%, train loss: 2.705515, norm: 2.8683\n",
            "valid loss: 2.704136\n",
            "Train Progress: 0.129921%, train loss: 2.748718, norm: 3.2245\n",
            "Train Progress: 0.129975%, train loss: 2.753759, norm: 2.0992\n",
            "Train Progress: 0.130030%, train loss: 2.738821, norm: 2.8877\n",
            "Train Progress: 0.130084%, train loss: 2.604926, norm: 2.2683\n",
            "Train Progress: 0.130139%, train loss: 2.647862, norm: 2.5672\n",
            "valid loss: 2.687574\n",
            "Train Progress: 0.130193%, train loss: 2.708793, norm: 2.0804\n",
            "Train Progress: 0.130248%, train loss: 2.658660, norm: 1.4127\n",
            "Train Progress: 0.130302%, train loss: 2.668642, norm: 2.1483\n",
            "Train Progress: 0.130357%, train loss: 2.653216, norm: 2.5848\n",
            "Train Progress: 0.130412%, train loss: 2.775509, norm: 2.4589\n",
            "valid loss: 2.695379\n",
            "Train Progress: 0.130466%, train loss: 2.460772, norm: 2.7396\n",
            "Train Progress: 0.130521%, train loss: 2.512499, norm: 2.2381\n",
            "Train Progress: 0.130575%, train loss: 2.751476, norm: 2.1501\n",
            "Train Progress: 0.130630%, train loss: 2.691815, norm: 2.1008\n",
            "Train Progress: 0.130684%, train loss: 2.632748, norm: 2.2878\n",
            "valid loss: 2.689541\n",
            "Train Progress: 0.130739%, train loss: 2.722986, norm: 2.2818\n",
            "Train Progress: 0.130793%, train loss: 2.463388, norm: 2.6196\n",
            "Train Progress: 0.130848%, train loss: 2.717031, norm: 2.8486\n",
            "Train Progress: 0.130902%, train loss: 2.557251, norm: 2.0499\n",
            "Train Progress: 0.130957%, train loss: 2.730241, norm: 2.0952\n",
            "valid loss: 2.692863\n",
            "Train Progress: 0.131011%, train loss: 2.731390, norm: 2.0897\n",
            "Train Progress: 0.131066%, train loss: 2.672807, norm: 2.6787\n",
            "Train Progress: 0.131121%, train loss: 2.702750, norm: 2.3007\n",
            "Train Progress: 0.131175%, train loss: 2.553049, norm: 2.9453\n",
            "Train Progress: 0.131230%, train loss: 2.722642, norm: 2.2302\n",
            "valid loss: 2.691447\n",
            "Train Progress: 0.131284%, train loss: 2.749716, norm: 1.9090\n",
            "Train Progress: 0.131339%, train loss: 2.767289, norm: 1.6114\n",
            "Train Progress: 0.131393%, train loss: 2.698656, norm: 1.9748\n",
            "Train Progress: 0.131448%, train loss: 2.732112, norm: 1.4107\n",
            "Train Progress: 0.131502%, train loss: 2.707600, norm: 1.9393\n",
            "valid loss: 2.691230\n",
            "Train Progress: 0.131557%, train loss: 2.758997, norm: 2.0742\n",
            "Train Progress: 0.131611%, train loss: 2.571244, norm: 3.2961\n",
            "Train Progress: 0.131666%, train loss: 2.668648, norm: 1.9769\n",
            "Train Progress: 0.131720%, train loss: 2.646332, norm: 2.3230\n",
            "Train Progress: 0.131775%, train loss: 2.722458, norm: 2.7084\n",
            "valid loss: 2.690122\n",
            "Train Progress: 0.131830%, train loss: 2.703607, norm: 2.8784\n",
            "Train Progress: 0.131884%, train loss: 2.757201, norm: 2.8647\n",
            "Train Progress: 0.131939%, train loss: 2.756659, norm: 2.0262\n",
            "Train Progress: 0.131993%, train loss: 2.719503, norm: 2.3771\n",
            "Train Progress: 0.132048%, train loss: 2.558452, norm: 2.5437\n",
            "valid loss: 2.688136\n",
            "Train Progress: 0.132102%, train loss: 2.703672, norm: 1.3963\n",
            "Train Progress: 0.132157%, train loss: 2.617861, norm: 1.7079\n",
            "Train Progress: 0.132211%, train loss: 2.707396, norm: 2.2744\n",
            "Train Progress: 0.132266%, train loss: 2.702288, norm: 2.3453\n",
            "Train Progress: 0.132320%, train loss: 2.595021, norm: 2.2051\n",
            "valid loss: 2.688795\n",
            "Train Progress: 0.132375%, train loss: 2.529340, norm: 3.9785\n",
            "Train Progress: 0.132429%, train loss: 2.523896, norm: 2.0699\n",
            "Train Progress: 0.132484%, train loss: 2.259965, norm: 2.2108\n",
            "Train Progress: 0.132539%, train loss: 2.747419, norm: 2.3270\n",
            "Train Progress: 0.132593%, train loss: 2.719197, norm: 2.0666\n",
            "valid loss: 2.685597\n",
            "Train Progress: 0.132648%, train loss: 2.662931, norm: 3.0141\n",
            "Train Progress: 0.132702%, train loss: 2.590144, norm: 3.0880\n",
            "Train Progress: 0.132757%, train loss: 2.747488, norm: 1.6500\n",
            "Train Progress: 0.132811%, train loss: 2.672669, norm: 3.4873\n",
            "Train Progress: 0.132866%, train loss: 2.442626, norm: 2.0591\n",
            "valid loss: 2.686150\n",
            "Train Progress: 0.132920%, train loss: 2.371429, norm: 3.6926\n",
            "Train Progress: 0.132975%, train loss: 2.721151, norm: 1.6552\n",
            "Train Progress: 0.133029%, train loss: 2.726671, norm: 1.7525\n",
            "Train Progress: 0.133084%, train loss: 2.524137, norm: 2.3654\n",
            "Train Progress: 0.133138%, train loss: 2.406824, norm: 3.0807\n",
            "valid loss: 2.684047\n",
            "Train Progress: 0.133193%, train loss: 2.678008, norm: 1.8285\n",
            "Train Progress: 0.133248%, train loss: 2.614441, norm: 2.1512\n",
            "Train Progress: 0.133302%, train loss: 2.720314, norm: 1.8464\n",
            "Train Progress: 0.133357%, train loss: 2.695199, norm: 2.4346\n",
            "Train Progress: 0.133411%, train loss: 2.669269, norm: 2.8450\n",
            "valid loss: 2.685184\n",
            "Train Progress: 0.133466%, train loss: 2.711459, norm: 2.1392\n",
            "Train Progress: 0.133520%, train loss: 2.673624, norm: 2.7988\n",
            "Train Progress: 0.133575%, train loss: 2.656243, norm: 2.9933\n",
            "Train Progress: 0.133629%, train loss: 2.769114, norm: 2.0963\n",
            "Train Progress: 0.133684%, train loss: 2.759447, norm: 2.2070\n",
            "valid loss: 2.683248\n",
            "Train Progress: 0.133738%, train loss: 2.601939, norm: 2.8632\n",
            "Train Progress: 0.133793%, train loss: 2.474031, norm: 3.6642\n",
            "Train Progress: 0.133847%, train loss: 2.702047, norm: 1.8091\n",
            "Train Progress: 0.133902%, train loss: 2.665537, norm: 2.3465\n",
            "Train Progress: 0.133957%, train loss: 2.701581, norm: 1.9458\n",
            "valid loss: 2.683131\n",
            "Train Progress: 0.134011%, train loss: 2.746448, norm: 1.9113\n",
            "Train Progress: 0.134066%, train loss: 2.680430, norm: 1.5989\n",
            "Train Progress: 0.134120%, train loss: 2.691080, norm: 2.3807\n",
            "Train Progress: 0.134175%, train loss: 2.685750, norm: 2.2080\n",
            "Train Progress: 0.134229%, train loss: 2.664496, norm: 2.8976\n",
            "valid loss: 2.687256\n",
            "Train Progress: 0.134284%, train loss: 2.711688, norm: 3.5066\n",
            "Train Progress: 0.134338%, train loss: 2.665910, norm: 2.6935\n",
            "Train Progress: 0.134393%, train loss: 2.502573, norm: 2.6934\n",
            "Train Progress: 0.134447%, train loss: 2.741178, norm: 1.7794\n",
            "Train Progress: 0.134502%, train loss: 2.262886, norm: 3.0834\n",
            "valid loss: 2.682777\n",
            "Train Progress: 0.134556%, train loss: 2.669316, norm: 2.0219\n",
            "Train Progress: 0.134611%, train loss: 2.477556, norm: 1.2958\n",
            "Train Progress: 0.134666%, train loss: 2.703463, norm: 3.0626\n",
            "Train Progress: 0.134720%, train loss: 2.599190, norm: 3.6118\n",
            "Train Progress: 0.134775%, train loss: 2.694165, norm: 2.2010\n",
            "valid loss: 2.685090\n",
            "Train Progress: 0.134829%, train loss: 2.608161, norm: 1.6490\n",
            "Train Progress: 0.134884%, train loss: 2.740144, norm: 1.9823\n",
            "Train Progress: 0.134938%, train loss: 2.759831, norm: 1.8982\n",
            "Train Progress: 0.134993%, train loss: 2.688135, norm: 2.3946\n",
            "Train Progress: 0.135047%, train loss: 2.679618, norm: 1.5635\n",
            "valid loss: 2.684132\n",
            "Train Progress: 0.135102%, train loss: 2.622341, norm: 2.1289\n",
            "Train Progress: 0.135156%, train loss: 2.693609, norm: 1.6303\n",
            "Train Progress: 0.135211%, train loss: 2.733971, norm: 1.7898\n",
            "Train Progress: 0.135265%, train loss: 2.676162, norm: 2.1470\n",
            "Train Progress: 0.135320%, train loss: 2.713878, norm: 1.7591\n",
            "valid loss: 2.680879\n",
            "Train Progress: 0.135375%, train loss: 2.649797, norm: 2.8952\n",
            "Train Progress: 0.135429%, train loss: 2.690795, norm: 1.9311\n",
            "Train Progress: 0.135484%, train loss: 2.751218, norm: 2.6002\n",
            "Train Progress: 0.135538%, train loss: 2.755706, norm: 3.4427\n",
            "Train Progress: 0.135593%, train loss: 2.591940, norm: 2.6147\n",
            "valid loss: 2.684613\n",
            "Train Progress: 0.135647%, train loss: 2.673653, norm: 2.0415\n",
            "Train Progress: 0.135702%, train loss: 2.707163, norm: 2.1321\n",
            "Train Progress: 0.135756%, train loss: 2.638488, norm: 2.3567\n",
            "Train Progress: 0.135811%, train loss: 2.665999, norm: 2.5636\n",
            "Train Progress: 0.135865%, train loss: 2.743634, norm: 2.4842\n",
            "valid loss: 2.681769\n",
            "Train Progress: 0.135920%, train loss: 2.754599, norm: 3.6013\n",
            "Train Progress: 0.135974%, train loss: 2.729262, norm: 2.1970\n",
            "Train Progress: 0.136029%, train loss: 2.630904, norm: 2.8433\n",
            "Train Progress: 0.136084%, train loss: 2.677181, norm: 1.9340\n",
            "Train Progress: 0.136138%, train loss: 2.719288, norm: 2.5613\n",
            "valid loss: 2.680743\n",
            "Train Progress: 0.136193%, train loss: 2.722270, norm: 1.8320\n",
            "Train Progress: 0.136247%, train loss: 2.644577, norm: 2.2557\n",
            "Train Progress: 0.136302%, train loss: 2.704110, norm: 1.6475\n",
            "Train Progress: 0.136356%, train loss: 2.749819, norm: 1.9602\n",
            "Train Progress: 0.136411%, train loss: 2.519549, norm: 2.1812\n",
            "valid loss: 2.684603\n",
            "Train Progress: 0.136465%, train loss: 2.592834, norm: 2.4363\n",
            "Train Progress: 0.136520%, train loss: 2.709074, norm: 2.0290\n",
            "Train Progress: 0.136574%, train loss: 2.681169, norm: 1.9559\n",
            "Train Progress: 0.136629%, train loss: 2.635791, norm: 1.8633\n",
            "Train Progress: 0.136683%, train loss: 2.654719, norm: 2.2289\n",
            "valid loss: 2.679885\n",
            "Train Progress: 0.136738%, train loss: 2.615408, norm: 2.1079\n",
            "Train Progress: 0.136793%, train loss: 2.706886, norm: 2.4448\n",
            "Train Progress: 0.136847%, train loss: 2.600826, norm: 2.3150\n",
            "Train Progress: 0.136902%, train loss: 2.756927, norm: 1.8806\n",
            "Train Progress: 0.136956%, train loss: 2.803809, norm: 1.9911\n",
            "valid loss: 2.681444\n",
            "Train Progress: 0.137011%, train loss: 2.763566, norm: 1.7358\n",
            "Train Progress: 0.137065%, train loss: 2.689901, norm: 2.4909\n",
            "Train Progress: 0.137120%, train loss: 2.688500, norm: 2.3370\n",
            "Train Progress: 0.137174%, train loss: 2.687546, norm: 2.2138\n",
            "Train Progress: 0.137229%, train loss: 2.662095, norm: 1.9716\n",
            "valid loss: 2.684919\n",
            "Train Progress: 0.137283%, train loss: 2.671580, norm: 1.9714\n",
            "Train Progress: 0.137338%, train loss: 2.685791, norm: 4.6300\n",
            "Train Progress: 0.137392%, train loss: 2.736580, norm: 3.0251\n",
            "Train Progress: 0.137447%, train loss: 2.752400, norm: 3.0973\n",
            "Train Progress: 0.137501%, train loss: 2.641029, norm: 4.1384\n",
            "valid loss: 2.688272\n",
            "Train Progress: 0.137556%, train loss: 2.633447, norm: 3.4858\n",
            "Train Progress: 0.137611%, train loss: 2.706151, norm: 2.9386\n",
            "Train Progress: 0.137665%, train loss: 2.697708, norm: 2.5813\n",
            "Train Progress: 0.137720%, train loss: 2.587332, norm: 2.3039\n",
            "Train Progress: 0.137774%, train loss: 2.718206, norm: 2.1081\n",
            "valid loss: 2.682679\n",
            "Train Progress: 0.137829%, train loss: 2.599091, norm: 2.8401\n",
            "Train Progress: 0.137883%, train loss: 2.663107, norm: 2.1905\n",
            "Train Progress: 0.137938%, train loss: 2.437442, norm: 2.2356\n",
            "Train Progress: 0.137992%, train loss: 2.752688, norm: 1.8442\n",
            "Train Progress: 0.138047%, train loss: 2.705213, norm: 2.0601\n",
            "valid loss: 2.689074\n",
            "Train Progress: 0.138101%, train loss: 2.682162, norm: 1.9369\n",
            "Train Progress: 0.138156%, train loss: 2.711541, norm: 2.4834\n",
            "Train Progress: 0.138210%, train loss: 2.591629, norm: 4.1362\n",
            "Train Progress: 0.138265%, train loss: 2.688634, norm: 1.9235\n",
            "Train Progress: 0.138320%, train loss: 2.666770, norm: 1.6176\n",
            "valid loss: 2.684682\n",
            "Train Progress: 0.138374%, train loss: 2.725785, norm: 2.4817\n",
            "Train Progress: 0.138429%, train loss: 2.687746, norm: 2.3322\n",
            "Train Progress: 0.138483%, train loss: 2.719907, norm: 2.2381\n",
            "Train Progress: 0.138538%, train loss: 2.743473, norm: 2.4209\n",
            "Train Progress: 0.138592%, train loss: 2.743838, norm: 2.2417\n",
            "valid loss: 2.688462\n",
            "Train Progress: 0.138647%, train loss: 2.762187, norm: 2.1322\n",
            "Train Progress: 0.138701%, train loss: 2.731652, norm: 3.1669\n",
            "Train Progress: 0.138756%, train loss: 2.587980, norm: 2.8791\n",
            "Train Progress: 0.138810%, train loss: 2.769744, norm: 2.4377\n",
            "Train Progress: 0.138865%, train loss: 2.447661, norm: 2.9162\n",
            "valid loss: 2.685612\n",
            "Train Progress: 0.138919%, train loss: 2.680594, norm: 3.1261\n",
            "Train Progress: 0.138974%, train loss: 2.700396, norm: 2.3130\n",
            "Train Progress: 0.139029%, train loss: 2.724343, norm: 2.2622\n",
            "Train Progress: 0.139083%, train loss: 2.651507, norm: 3.9280\n",
            "Train Progress: 0.139138%, train loss: 2.709594, norm: 1.5964\n",
            "valid loss: 2.685741\n",
            "Train Progress: 0.139192%, train loss: 2.641505, norm: 2.6415\n",
            "Train Progress: 0.139247%, train loss: 2.558596, norm: 4.4423\n",
            "Train Progress: 0.139301%, train loss: 2.626117, norm: 2.1014\n",
            "Train Progress: 0.139356%, train loss: 2.619302, norm: 2.1011\n",
            "Train Progress: 0.139410%, train loss: 2.690767, norm: 2.1301\n",
            "valid loss: 2.686702\n",
            "Train Progress: 0.139465%, train loss: 2.367828, norm: 2.3756\n",
            "Train Progress: 0.139519%, train loss: 2.695952, norm: 2.1778\n",
            "Train Progress: 0.139574%, train loss: 2.690196, norm: 3.9730\n",
            "Train Progress: 0.139628%, train loss: 2.782803, norm: 2.8302\n",
            "Train Progress: 0.139683%, train loss: 2.665877, norm: 3.1204\n",
            "valid loss: 2.696644\n",
            "Train Progress: 0.139738%, train loss: 2.582471, norm: 2.7336\n",
            "Train Progress: 0.139792%, train loss: 2.689062, norm: 2.9200\n",
            "Train Progress: 0.139847%, train loss: 2.662151, norm: 2.9503\n",
            "Train Progress: 0.139901%, train loss: 2.729346, norm: 2.0471\n",
            "Train Progress: 0.139956%, train loss: 2.565151, norm: 3.3903\n",
            "valid loss: 2.686827\n",
            "Train Progress: 0.140010%, train loss: 2.774366, norm: 1.7421\n",
            "Train Progress: 0.140065%, train loss: 2.733991, norm: 2.5307\n",
            "Train Progress: 0.140119%, train loss: 2.732869, norm: 2.4146\n",
            "Train Progress: 0.140174%, train loss: 2.645468, norm: 2.4180\n",
            "Train Progress: 0.140228%, train loss: 2.722848, norm: 2.9799\n",
            "valid loss: 2.689534\n",
            "Train Progress: 0.140283%, train loss: 2.667426, norm: 1.7550\n",
            "Train Progress: 0.140337%, train loss: 2.740422, norm: 2.0887\n",
            "Train Progress: 0.140392%, train loss: 2.734085, norm: 2.3610\n",
            "Train Progress: 0.140447%, train loss: 2.652435, norm: 1.6875\n",
            "Train Progress: 0.140501%, train loss: 2.635210, norm: 4.1991\n",
            "valid loss: 2.685785\n",
            "Train Progress: 0.140556%, train loss: 2.598615, norm: 2.0702\n",
            "Train Progress: 0.140610%, train loss: 2.721104, norm: 3.2038\n",
            "Train Progress: 0.140665%, train loss: 2.437576, norm: 3.1237\n",
            "Train Progress: 0.140719%, train loss: 2.598543, norm: 2.5181\n",
            "Train Progress: 0.140774%, train loss: 2.677835, norm: 3.1149\n",
            "valid loss: 2.689522\n",
            "Train Progress: 0.140828%, train loss: 2.705349, norm: 3.2691\n",
            "Train Progress: 0.140883%, train loss: 2.387677, norm: 3.0584\n",
            "Train Progress: 0.140937%, train loss: 2.491693, norm: 2.7531\n",
            "Train Progress: 0.140992%, train loss: 2.710206, norm: 2.9674\n",
            "Train Progress: 0.141046%, train loss: 2.651039, norm: 2.6869\n",
            "valid loss: 2.684538\n",
            "Train Progress: 0.141101%, train loss: 2.745116, norm: 3.2695\n",
            "Train Progress: 0.141156%, train loss: 2.593892, norm: 2.5691\n",
            "Train Progress: 0.141210%, train loss: 2.756534, norm: 2.6087\n",
            "Train Progress: 0.141265%, train loss: 2.662137, norm: 3.1186\n",
            "Train Progress: 0.141319%, train loss: 2.629826, norm: 2.3550\n",
            "valid loss: 2.684304\n",
            "Train Progress: 0.141374%, train loss: 2.709629, norm: 2.5543\n",
            "Train Progress: 0.141428%, train loss: 2.442730, norm: 2.1940\n",
            "Train Progress: 0.141483%, train loss: 2.615865, norm: 2.7964\n",
            "Train Progress: 0.141537%, train loss: 2.598169, norm: 2.0211\n",
            "Train Progress: 0.141592%, train loss: 2.134039, norm: 4.3259\n",
            "valid loss: 2.679438\n",
            "Train Progress: 0.141646%, train loss: 2.643834, norm: 1.8507\n",
            "Train Progress: 0.141701%, train loss: 2.650925, norm: 1.9091\n",
            "Train Progress: 0.141755%, train loss: 2.614638, norm: 2.4260\n",
            "Train Progress: 0.141810%, train loss: 2.611435, norm: 4.0984\n",
            "Train Progress: 0.141865%, train loss: 2.664910, norm: 3.0328\n",
            "valid loss: 2.674829\n",
            "Train Progress: 0.141919%, train loss: 2.714817, norm: 2.5540\n",
            "Train Progress: 0.141974%, train loss: 2.731323, norm: 1.9452\n",
            "Train Progress: 0.142028%, train loss: 2.649369, norm: 1.8887\n",
            "Train Progress: 0.142083%, train loss: 2.656482, norm: 2.3058\n",
            "Train Progress: 0.142137%, train loss: 2.659768, norm: 2.3336\n",
            "valid loss: 2.675255\n",
            "Train Progress: 0.142192%, train loss: 2.597688, norm: 2.1817\n",
            "Train Progress: 0.142246%, train loss: 2.595698, norm: 2.2857\n",
            "Train Progress: 0.142301%, train loss: 2.685221, norm: 2.0014\n",
            "Train Progress: 0.142355%, train loss: 2.433668, norm: 2.3971\n",
            "Train Progress: 0.142410%, train loss: 2.749448, norm: 1.8903\n",
            "valid loss: 2.673873\n",
            "Train Progress: 0.142464%, train loss: 2.467190, norm: 2.3269\n",
            "Train Progress: 0.142519%, train loss: 2.575216, norm: 2.9655\n",
            "Train Progress: 0.142574%, train loss: 2.711665, norm: 2.2238\n",
            "Train Progress: 0.142628%, train loss: 2.626655, norm: 2.2114\n",
            "Train Progress: 0.142683%, train loss: 2.661911, norm: 2.2901\n",
            "valid loss: 2.681868\n",
            "Train Progress: 0.142737%, train loss: 2.728724, norm: 1.9308\n",
            "Train Progress: 0.142792%, train loss: 2.620663, norm: 2.6063\n",
            "Train Progress: 0.142846%, train loss: 2.690732, norm: 2.4003\n",
            "Train Progress: 0.142901%, train loss: 2.670369, norm: 1.7723\n",
            "Train Progress: 0.142955%, train loss: 2.756039, norm: 1.8423\n",
            "valid loss: 2.679181\n",
            "Train Progress: 0.143010%, train loss: 2.681045, norm: 2.5301\n",
            "Train Progress: 0.143064%, train loss: 2.785596, norm: 2.7064\n",
            "Train Progress: 0.143119%, train loss: 2.726798, norm: 2.1187\n",
            "Train Progress: 0.143173%, train loss: 2.679865, norm: 1.9317\n",
            "Train Progress: 0.143228%, train loss: 2.711154, norm: 2.0527\n",
            "valid loss: 2.675965\n",
            "Train Progress: 0.143283%, train loss: 2.746325, norm: 2.4217\n",
            "Train Progress: 0.143337%, train loss: 2.734349, norm: 1.7505\n",
            "Train Progress: 0.143392%, train loss: 2.776634, norm: 1.4926\n",
            "Train Progress: 0.143446%, train loss: 2.742457, norm: 2.3697\n",
            "Train Progress: 0.143501%, train loss: 2.652181, norm: 1.8733\n",
            "valid loss: 2.677917\n",
            "Train Progress: 0.143555%, train loss: 2.698979, norm: 2.6881\n",
            "Train Progress: 0.143610%, train loss: 2.636895, norm: 2.2154\n",
            "Train Progress: 0.143664%, train loss: 2.661664, norm: 2.1204\n",
            "Train Progress: 0.143719%, train loss: 2.748794, norm: 2.2269\n",
            "Train Progress: 0.143773%, train loss: 2.703752, norm: 2.3042\n",
            "valid loss: 2.671111\n",
            "Train Progress: 0.143828%, train loss: 2.692640, norm: 2.1010\n",
            "Train Progress: 0.143882%, train loss: 2.702304, norm: 2.2516\n",
            "Train Progress: 0.143937%, train loss: 2.657990, norm: 2.0589\n",
            "Train Progress: 0.143992%, train loss: 2.655223, norm: 2.5111\n",
            "Train Progress: 0.144046%, train loss: 2.674436, norm: 2.3852\n",
            "valid loss: 2.674660\n",
            "Train Progress: 0.144101%, train loss: 2.735846, norm: 3.1701\n",
            "Train Progress: 0.144155%, train loss: 2.660136, norm: 2.1177\n",
            "Train Progress: 0.144210%, train loss: 2.601774, norm: 2.5974\n",
            "Train Progress: 0.144264%, train loss: 2.688102, norm: 2.3884\n",
            "Train Progress: 0.144319%, train loss: 2.761879, norm: 2.1462\n",
            "valid loss: 2.673556\n",
            "Train Progress: 0.144373%, train loss: 2.677861, norm: 2.0766\n",
            "Train Progress: 0.144428%, train loss: 2.744358, norm: 2.2141\n",
            "Train Progress: 0.144482%, train loss: 2.747423, norm: 2.0312\n",
            "Train Progress: 0.144537%, train loss: 2.734726, norm: 2.5255\n",
            "Train Progress: 0.144591%, train loss: 2.675372, norm: 2.6930\n",
            "valid loss: 2.672490\n",
            "Train Progress: 0.144646%, train loss: 2.648333, norm: 2.9986\n",
            "Train Progress: 0.144701%, train loss: 2.653970, norm: 2.0607\n",
            "Train Progress: 0.144755%, train loss: 2.479089, norm: 2.8148\n",
            "Train Progress: 0.144810%, train loss: 2.667167, norm: 2.5085\n",
            "Train Progress: 0.144864%, train loss: 2.613597, norm: 2.5732\n",
            "valid loss: 2.675086\n",
            "Train Progress: 0.144919%, train loss: 2.755910, norm: 1.9837\n",
            "Train Progress: 0.144973%, train loss: 2.724795, norm: 2.4549\n",
            "Train Progress: 0.145028%, train loss: 2.640736, norm: 2.5836\n",
            "Train Progress: 0.145082%, train loss: 2.299181, norm: 2.7630\n",
            "Train Progress: 0.145137%, train loss: 2.746461, norm: 3.2963\n",
            "valid loss: 2.679063\n",
            "Train Progress: 0.145191%, train loss: 2.760326, norm: 1.8060\n",
            "Train Progress: 0.145246%, train loss: 2.622962, norm: 3.0878\n",
            "Train Progress: 0.145300%, train loss: 2.667414, norm: 2.6645\n",
            "Train Progress: 0.145355%, train loss: 2.720408, norm: 2.5128\n",
            "Train Progress: 0.145410%, train loss: 2.546630, norm: 1.8792\n",
            "valid loss: 2.676513\n",
            "Train Progress: 0.145464%, train loss: 2.747524, norm: 2.8571\n",
            "Train Progress: 0.145519%, train loss: 2.527844, norm: 2.5280\n",
            "Train Progress: 0.145573%, train loss: 2.717375, norm: 2.6144\n",
            "Train Progress: 0.145628%, train loss: 2.776240, norm: 2.3046\n",
            "Train Progress: 0.145682%, train loss: 2.695456, norm: 2.7267\n",
            "valid loss: 2.679127\n",
            "Train Progress: 0.145737%, train loss: 2.763637, norm: 2.2333\n",
            "Train Progress: 0.145791%, train loss: 2.560140, norm: 2.2731\n",
            "Train Progress: 0.145846%, train loss: 2.597251, norm: 2.9006\n",
            "Train Progress: 0.145900%, train loss: 2.681958, norm: 2.2479\n",
            "Train Progress: 0.145955%, train loss: 2.577842, norm: 2.4332\n",
            "valid loss: 2.678237\n",
            "Train Progress: 0.146009%, train loss: 2.683207, norm: 2.4674\n",
            "Train Progress: 0.146064%, train loss: 2.691580, norm: 2.6021\n",
            "Train Progress: 0.146119%, train loss: 2.735990, norm: 2.9323\n",
            "Train Progress: 0.146173%, train loss: 2.688575, norm: 2.3319\n",
            "Train Progress: 0.146228%, train loss: 2.696535, norm: 3.3053\n",
            "valid loss: 2.679027\n",
            "Train Progress: 0.146282%, train loss: 2.654113, norm: 2.0292\n",
            "Train Progress: 0.146337%, train loss: 2.672776, norm: 2.0954\n",
            "Train Progress: 0.146391%, train loss: 2.678143, norm: 2.8221\n",
            "Train Progress: 0.146446%, train loss: 2.761929, norm: 2.4881\n",
            "Train Progress: 0.146500%, train loss: 2.712849, norm: 2.6653\n",
            "valid loss: 2.676043\n",
            "Train Progress: 0.146555%, train loss: 2.722598, norm: 2.4233\n",
            "Train Progress: 0.146609%, train loss: 2.762922, norm: 2.3706\n",
            "Train Progress: 0.146664%, train loss: 2.678206, norm: 2.5079\n",
            "Train Progress: 0.146718%, train loss: 2.777575, norm: 2.5835\n",
            "Train Progress: 0.146773%, train loss: 2.737425, norm: 1.9571\n",
            "valid loss: 2.680406\n",
            "Train Progress: 0.146828%, train loss: 2.745640, norm: 2.6128\n",
            "Train Progress: 0.146882%, train loss: 2.565398, norm: 2.1017\n",
            "Train Progress: 0.146937%, train loss: 2.650881, norm: 3.3053\n",
            "Train Progress: 0.146991%, train loss: 2.715451, norm: 2.9026\n",
            "Train Progress: 0.147046%, train loss: 2.732874, norm: 1.7316\n",
            "valid loss: 2.680086\n",
            "Train Progress: 0.147100%, train loss: 2.576968, norm: 3.5442\n",
            "Train Progress: 0.147155%, train loss: 2.741352, norm: 2.1990\n",
            "Train Progress: 0.147209%, train loss: 2.763358, norm: 2.3052\n",
            "Train Progress: 0.147264%, train loss: 2.522544, norm: 2.8745\n",
            "Train Progress: 0.147318%, train loss: 2.657797, norm: 3.4159\n",
            "valid loss: 2.679224\n",
            "Train Progress: 0.147373%, train loss: 2.544188, norm: 2.7722\n",
            "Train Progress: 0.147427%, train loss: 2.722229, norm: 2.3987\n",
            "Train Progress: 0.147482%, train loss: 2.706927, norm: 2.7012\n",
            "Train Progress: 0.147537%, train loss: 2.693584, norm: 1.9069\n",
            "Train Progress: 0.147591%, train loss: 2.708887, norm: 2.0164\n",
            "valid loss: 2.674705\n",
            "Train Progress: 0.147646%, train loss: 2.675526, norm: 1.9024\n",
            "Train Progress: 0.147700%, train loss: 2.613895, norm: 2.3358\n",
            "Train Progress: 0.147755%, train loss: 2.646624, norm: 2.5390\n",
            "Train Progress: 0.147809%, train loss: 2.674086, norm: 3.0623\n",
            "Train Progress: 0.147864%, train loss: 2.607514, norm: 3.0568\n",
            "valid loss: 2.673705\n",
            "Train Progress: 0.147918%, train loss: 2.702951, norm: 2.4848\n",
            "Train Progress: 0.147973%, train loss: 2.659928, norm: 2.5324\n",
            "Train Progress: 0.148027%, train loss: 2.668859, norm: 1.8411\n",
            "Train Progress: 0.148082%, train loss: 2.489115, norm: 2.2511\n",
            "Train Progress: 0.148136%, train loss: 2.740358, norm: 2.5159\n",
            "valid loss: 2.678990\n",
            "Train Progress: 0.148191%, train loss: 2.669890, norm: 2.9906\n",
            "Train Progress: 0.148246%, train loss: 2.552055, norm: 2.8500\n",
            "Train Progress: 0.148300%, train loss: 2.567364, norm: 2.6772\n",
            "Train Progress: 0.148355%, train loss: 2.152135, norm: 3.2195\n",
            "Train Progress: 0.148409%, train loss: 2.610066, norm: 2.1402\n",
            "valid loss: 2.676677\n",
            "Train Progress: 0.148464%, train loss: 2.678667, norm: 3.1231\n",
            "Train Progress: 0.148518%, train loss: 2.592330, norm: 2.1935\n",
            "Train Progress: 0.148573%, train loss: 2.594639, norm: 2.2723\n",
            "Train Progress: 0.148627%, train loss: 2.775214, norm: 2.1022\n",
            "Train Progress: 0.148682%, train loss: 2.660055, norm: 2.2967\n",
            "valid loss: 2.675826\n",
            "Train Progress: 0.148736%, train loss: 2.716820, norm: 2.0392\n",
            "Train Progress: 0.148791%, train loss: 2.623171, norm: 2.9394\n",
            "Train Progress: 0.148845%, train loss: 2.702484, norm: 2.2694\n",
            "Train Progress: 0.148900%, train loss: 2.777784, norm: 2.3341\n",
            "Train Progress: 0.148955%, train loss: 2.752651, norm: 3.0202\n",
            "valid loss: 2.676871\n",
            "Train Progress: 0.149009%, train loss: 2.710591, norm: 2.4954\n",
            "Train Progress: 0.149064%, train loss: 2.557146, norm: 2.0618\n",
            "Train Progress: 0.149118%, train loss: 2.736522, norm: 2.9706\n",
            "Train Progress: 0.149173%, train loss: 2.550992, norm: 3.4248\n",
            "Train Progress: 0.149227%, train loss: 2.765376, norm: 1.8727\n",
            "valid loss: 2.676777\n",
            "Train Progress: 0.149282%, train loss: 2.648586, norm: 2.6732\n",
            "Train Progress: 0.149336%, train loss: 2.443953, norm: 3.2325\n",
            "Train Progress: 0.149391%, train loss: 2.563064, norm: 3.7527\n",
            "Train Progress: 0.149445%, train loss: 2.743405, norm: 3.3458\n",
            "Train Progress: 0.149500%, train loss: 2.778526, norm: 4.1239\n",
            "valid loss: 2.678236\n",
            "Train Progress: 0.149554%, train loss: 2.247030, norm: 2.9121\n",
            "Train Progress: 0.149609%, train loss: 2.635129, norm: 3.0612\n",
            "Train Progress: 0.149663%, train loss: 2.600335, norm: 2.8808\n",
            "Train Progress: 0.149718%, train loss: 2.695373, norm: 2.0369\n",
            "Train Progress: 0.149773%, train loss: 2.704200, norm: 2.0393\n",
            "valid loss: 2.680462\n",
            "Train Progress: 0.149827%, train loss: 2.311633, norm: 3.2157\n",
            "Train Progress: 0.149882%, train loss: 2.627637, norm: 3.3089\n",
            "Train Progress: 0.149936%, train loss: 2.682626, norm: 2.9725\n",
            "Train Progress: 0.149991%, train loss: 2.678220, norm: 2.6416\n",
            "Train Progress: 0.150045%, train loss: 2.725266, norm: 2.6592\n",
            "valid loss: 2.675888\n",
            "Train Progress: 0.150100%, train loss: 2.744828, norm: 3.3399\n",
            "Train Progress: 0.150154%, train loss: 2.714272, norm: 2.0597\n",
            "Train Progress: 0.150209%, train loss: 2.623988, norm: 2.0784\n",
            "Train Progress: 0.150263%, train loss: 2.744094, norm: 3.1716\n",
            "Train Progress: 0.150318%, train loss: 2.739728, norm: 2.7511\n",
            "valid loss: 2.674932\n",
            "Train Progress: 0.150372%, train loss: 2.713786, norm: 3.1055\n",
            "Train Progress: 0.150427%, train loss: 2.785049, norm: 2.0442\n",
            "Train Progress: 0.150482%, train loss: 2.733310, norm: 2.8806\n",
            "Train Progress: 0.150536%, train loss: 2.753861, norm: 2.5163\n",
            "Train Progress: 0.150591%, train loss: 2.738961, norm: 3.0439\n",
            "valid loss: 2.676245\n",
            "Train Progress: 0.150645%, train loss: 2.544239, norm: 3.3754\n",
            "Train Progress: 0.150700%, train loss: 2.737597, norm: 2.4951\n",
            "Train Progress: 0.150754%, train loss: 2.660134, norm: 1.7536\n",
            "Train Progress: 0.150809%, train loss: 2.738087, norm: 2.0898\n",
            "Train Progress: 0.150863%, train loss: 2.604111, norm: 2.0261\n",
            "valid loss: 2.673881\n",
            "Train Progress: 0.150918%, train loss: 2.698240, norm: 2.7472\n",
            "Train Progress: 0.150972%, train loss: 2.740154, norm: 2.2883\n",
            "Train Progress: 0.151027%, train loss: 2.612227, norm: 2.3650\n",
            "Train Progress: 0.151081%, train loss: 2.722375, norm: 2.1203\n",
            "Train Progress: 0.151136%, train loss: 2.530377, norm: 3.3007\n",
            "valid loss: 2.675076\n",
            "Train Progress: 0.151191%, train loss: 2.625343, norm: 3.2748\n",
            "Train Progress: 0.151245%, train loss: 2.622117, norm: 1.8809\n",
            "Train Progress: 0.151300%, train loss: 2.651852, norm: 2.0046\n",
            "Train Progress: 0.151354%, train loss: 2.516705, norm: 2.4920\n",
            "Train Progress: 0.151409%, train loss: 2.684003, norm: 2.9639\n",
            "valid loss: 2.676517\n",
            "Train Progress: 0.151463%, train loss: 2.609007, norm: 2.6375\n",
            "Train Progress: 0.151518%, train loss: 2.489911, norm: 3.1232\n",
            "Train Progress: 0.151572%, train loss: 2.751930, norm: 2.7963\n",
            "Train Progress: 0.151627%, train loss: 2.705989, norm: 3.2147\n",
            "Train Progress: 0.151681%, train loss: 2.609425, norm: 3.2769\n",
            "valid loss: 2.676925\n",
            "Train Progress: 0.151736%, train loss: 2.645285, norm: 2.0034\n",
            "Train Progress: 0.151790%, train loss: 2.728301, norm: 3.1297\n",
            "Train Progress: 0.151845%, train loss: 2.711355, norm: 2.5277\n",
            "Train Progress: 0.151900%, train loss: 2.619062, norm: 2.8210\n",
            "Train Progress: 0.151954%, train loss: 2.745757, norm: 2.0770\n",
            "valid loss: 2.675550\n",
            "Train Progress: 0.152009%, train loss: 2.729244, norm: 2.6747\n",
            "Train Progress: 0.152063%, train loss: 2.796719, norm: 3.7105\n",
            "Train Progress: 0.152118%, train loss: 2.575593, norm: 2.8089\n",
            "Train Progress: 0.152172%, train loss: 2.547371, norm: 3.0421\n",
            "Train Progress: 0.152227%, train loss: 2.781650, norm: 1.7415\n",
            "valid loss: 2.676172\n",
            "Train Progress: 0.152281%, train loss: 2.751014, norm: 2.5624\n",
            "Train Progress: 0.152336%, train loss: 2.619877, norm: 2.6280\n",
            "Train Progress: 0.152390%, train loss: 2.650301, norm: 2.9094\n",
            "Train Progress: 0.152445%, train loss: 2.545225, norm: 3.3620\n",
            "Train Progress: 0.152499%, train loss: 2.643185, norm: 2.0469\n",
            "valid loss: 2.675354\n",
            "Train Progress: 0.152554%, train loss: 2.410441, norm: 2.9085\n",
            "Train Progress: 0.152609%, train loss: 2.519509, norm: 2.6814\n",
            "Train Progress: 0.152663%, train loss: 2.748300, norm: 1.9179\n",
            "Train Progress: 0.152718%, train loss: 2.685550, norm: 2.7836\n",
            "Train Progress: 0.152772%, train loss: 2.477815, norm: 4.9073\n",
            "valid loss: 2.674819\n",
            "Train Progress: 0.152827%, train loss: 2.746712, norm: 2.1330\n",
            "Train Progress: 0.152881%, train loss: 2.683269, norm: 3.0017\n",
            "Train Progress: 0.152936%, train loss: 2.746436, norm: 3.0657\n",
            "Train Progress: 0.152990%, train loss: 2.725934, norm: 2.7659\n",
            "Train Progress: 0.153045%, train loss: 2.475774, norm: 2.3216\n",
            "valid loss: 2.672118\n",
            "Train Progress: 0.153099%, train loss: 2.692022, norm: 2.0076\n",
            "Train Progress: 0.153154%, train loss: 2.688873, norm: 2.0665\n",
            "Train Progress: 0.153208%, train loss: 2.465949, norm: 3.3123\n",
            "Train Progress: 0.153263%, train loss: 2.345081, norm: 3.6271\n",
            "Train Progress: 0.153318%, train loss: 2.631058, norm: 2.6535\n",
            "valid loss: 2.669167\n",
            "Train Progress: 0.153372%, train loss: 2.539708, norm: 3.1395\n",
            "Train Progress: 0.153427%, train loss: 2.590882, norm: 3.2609\n",
            "Train Progress: 0.153481%, train loss: 2.734402, norm: 2.2827\n",
            "Train Progress: 0.153536%, train loss: 2.648547, norm: 2.0617\n",
            "Train Progress: 0.153590%, train loss: 2.710368, norm: 2.2654\n",
            "valid loss: 2.671608\n",
            "Train Progress: 0.153645%, train loss: 2.630333, norm: 1.8493\n",
            "Train Progress: 0.153699%, train loss: 2.673777, norm: 2.1060\n",
            "Train Progress: 0.153754%, train loss: 2.724772, norm: 1.8668\n",
            "Train Progress: 0.153808%, train loss: 2.689687, norm: 2.1495\n",
            "Train Progress: 0.153863%, train loss: 2.546437, norm: 4.3272\n",
            "valid loss: 2.672091\n",
            "Train Progress: 0.153917%, train loss: 2.732563, norm: 3.2831\n",
            "Train Progress: 0.153972%, train loss: 2.589599, norm: 3.2908\n",
            "Train Progress: 0.154027%, train loss: 2.662962, norm: 1.6616\n",
            "Train Progress: 0.154081%, train loss: 2.703860, norm: 2.8963\n",
            "Train Progress: 0.154136%, train loss: 2.719797, norm: 3.0516\n",
            "valid loss: 2.669301\n",
            "Train Progress: 0.154190%, train loss: 2.725583, norm: 2.3124\n",
            "Train Progress: 0.154245%, train loss: 2.598064, norm: 2.4202\n",
            "Train Progress: 0.154299%, train loss: 2.680462, norm: 1.6529\n",
            "Train Progress: 0.154354%, train loss: 2.671451, norm: 1.7765\n",
            "Train Progress: 0.154408%, train loss: 2.714479, norm: 3.5698\n",
            "valid loss: 2.676961\n",
            "Train Progress: 0.154463%, train loss: 2.643808, norm: 2.8276\n",
            "Train Progress: 0.154517%, train loss: 2.622297, norm: 3.2579\n",
            "Train Progress: 0.154572%, train loss: 2.675825, norm: 3.4939\n",
            "Train Progress: 0.154626%, train loss: 2.688189, norm: 2.3938\n",
            "Train Progress: 0.154681%, train loss: 2.665695, norm: 2.3170\n",
            "valid loss: 2.669791\n",
            "Train Progress: 0.154736%, train loss: 2.685161, norm: 2.8989\n",
            "Train Progress: 0.154790%, train loss: 2.606524, norm: 2.2032\n",
            "Train Progress: 0.154845%, train loss: 2.722161, norm: 1.8817\n",
            "Train Progress: 0.154899%, train loss: 2.743248, norm: 1.9616\n",
            "Train Progress: 0.154954%, train loss: 2.629272, norm: 2.4280\n",
            "valid loss: 2.671324\n",
            "Train Progress: 0.155008%, train loss: 2.640752, norm: 4.0443\n",
            "Train Progress: 0.155063%, train loss: 2.688633, norm: 2.6489\n",
            "Train Progress: 0.155117%, train loss: 2.711389, norm: 2.4998\n",
            "Train Progress: 0.155172%, train loss: 2.692870, norm: 2.8316\n",
            "Train Progress: 0.155226%, train loss: 2.752559, norm: 2.9310\n",
            "valid loss: 2.670966\n",
            "Train Progress: 0.155281%, train loss: 2.581588, norm: 3.1092\n",
            "Train Progress: 0.155335%, train loss: 2.576303, norm: 3.5142\n",
            "Train Progress: 0.155390%, train loss: 2.686057, norm: 2.5176\n",
            "Train Progress: 0.155445%, train loss: 2.572128, norm: 2.2321\n",
            "Train Progress: 0.155499%, train loss: 2.550569, norm: 3.2062\n",
            "valid loss: 2.673364\n",
            "Train Progress: 0.155554%, train loss: 2.769552, norm: 2.0578\n",
            "Train Progress: 0.155608%, train loss: 2.685689, norm: 2.1788\n",
            "Train Progress: 0.155663%, train loss: 2.672199, norm: 2.7449\n",
            "Train Progress: 0.155717%, train loss: 2.540339, norm: 2.4485\n",
            "Train Progress: 0.155772%, train loss: 2.753647, norm: 2.8771\n",
            "valid loss: 2.674235\n",
            "Train Progress: 0.155826%, train loss: 2.685335, norm: 2.6963\n",
            "Train Progress: 0.155881%, train loss: 2.241923, norm: 3.7880\n",
            "Train Progress: 0.155935%, train loss: 2.675952, norm: 1.7035\n",
            "Train Progress: 0.155990%, train loss: 2.720803, norm: 2.4637\n",
            "Train Progress: 0.156044%, train loss: 2.699798, norm: 2.2682\n",
            "valid loss: 2.668890\n",
            "Train Progress: 0.156099%, train loss: 2.568629, norm: 2.2086\n",
            "Train Progress: 0.156154%, train loss: 2.574398, norm: 2.2232\n",
            "Train Progress: 0.156208%, train loss: 2.722657, norm: 2.2041\n",
            "Train Progress: 0.156263%, train loss: 2.727193, norm: 2.8654\n",
            "Train Progress: 0.156317%, train loss: 2.637240, norm: 3.6016\n",
            "valid loss: 2.670266\n",
            "Train Progress: 0.156372%, train loss: 2.740544, norm: 2.0353\n",
            "Train Progress: 0.156426%, train loss: 2.708649, norm: 3.2253\n",
            "Train Progress: 0.156481%, train loss: 2.667898, norm: 3.0407\n",
            "Train Progress: 0.156535%, train loss: 2.538485, norm: 1.8857\n",
            "Train Progress: 0.156590%, train loss: 2.696173, norm: 2.0672\n",
            "valid loss: 2.674978\n",
            "Train Progress: 0.156644%, train loss: 2.678922, norm: 2.7544\n",
            "Train Progress: 0.156699%, train loss: 2.740295, norm: 2.8136\n",
            "Train Progress: 0.156753%, train loss: 2.703189, norm: 2.2937\n",
            "Train Progress: 0.156808%, train loss: 2.631356, norm: 3.3313\n",
            "Train Progress: 0.156863%, train loss: 2.687536, norm: 1.9503\n",
            "valid loss: 2.675685\n",
            "Train Progress: 0.156917%, train loss: 2.726631, norm: 2.4703\n",
            "Train Progress: 0.156972%, train loss: 2.729878, norm: 2.4295\n",
            "Train Progress: 0.157026%, train loss: 2.674711, norm: 2.5192\n",
            "Train Progress: 0.157081%, train loss: 2.723609, norm: 1.9400\n",
            "Train Progress: 0.157135%, train loss: 2.688907, norm: 2.1536\n",
            "valid loss: 2.677418\n",
            "Train Progress: 0.157190%, train loss: 2.609583, norm: 3.0027\n",
            "Train Progress: 0.157244%, train loss: 2.717898, norm: 3.8313\n",
            "Train Progress: 0.157299%, train loss: 2.656192, norm: 3.1081\n",
            "Train Progress: 0.157353%, train loss: 2.459701, norm: 2.5026\n",
            "Train Progress: 0.157408%, train loss: 2.505646, norm: 3.1402\n",
            "valid loss: 2.674865\n",
            "Train Progress: 0.157462%, train loss: 2.743840, norm: 1.6337\n",
            "Train Progress: 0.157517%, train loss: 2.649980, norm: 2.3784\n",
            "Train Progress: 0.157572%, train loss: 2.707381, norm: 2.2089\n",
            "Train Progress: 0.157626%, train loss: 2.416802, norm: 2.0879\n",
            "Train Progress: 0.157681%, train loss: 2.669185, norm: 2.6236\n",
            "valid loss: 2.677038\n",
            "Train Progress: 0.157735%, train loss: 2.538232, norm: 3.1485\n",
            "Train Progress: 0.157790%, train loss: 2.703521, norm: 3.3580\n",
            "Train Progress: 0.157844%, train loss: 2.406367, norm: 3.5866\n",
            "Train Progress: 0.157899%, train loss: 2.452182, norm: 2.6050\n",
            "Train Progress: 0.157953%, train loss: 2.433052, norm: 3.1744\n",
            "valid loss: 2.675970\n",
            "Train Progress: 0.158008%, train loss: 2.493096, norm: 2.2197\n",
            "Train Progress: 0.158062%, train loss: 2.669700, norm: 2.3125\n",
            "Train Progress: 0.158117%, train loss: 2.624497, norm: 2.7812\n",
            "Train Progress: 0.158171%, train loss: 2.698293, norm: 3.0017\n",
            "Train Progress: 0.158226%, train loss: 2.718894, norm: 2.5472\n",
            "valid loss: 2.671242\n",
            "Train Progress: 0.158281%, train loss: 2.679030, norm: 2.7119\n",
            "Train Progress: 0.158335%, train loss: 2.439830, norm: 2.1608\n",
            "Train Progress: 0.158390%, train loss: 2.702091, norm: 2.8850\n",
            "Train Progress: 0.158444%, train loss: 2.415516, norm: 3.3765\n",
            "Train Progress: 0.158499%, train loss: 2.556464, norm: 2.4155\n",
            "valid loss: 2.669146\n",
            "Train Progress: 0.158553%, train loss: 2.698790, norm: 2.9584\n",
            "Train Progress: 0.158608%, train loss: 2.594528, norm: 2.5542\n",
            "Train Progress: 0.158662%, train loss: 2.760956, norm: 2.4674\n",
            "Train Progress: 0.158717%, train loss: 2.444993, norm: 2.5362\n",
            "Train Progress: 0.158771%, train loss: 2.734807, norm: 1.6292\n",
            "valid loss: 2.670614\n",
            "Train Progress: 0.158826%, train loss: 2.581731, norm: 2.1063\n",
            "Train Progress: 0.158880%, train loss: 2.622877, norm: 2.3905\n",
            "Train Progress: 0.158935%, train loss: 2.702954, norm: 3.5564\n",
            "Train Progress: 0.158990%, train loss: 2.627547, norm: 2.1232\n",
            "Train Progress: 0.159044%, train loss: 2.668135, norm: 1.7152\n",
            "valid loss: 2.672808\n",
            "Train Progress: 0.159099%, train loss: 2.516605, norm: 2.2087\n",
            "Train Progress: 0.159153%, train loss: 2.630416, norm: 2.5999\n",
            "Train Progress: 0.159208%, train loss: 2.737537, norm: 2.5550\n",
            "Train Progress: 0.159262%, train loss: 2.684299, norm: 2.8442\n",
            "Train Progress: 0.159317%, train loss: 2.724744, norm: 2.4579\n",
            "valid loss: 2.668624\n",
            "Train Progress: 0.159371%, train loss: 2.619817, norm: 1.8443\n",
            "Train Progress: 0.159426%, train loss: 2.710987, norm: 2.9890\n",
            "Train Progress: 0.159480%, train loss: 2.778623, norm: 3.0318\n",
            "Train Progress: 0.159535%, train loss: 2.598707, norm: 2.5896\n",
            "Train Progress: 0.159589%, train loss: 2.340028, norm: 2.6553\n",
            "valid loss: 2.669748\n",
            "Train Progress: 0.159644%, train loss: 2.706774, norm: 3.1875\n",
            "Train Progress: 0.159699%, train loss: 2.704509, norm: 2.8377\n",
            "Train Progress: 0.159753%, train loss: 2.475158, norm: 1.9894\n",
            "Train Progress: 0.159808%, train loss: 2.547625, norm: 2.6336\n",
            "Train Progress: 0.159862%, train loss: 2.726199, norm: 3.3280\n",
            "valid loss: 2.671777\n",
            "Train Progress: 0.159917%, train loss: 2.616992, norm: 2.2280\n",
            "Train Progress: 0.159971%, train loss: 2.559584, norm: 2.0274\n",
            "Train Progress: 0.160026%, train loss: 2.742743, norm: 2.2023\n",
            "Train Progress: 0.160080%, train loss: 2.638915, norm: 2.5095\n",
            "Train Progress: 0.160135%, train loss: 2.703080, norm: 2.4423\n",
            "valid loss: 2.668606\n",
            "Train Progress: 0.160189%, train loss: 2.701551, norm: 3.5979\n",
            "Train Progress: 0.160244%, train loss: 2.701282, norm: 2.5231\n",
            "Train Progress: 0.160298%, train loss: 2.732309, norm: 2.3401\n",
            "Train Progress: 0.160353%, train loss: 2.743981, norm: 2.7907\n",
            "Train Progress: 0.160408%, train loss: 2.626922, norm: 2.2524\n",
            "valid loss: 2.674556\n",
            "Train Progress: 0.160462%, train loss: 2.586257, norm: 2.2457\n",
            "Train Progress: 0.160517%, train loss: 2.757327, norm: 2.3048\n",
            "Train Progress: 0.160571%, train loss: 2.638741, norm: 2.0509\n",
            "Train Progress: 0.160626%, train loss: 2.733337, norm: 3.6217\n",
            "Train Progress: 0.160680%, train loss: 2.735566, norm: 1.9300\n",
            "valid loss: 2.670683\n",
            "Train Progress: 0.160735%, train loss: 2.695370, norm: 2.2267\n",
            "Train Progress: 0.160789%, train loss: 2.762623, norm: 2.2016\n",
            "Train Progress: 0.160844%, train loss: 2.507261, norm: 2.6194\n",
            "Train Progress: 0.160898%, train loss: 2.311016, norm: 2.1405\n",
            "Train Progress: 0.160953%, train loss: 2.719503, norm: 2.3749\n",
            "valid loss: 2.670990\n",
            "Train Progress: 0.161007%, train loss: 2.606802, norm: 2.1528\n",
            "Train Progress: 0.161062%, train loss: 2.573200, norm: 3.0286\n",
            "Train Progress: 0.161117%, train loss: 2.583187, norm: 2.7470\n",
            "Train Progress: 0.161171%, train loss: 2.536017, norm: 2.5202\n",
            "Train Progress: 0.161226%, train loss: 2.629067, norm: 3.1826\n",
            "valid loss: 2.668322\n",
            "Train Progress: 0.161280%, train loss: 2.713360, norm: 2.8001\n",
            "Train Progress: 0.161335%, train loss: 2.714462, norm: 2.8091\n",
            "Train Progress: 0.161389%, train loss: 2.726830, norm: 4.5809\n",
            "Train Progress: 0.161444%, train loss: 2.390630, norm: 3.9032\n",
            "Train Progress: 0.161498%, train loss: 2.788426, norm: 3.2796\n",
            "valid loss: 2.676216\n",
            "Train Progress: 0.161553%, train loss: 2.619748, norm: 3.3516\n",
            "Train Progress: 0.161607%, train loss: 2.642002, norm: 2.5855\n",
            "Train Progress: 0.161662%, train loss: 2.545490, norm: 3.0529\n",
            "Train Progress: 0.161716%, train loss: 2.779315, norm: 2.6197\n",
            "Train Progress: 0.161771%, train loss: 2.671235, norm: 3.2685\n",
            "valid loss: 2.669606\n",
            "Train Progress: 0.161825%, train loss: 2.589156, norm: 3.2561\n",
            "Train Progress: 0.161880%, train loss: 2.562981, norm: 3.1519\n",
            "Train Progress: 0.161935%, train loss: 2.652598, norm: 2.4257\n",
            "Train Progress: 0.161989%, train loss: 2.699684, norm: 2.2810\n",
            "Train Progress: 0.162044%, train loss: 2.716352, norm: 2.4373\n",
            "valid loss: 2.667786\n",
            "Train Progress: 0.162098%, train loss: 2.496068, norm: 2.4057\n",
            "Train Progress: 0.162153%, train loss: 2.628535, norm: 2.1862\n",
            "Train Progress: 0.162207%, train loss: 2.719266, norm: 1.9019\n",
            "Train Progress: 0.162262%, train loss: 2.663661, norm: 2.5362\n",
            "Train Progress: 0.162316%, train loss: 2.620271, norm: 2.5838\n",
            "valid loss: 2.670998\n",
            "Train Progress: 0.162371%, train loss: 2.582970, norm: 3.3846\n",
            "Train Progress: 0.162425%, train loss: 2.428448, norm: 2.6264\n",
            "Train Progress: 0.162480%, train loss: 2.335118, norm: 3.5083\n",
            "Train Progress: 0.162534%, train loss: 2.365309, norm: 2.9237\n",
            "Train Progress: 0.162589%, train loss: 2.685032, norm: 2.6988\n",
            "valid loss: 2.674342\n",
            "Train Progress: 0.162644%, train loss: 2.720104, norm: 3.4364\n",
            "Train Progress: 0.162698%, train loss: 2.713163, norm: 2.7968\n",
            "Train Progress: 0.162753%, train loss: 2.540203, norm: 3.1163\n",
            "Train Progress: 0.162807%, train loss: 2.610815, norm: 2.2129\n",
            "Train Progress: 0.162862%, train loss: 2.458529, norm: 2.9863\n",
            "valid loss: 2.669954\n",
            "Train Progress: 0.162916%, train loss: 2.746638, norm: 2.9940\n",
            "Train Progress: 0.162971%, train loss: 2.716266, norm: 2.5602\n",
            "Train Progress: 0.163025%, train loss: 2.169952, norm: 2.4626\n",
            "Train Progress: 0.163080%, train loss: 2.816021, norm: 3.4326\n",
            "Train Progress: 0.163134%, train loss: 2.685118, norm: 2.1662\n",
            "valid loss: 2.670973\n",
            "Train Progress: 0.163189%, train loss: 2.530940, norm: 2.5942\n",
            "Train Progress: 0.163243%, train loss: 2.667284, norm: 2.2765\n",
            "Train Progress: 0.163298%, train loss: 2.599340, norm: 1.9603\n",
            "Train Progress: 0.163353%, train loss: 2.756980, norm: 1.6979\n",
            "Train Progress: 0.163407%, train loss: 2.583308, norm: 2.8888\n",
            "valid loss: 2.669007\n",
            "Train Progress: 0.163462%, train loss: 2.584712, norm: 2.9402\n",
            "Train Progress: 0.163516%, train loss: 2.620942, norm: 2.7676\n",
            "Train Progress: 0.163571%, train loss: 2.625878, norm: 3.4966\n",
            "Train Progress: 0.163625%, train loss: 2.682547, norm: 3.9488\n",
            "Train Progress: 0.163680%, train loss: 2.741607, norm: 2.9778\n",
            "valid loss: 2.670151\n",
            "Train Progress: 0.163734%, train loss: 2.753472, norm: 2.6710\n",
            "Train Progress: 0.163789%, train loss: 2.569697, norm: 2.4296\n",
            "Train Progress: 0.163843%, train loss: 2.642004, norm: 3.3249\n",
            "Train Progress: 0.163898%, train loss: 2.541629, norm: 2.7811\n",
            "Train Progress: 0.163952%, train loss: 2.671205, norm: 3.7811\n",
            "valid loss: 2.671167\n",
            "Train Progress: 0.164007%, train loss: 2.746448, norm: 1.4144\n",
            "Train Progress: 0.164062%, train loss: 2.666317, norm: 2.8889\n",
            "Train Progress: 0.164116%, train loss: 2.627547, norm: 2.9890\n",
            "Train Progress: 0.164171%, train loss: 2.508503, norm: 3.5677\n",
            "Train Progress: 0.164225%, train loss: 2.409643, norm: 3.1366\n",
            "valid loss: 2.669111\n",
            "Train Progress: 0.164280%, train loss: 2.718587, norm: 3.5167\n",
            "Train Progress: 0.164334%, train loss: 2.774566, norm: 2.2470\n",
            "Train Progress: 0.164389%, train loss: 2.744097, norm: 2.1314\n",
            "Train Progress: 0.164443%, train loss: 2.638129, norm: 2.9917\n",
            "Train Progress: 0.164498%, train loss: 2.668900, norm: 2.8996\n",
            "valid loss: 2.671385\n",
            "Train Progress: 0.164552%, train loss: 2.721053, norm: 2.1571\n",
            "Train Progress: 0.164607%, train loss: 2.658705, norm: 3.4691\n",
            "Train Progress: 0.164661%, train loss: 2.644033, norm: 2.4657\n",
            "Train Progress: 0.164716%, train loss: 2.618790, norm: 2.7886\n",
            "Train Progress: 0.164771%, train loss: 2.774151, norm: 1.9886\n",
            "valid loss: 2.670736\n",
            "Train Progress: 0.164825%, train loss: 2.598423, norm: 2.6274\n",
            "Train Progress: 0.164880%, train loss: 2.694380, norm: 3.4603\n",
            "Train Progress: 0.164934%, train loss: 2.686000, norm: 2.5306\n",
            "Train Progress: 0.164989%, train loss: 2.573009, norm: 2.7938\n",
            "Train Progress: 0.165043%, train loss: 2.563024, norm: 2.3662\n",
            "valid loss: 2.670875\n",
            "Train Progress: 0.165098%, train loss: 2.692107, norm: 2.2657\n",
            "Train Progress: 0.165152%, train loss: 2.673208, norm: 3.1245\n",
            "Train Progress: 0.165207%, train loss: 2.723259, norm: 2.4889\n",
            "Train Progress: 0.165261%, train loss: 2.751000, norm: 2.8442\n",
            "Train Progress: 0.165316%, train loss: 2.688507, norm: 3.7927\n",
            "valid loss: 2.672159\n",
            "Train Progress: 0.165370%, train loss: 2.694826, norm: 2.6414\n",
            "Train Progress: 0.165425%, train loss: 2.740734, norm: 3.0065\n",
            "Train Progress: 0.165480%, train loss: 2.761287, norm: 2.5112\n",
            "Train Progress: 0.165534%, train loss: 2.732023, norm: 1.8542\n",
            "Train Progress: 0.165589%, train loss: 2.709542, norm: 1.8803\n",
            "valid loss: 2.671654\n",
            "Train Progress: 0.165643%, train loss: 2.722129, norm: 1.8732\n",
            "Train Progress: 0.165698%, train loss: 2.726969, norm: 1.9232\n",
            "Train Progress: 0.165752%, train loss: 2.668724, norm: 2.2935\n",
            "Train Progress: 0.165807%, train loss: 2.636322, norm: 2.4234\n",
            "Train Progress: 0.165861%, train loss: 2.729389, norm: 2.5289\n",
            "valid loss: 2.672934\n",
            "Train Progress: 0.165916%, train loss: 2.482892, norm: 3.0277\n",
            "Train Progress: 0.165970%, train loss: 2.653487, norm: 3.2195\n",
            "Train Progress: 0.166025%, train loss: 2.575987, norm: 2.8966\n",
            "Train Progress: 0.166079%, train loss: 2.467148, norm: 2.7000\n",
            "Train Progress: 0.166134%, train loss: 2.701528, norm: 2.4258\n",
            "valid loss: 2.676817\n",
            "Train Progress: 0.166189%, train loss: 2.724930, norm: 2.0631\n",
            "Train Progress: 0.166243%, train loss: 2.582699, norm: 2.2526\n",
            "Train Progress: 0.166298%, train loss: 2.803576, norm: 1.8998\n",
            "Train Progress: 0.166352%, train loss: 2.783146, norm: 2.6456\n",
            "Train Progress: 0.166407%, train loss: 2.750190, norm: 2.6895\n",
            "valid loss: 2.678107\n",
            "Train Progress: 0.166461%, train loss: 2.671703, norm: 3.4315\n",
            "Train Progress: 0.166516%, train loss: 2.631495, norm: 3.5790\n",
            "Train Progress: 0.166570%, train loss: 2.749329, norm: 2.7753\n",
            "Train Progress: 0.166625%, train loss: 2.684969, norm: 3.2269\n",
            "Train Progress: 0.166679%, train loss: 2.591606, norm: 2.7838\n",
            "valid loss: 2.676626\n",
            "Train Progress: 0.166734%, train loss: 2.615256, norm: 3.2166\n",
            "Train Progress: 0.166788%, train loss: 2.615041, norm: 2.6740\n",
            "Train Progress: 0.166843%, train loss: 2.703238, norm: 2.2965\n",
            "Train Progress: 0.166898%, train loss: 2.665641, norm: 2.1045\n",
            "Train Progress: 0.166952%, train loss: 2.735684, norm: 1.7707\n",
            "valid loss: 2.676386\n",
            "Train Progress: 0.167007%, train loss: 2.700262, norm: 2.9610\n",
            "Train Progress: 0.167061%, train loss: 2.714307, norm: 3.2022\n",
            "Train Progress: 0.167116%, train loss: 2.617668, norm: 2.7856\n",
            "Train Progress: 0.167170%, train loss: 2.612721, norm: 3.4459\n",
            "Train Progress: 0.167225%, train loss: 2.598542, norm: 4.8689\n",
            "valid loss: 2.678504\n",
            "Train Progress: 0.167279%, train loss: 2.732274, norm: 3.0235\n",
            "Train Progress: 0.167334%, train loss: 2.534285, norm: 3.1505\n",
            "Train Progress: 0.167388%, train loss: 2.354674, norm: 2.6139\n",
            "Train Progress: 0.167443%, train loss: 2.665910, norm: 2.3038\n",
            "Train Progress: 0.167497%, train loss: 2.683456, norm: 2.6517\n",
            "valid loss: 2.678917\n",
            "Train Progress: 0.167552%, train loss: 2.513766, norm: 3.1486\n",
            "Train Progress: 0.167607%, train loss: 2.510355, norm: 3.6361\n",
            "Train Progress: 0.167661%, train loss: 2.637511, norm: 3.4597\n",
            "Train Progress: 0.167716%, train loss: 2.560277, norm: 3.4065\n",
            "Train Progress: 0.167770%, train loss: 2.650693, norm: 3.7901\n",
            "valid loss: 2.677421\n",
            "Train Progress: 0.167825%, train loss: 2.679813, norm: 3.5467\n",
            "Train Progress: 0.167879%, train loss: 2.731923, norm: 2.3465\n",
            "Train Progress: 0.167934%, train loss: 2.693515, norm: 2.4216\n",
            "Train Progress: 0.167988%, train loss: 2.631637, norm: 3.6591\n",
            "Train Progress: 0.168043%, train loss: 2.678104, norm: 2.0199\n",
            "valid loss: 2.676664\n",
            "Train Progress: 0.168097%, train loss: 2.702316, norm: 2.5607\n",
            "Train Progress: 0.168152%, train loss: 2.515264, norm: 3.2130\n",
            "Train Progress: 0.168206%, train loss: 2.709047, norm: 2.7813\n",
            "Train Progress: 0.168261%, train loss: 2.632666, norm: 1.9821\n",
            "Train Progress: 0.168316%, train loss: 2.748943, norm: 2.7294\n",
            "valid loss: 2.677852\n",
            "Train Progress: 0.168370%, train loss: 2.589664, norm: 2.9110\n",
            "Train Progress: 0.168425%, train loss: 2.723287, norm: 2.1435\n",
            "Train Progress: 0.168479%, train loss: 2.756783, norm: 3.3894\n",
            "Train Progress: 0.168534%, train loss: 2.603803, norm: 2.1600\n",
            "Train Progress: 0.168588%, train loss: 2.647614, norm: 3.2642\n",
            "valid loss: 2.678102\n",
            "Train Progress: 0.168643%, train loss: 2.379632, norm: 3.8191\n",
            "Train Progress: 0.168697%, train loss: 2.591265, norm: 4.3705\n",
            "Train Progress: 0.168752%, train loss: 2.674600, norm: 2.7419\n",
            "Train Progress: 0.168806%, train loss: 2.712817, norm: 3.7740\n",
            "Train Progress: 0.168861%, train loss: 2.743964, norm: 2.3552\n",
            "valid loss: 2.673238\n",
            "Train Progress: 0.168915%, train loss: 2.757702, norm: 1.8840\n",
            "Train Progress: 0.168970%, train loss: 2.751357, norm: 2.1751\n",
            "Train Progress: 0.169025%, train loss: 2.709391, norm: 2.1836\n",
            "Train Progress: 0.169079%, train loss: 2.603659, norm: 2.5076\n",
            "Train Progress: 0.169134%, train loss: 2.677938, norm: 2.6636\n",
            "valid loss: 2.676430\n",
            "Train Progress: 0.169188%, train loss: 2.540898, norm: 2.9981\n",
            "Train Progress: 0.169243%, train loss: 2.671591, norm: 2.9892\n",
            "Train Progress: 0.169297%, train loss: 2.725448, norm: 3.4224\n",
            "Train Progress: 0.169352%, train loss: 2.688046, norm: 3.3165\n",
            "Train Progress: 0.169406%, train loss: 2.531948, norm: 3.1580\n",
            "valid loss: 2.677058\n",
            "Train Progress: 0.169461%, train loss: 2.715050, norm: 2.9974\n",
            "Train Progress: 0.169515%, train loss: 2.594873, norm: 3.0834\n",
            "Train Progress: 0.169570%, train loss: 2.693008, norm: 2.1375\n",
            "Train Progress: 0.169624%, train loss: 2.682457, norm: 2.2380\n",
            "Train Progress: 0.169679%, train loss: 2.692984, norm: 2.7703\n",
            "valid loss: 2.673908\n",
            "Train Progress: 0.169734%, train loss: 2.621377, norm: 2.5279\n",
            "Train Progress: 0.169788%, train loss: 2.458076, norm: 3.3057\n",
            "Train Progress: 0.169843%, train loss: 2.624101, norm: 3.4686\n",
            "Train Progress: 0.169897%, train loss: 2.678309, norm: 2.2467\n",
            "Train Progress: 0.169952%, train loss: 2.684810, norm: 2.5410\n",
            "valid loss: 2.674428\n",
            "Train Progress: 0.170006%, train loss: 2.628936, norm: 3.7177\n",
            "Train Progress: 0.170061%, train loss: 2.516056, norm: 2.9539\n",
            "Train Progress: 0.170115%, train loss: 2.538902, norm: 2.5996\n",
            "Train Progress: 0.170170%, train loss: 2.727130, norm: 2.9697\n",
            "Train Progress: 0.170224%, train loss: 2.545952, norm: 2.8634\n",
            "valid loss: 2.672910\n",
            "Train Progress: 0.170279%, train loss: 2.660196, norm: 3.4338\n",
            "Train Progress: 0.170333%, train loss: 2.610924, norm: 2.5590\n",
            "Train Progress: 0.170388%, train loss: 2.684878, norm: 3.0163\n",
            "Train Progress: 0.170443%, train loss: 2.660146, norm: 2.6328\n",
            "Train Progress: 0.170497%, train loss: 2.713138, norm: 2.7703\n",
            "valid loss: 2.674772\n",
            "Train Progress: 0.170552%, train loss: 2.684025, norm: 2.9298\n",
            "Train Progress: 0.170606%, train loss: 2.640575, norm: 2.9542\n",
            "Train Progress: 0.170661%, train loss: 2.567003, norm: 2.8522\n",
            "Train Progress: 0.170715%, train loss: 2.723300, norm: 3.2548\n",
            "Train Progress: 0.170770%, train loss: 2.744613, norm: 2.0904\n",
            "valid loss: 2.673348\n",
            "Train Progress: 0.170824%, train loss: 2.752668, norm: 1.7811\n",
            "Train Progress: 0.170879%, train loss: 2.691535, norm: 2.9993\n",
            "Train Progress: 0.170933%, train loss: 2.291584, norm: 3.2223\n",
            "Train Progress: 0.170988%, train loss: 2.239389, norm: 3.1350\n",
            "Train Progress: 0.171042%, train loss: 2.611391, norm: 3.9011\n",
            "valid loss: 2.676198\n",
            "Train Progress: 0.171097%, train loss: 2.644209, norm: 2.5615\n",
            "Train Progress: 0.171152%, train loss: 2.689771, norm: 1.9116\n",
            "Train Progress: 0.171206%, train loss: 2.648281, norm: 3.5015\n",
            "Train Progress: 0.171261%, train loss: 2.745064, norm: 2.6142\n",
            "Train Progress: 0.171315%, train loss: 2.700932, norm: 2.8772\n",
            "valid loss: 2.675194\n",
            "Train Progress: 0.171370%, train loss: 2.663630, norm: 3.7776\n",
            "Train Progress: 0.171424%, train loss: 2.761429, norm: 3.6358\n",
            "Train Progress: 0.171479%, train loss: 2.482354, norm: 2.7181\n",
            "Train Progress: 0.171533%, train loss: 2.448139, norm: 2.7262\n",
            "Train Progress: 0.171588%, train loss: 2.744205, norm: 2.8243\n",
            "valid loss: 2.673530\n",
            "Train Progress: 0.171642%, train loss: 2.365506, norm: 2.9832\n",
            "Train Progress: 0.171697%, train loss: 2.742809, norm: 2.0335\n",
            "Train Progress: 0.171751%, train loss: 2.694874, norm: 2.8096\n",
            "Train Progress: 0.171806%, train loss: 2.661381, norm: 3.5312\n",
            "Train Progress: 0.171861%, train loss: 2.562846, norm: 3.2713\n",
            "valid loss: 2.675430\n",
            "Train Progress: 0.171915%, train loss: 2.725992, norm: 2.2325\n",
            "Train Progress: 0.171970%, train loss: 2.659165, norm: 2.6846\n",
            "Train Progress: 0.172024%, train loss: 2.688371, norm: 2.6088\n",
            "Train Progress: 0.172079%, train loss: 2.778971, norm: 3.3797\n",
            "Train Progress: 0.172133%, train loss: 2.626297, norm: 2.0936\n",
            "valid loss: 2.673174\n",
            "Train Progress: 0.172188%, train loss: 2.697473, norm: 2.7340\n",
            "Train Progress: 0.172242%, train loss: 2.672676, norm: 2.2562\n",
            "Train Progress: 0.172297%, train loss: 2.752627, norm: 4.0431\n",
            "Train Progress: 0.172351%, train loss: 2.543218, norm: 3.2120\n",
            "Train Progress: 0.172406%, train loss: 2.655760, norm: 4.3176\n",
            "valid loss: 2.675060\n",
            "Train Progress: 0.172460%, train loss: 2.523153, norm: 4.1421\n",
            "Train Progress: 0.172515%, train loss: 2.725401, norm: 3.5210\n",
            "Train Progress: 0.172570%, train loss: 2.550503, norm: 3.4045\n",
            "Train Progress: 0.172624%, train loss: 2.682850, norm: 2.6102\n",
            "Train Progress: 0.172679%, train loss: 2.631763, norm: 2.5155\n",
            "valid loss: 2.676528\n",
            "Train Progress: 0.172733%, train loss: 2.463093, norm: 3.9789\n",
            "Train Progress: 0.172788%, train loss: 2.755880, norm: 2.4908\n",
            "Train Progress: 0.172842%, train loss: 2.542615, norm: 2.4928\n",
            "Train Progress: 0.172897%, train loss: 2.589182, norm: 2.6624\n",
            "Train Progress: 0.172951%, train loss: 2.451088, norm: 2.5871\n",
            "valid loss: 2.673268\n",
            "Train Progress: 0.173006%, train loss: 2.726624, norm: 2.5753\n",
            "Train Progress: 0.173060%, train loss: 2.593220, norm: 2.7486\n",
            "Train Progress: 0.173115%, train loss: 2.483639, norm: 4.2701\n",
            "Train Progress: 0.173169%, train loss: 2.703427, norm: 1.8517\n",
            "Train Progress: 0.173224%, train loss: 2.720679, norm: 1.5867\n",
            "valid loss: 2.675553\n",
            "Train Progress: 0.173279%, train loss: 2.593903, norm: 2.1972\n",
            "Train Progress: 0.173333%, train loss: 2.660831, norm: 2.7868\n",
            "Train Progress: 0.173388%, train loss: 2.541403, norm: 2.7335\n",
            "Train Progress: 0.173442%, train loss: 2.679024, norm: 2.2687\n",
            "Train Progress: 0.173497%, train loss: 2.586152, norm: 2.4117\n",
            "valid loss: 2.670636\n",
            "Train Progress: 0.173551%, train loss: 2.597583, norm: 2.8670\n",
            "Train Progress: 0.173606%, train loss: 2.637025, norm: 2.9800\n",
            "Train Progress: 0.173660%, train loss: 2.576408, norm: 3.5647\n",
            "Train Progress: 0.173715%, train loss: 2.679951, norm: 2.4140\n",
            "Train Progress: 0.173769%, train loss: 2.622816, norm: 2.2982\n",
            "valid loss: 2.666018\n",
            "Train Progress: 0.173824%, train loss: 2.717305, norm: 2.5915\n",
            "Train Progress: 0.173878%, train loss: 2.602985, norm: 2.8803\n",
            "Train Progress: 0.173933%, train loss: 2.507893, norm: 3.1128\n",
            "Train Progress: 0.173987%, train loss: 2.622702, norm: 2.9648\n",
            "Train Progress: 0.174042%, train loss: 2.686263, norm: 2.4918\n",
            "valid loss: 2.667877\n",
            "Train Progress: 0.174097%, train loss: 2.378335, norm: 2.7782\n",
            "Train Progress: 0.174151%, train loss: 2.716972, norm: 2.5137\n",
            "Train Progress: 0.174206%, train loss: 2.775455, norm: 2.4625\n",
            "Train Progress: 0.174260%, train loss: 2.353414, norm: 3.6132\n",
            "Train Progress: 0.174315%, train loss: 2.693643, norm: 3.1638\n",
            "valid loss: 2.662919\n",
            "Train Progress: 0.174369%, train loss: 2.658659, norm: 2.4236\n",
            "Train Progress: 0.174424%, train loss: 2.725841, norm: 2.7069\n",
            "Train Progress: 0.174478%, train loss: 2.430523, norm: 3.9407\n",
            "Train Progress: 0.174533%, train loss: 2.711894, norm: 4.3297\n",
            "Train Progress: 0.174587%, train loss: 2.667282, norm: 3.2232\n",
            "valid loss: 2.668088\n",
            "Train Progress: 0.174642%, train loss: 2.614058, norm: 3.5006\n",
            "Train Progress: 0.174696%, train loss: 2.728370, norm: 2.3172\n",
            "Train Progress: 0.174751%, train loss: 2.393302, norm: 4.2226\n",
            "Train Progress: 0.174806%, train loss: 2.691782, norm: 2.8058\n",
            "Train Progress: 0.174860%, train loss: 2.304645, norm: 4.4566\n",
            "valid loss: 2.662736\n",
            "Train Progress: 0.174915%, train loss: 2.452319, norm: 3.8157\n",
            "Train Progress: 0.174969%, train loss: 2.675594, norm: 5.9059\n",
            "Train Progress: 0.175024%, train loss: 2.657511, norm: 3.4052\n",
            "Train Progress: 0.175078%, train loss: 2.432703, norm: 3.9436\n",
            "Train Progress: 0.175133%, train loss: 2.713495, norm: 1.7779\n",
            "valid loss: 2.667472\n",
            "Train Progress: 0.175187%, train loss: 2.723002, norm: 3.0843\n",
            "Train Progress: 0.175242%, train loss: 2.747582, norm: 1.6558\n",
            "Train Progress: 0.175296%, train loss: 2.611979, norm: 2.1852\n",
            "Train Progress: 0.175351%, train loss: 2.668656, norm: 2.0009\n",
            "Train Progress: 0.175405%, train loss: 2.653103, norm: 2.2582\n",
            "valid loss: 2.665227\n",
            "Train Progress: 0.175460%, train loss: 2.390546, norm: 2.9208\n",
            "Train Progress: 0.175515%, train loss: 2.660622, norm: 4.6011\n",
            "Train Progress: 0.175569%, train loss: 2.709845, norm: 3.0855\n",
            "Train Progress: 0.175624%, train loss: 2.736578, norm: 2.5929\n",
            "Train Progress: 0.175678%, train loss: 2.326482, norm: 4.0003\n",
            "valid loss: 2.667369\n",
            "Train Progress: 0.175733%, train loss: 2.649675, norm: 3.2075\n",
            "Train Progress: 0.175787%, train loss: 2.663719, norm: 2.5524\n",
            "Train Progress: 0.175842%, train loss: 2.705015, norm: 3.3035\n",
            "Train Progress: 0.175896%, train loss: 2.604027, norm: 2.2933\n",
            "Train Progress: 0.175951%, train loss: 2.492834, norm: 2.7019\n",
            "valid loss: 2.668049\n",
            "Train Progress: 0.176005%, train loss: 2.686993, norm: 2.2970\n",
            "Train Progress: 0.176060%, train loss: 2.619566, norm: 2.1587\n",
            "Train Progress: 0.176114%, train loss: 2.470997, norm: 3.4018\n",
            "Train Progress: 0.176169%, train loss: 2.742926, norm: 2.6117\n",
            "Train Progress: 0.176224%, train loss: 2.728845, norm: 2.3863\n",
            "valid loss: 2.669120\n",
            "Train Progress: 0.176278%, train loss: 2.492068, norm: 4.5651\n",
            "Train Progress: 0.176333%, train loss: 2.533494, norm: 2.6911\n",
            "Train Progress: 0.176387%, train loss: 2.704041, norm: 2.4044\n",
            "Train Progress: 0.176442%, train loss: 2.654732, norm: 3.7727\n",
            "Train Progress: 0.176496%, train loss: 2.744942, norm: 2.3467\n",
            "valid loss: 2.669267\n",
            "Train Progress: 0.176551%, train loss: 2.606181, norm: 2.8274\n",
            "Train Progress: 0.176605%, train loss: 2.714477, norm: 1.4445\n",
            "Train Progress: 0.176660%, train loss: 2.583694, norm: 2.4170\n",
            "Train Progress: 0.176714%, train loss: 2.556560, norm: 3.0153\n",
            "Train Progress: 0.176769%, train loss: 2.699832, norm: 2.6116\n",
            "valid loss: 2.667576\n",
            "Train Progress: 0.176823%, train loss: 2.702594, norm: 3.2290\n",
            "Train Progress: 0.176878%, train loss: 2.549379, norm: 2.5973\n",
            "Train Progress: 0.176933%, train loss: 2.576351, norm: 3.2692\n",
            "Train Progress: 0.176987%, train loss: 2.690589, norm: 3.0710\n",
            "Train Progress: 0.177042%, train loss: 2.662607, norm: 1.9022\n",
            "valid loss: 2.674542\n",
            "Train Progress: 0.177096%, train loss: 2.707489, norm: 2.5716\n",
            "Train Progress: 0.177151%, train loss: 2.570634, norm: 2.2501\n",
            "Train Progress: 0.177205%, train loss: 2.643671, norm: 2.7954\n",
            "Train Progress: 0.177260%, train loss: 2.718224, norm: 1.9116\n",
            "Train Progress: 0.177314%, train loss: 2.635480, norm: 2.9341\n",
            "valid loss: 2.676607\n",
            "Train Progress: 0.177369%, train loss: 2.639369, norm: 2.8977\n",
            "Train Progress: 0.177423%, train loss: 2.525779, norm: 2.7095\n",
            "Train Progress: 0.177478%, train loss: 2.695226, norm: 2.4832\n",
            "Train Progress: 0.177532%, train loss: 2.730338, norm: 2.7234\n",
            "Train Progress: 0.177587%, train loss: 2.655768, norm: 2.5488\n",
            "valid loss: 2.671118\n",
            "Train Progress: 0.177642%, train loss: 2.605768, norm: 3.6006\n",
            "Train Progress: 0.177696%, train loss: 2.702564, norm: 3.1208\n",
            "Train Progress: 0.177751%, train loss: 2.587327, norm: 2.9913\n",
            "Train Progress: 0.177805%, train loss: 2.249132, norm: 3.8792\n",
            "Train Progress: 0.177860%, train loss: 2.567161, norm: 2.0957\n",
            "valid loss: 2.671086\n",
            "Train Progress: 0.177914%, train loss: 2.709448, norm: 2.7179\n",
            "Train Progress: 0.177969%, train loss: 2.458251, norm: 2.6550\n",
            "Train Progress: 0.178023%, train loss: 2.271251, norm: 2.2151\n",
            "Train Progress: 0.178078%, train loss: 2.382599, norm: 2.6037\n",
            "Train Progress: 0.178132%, train loss: 2.720738, norm: 2.8342\n",
            "valid loss: 2.668650\n",
            "Train Progress: 0.178187%, train loss: 2.390111, norm: 2.2959\n",
            "Train Progress: 0.178241%, train loss: 2.550195, norm: 3.1596\n",
            "Train Progress: 0.178296%, train loss: 2.694408, norm: 3.3541\n",
            "Train Progress: 0.178351%, train loss: 2.531744, norm: 2.4077\n",
            "Train Progress: 0.178405%, train loss: 2.634960, norm: 2.1415\n",
            "valid loss: 2.672614\n",
            "Train Progress: 0.178460%, train loss: 2.705430, norm: 2.4664\n",
            "Train Progress: 0.178514%, train loss: 2.718185, norm: 2.5071\n",
            "Train Progress: 0.178569%, train loss: 2.669729, norm: 3.5370\n",
            "Train Progress: 0.178623%, train loss: 2.475838, norm: 2.6746\n",
            "Train Progress: 0.178678%, train loss: 2.454959, norm: 2.5982\n",
            "valid loss: 2.670109\n",
            "Train Progress: 0.178732%, train loss: 2.592467, norm: 2.4078\n",
            "Train Progress: 0.178787%, train loss: 2.567338, norm: 2.7318\n",
            "Train Progress: 0.178841%, train loss: 2.733032, norm: 2.6774\n",
            "Train Progress: 0.178896%, train loss: 2.633786, norm: 3.2621\n",
            "Train Progress: 0.178950%, train loss: 2.600484, norm: 4.0850\n",
            "valid loss: 2.669990\n",
            "Train Progress: 0.179005%, train loss: 2.738379, norm: 2.2990\n",
            "Train Progress: 0.179060%, train loss: 2.697439, norm: 3.6427\n",
            "Train Progress: 0.179114%, train loss: 2.661913, norm: 3.3673\n",
            "Train Progress: 0.179169%, train loss: 2.573704, norm: 2.9692\n",
            "Train Progress: 0.179223%, train loss: 2.704397, norm: 3.1825\n",
            "valid loss: 2.668978\n",
            "Train Progress: 0.179278%, train loss: 2.659791, norm: 3.0464\n",
            "Train Progress: 0.179332%, train loss: 2.684996, norm: 2.8190\n",
            "Train Progress: 0.179387%, train loss: 2.697605, norm: 2.2697\n",
            "Train Progress: 0.179441%, train loss: 2.759747, norm: 2.5604\n",
            "Train Progress: 0.179496%, train loss: 2.606831, norm: 3.5674\n",
            "valid loss: 2.667672\n",
            "Train Progress: 0.179550%, train loss: 2.719557, norm: 3.7671\n",
            "Train Progress: 0.179605%, train loss: 2.696884, norm: 3.0320\n",
            "Train Progress: 0.179659%, train loss: 2.495559, norm: 3.5615\n",
            "Train Progress: 0.179714%, train loss: 2.161057, norm: 3.4463\n",
            "Train Progress: 0.179769%, train loss: 2.547619, norm: 3.3783\n",
            "valid loss: 2.669264\n",
            "Train Progress: 0.179823%, train loss: 2.647546, norm: 2.0850\n",
            "Train Progress: 0.179878%, train loss: 2.698500, norm: 3.1633\n",
            "Train Progress: 0.179932%, train loss: 2.707286, norm: 4.4590\n",
            "Train Progress: 0.179987%, train loss: 2.532568, norm: 3.0011\n",
            "Train Progress: 0.180041%, train loss: 2.359854, norm: 3.5867\n",
            "valid loss: 2.667706\n",
            "Train Progress: 0.180096%, train loss: 2.720146, norm: 3.8269\n",
            "Train Progress: 0.180150%, train loss: 2.695471, norm: 3.0422\n",
            "Train Progress: 0.180205%, train loss: 2.715053, norm: 2.7189\n",
            "Train Progress: 0.180259%, train loss: 2.647634, norm: 4.2941\n",
            "Train Progress: 0.180314%, train loss: 2.464140, norm: 3.4261\n",
            "valid loss: 2.671714\n",
            "Train Progress: 0.180368%, train loss: 2.706317, norm: 3.7530\n",
            "Train Progress: 0.180423%, train loss: 2.741295, norm: 2.6511\n",
            "Train Progress: 0.180478%, train loss: 2.630699, norm: 4.1001\n",
            "Train Progress: 0.180532%, train loss: 2.688573, norm: 3.0445\n",
            "Train Progress: 0.180587%, train loss: 2.624401, norm: 3.2981\n",
            "valid loss: 2.671808\n",
            "Train Progress: 0.180641%, train loss: 2.593550, norm: 3.6915\n",
            "Train Progress: 0.180696%, train loss: 2.683786, norm: 4.2763\n",
            "Train Progress: 0.180750%, train loss: 2.385434, norm: 2.6798\n",
            "Train Progress: 0.180805%, train loss: 2.660880, norm: 2.8453\n",
            "Train Progress: 0.180859%, train loss: 2.647213, norm: 2.6773\n",
            "valid loss: 2.669427\n",
            "Train Progress: 0.180914%, train loss: 2.512281, norm: 2.9553\n",
            "Train Progress: 0.180968%, train loss: 2.558398, norm: 2.6996\n",
            "Train Progress: 0.181023%, train loss: 2.610574, norm: 2.1648\n",
            "Train Progress: 0.181077%, train loss: 2.788098, norm: 2.6157\n",
            "Train Progress: 0.181132%, train loss: 2.268645, norm: 4.0530\n",
            "valid loss: 2.663527\n",
            "Train Progress: 0.181187%, train loss: 2.503216, norm: 4.0684\n",
            "Train Progress: 0.181241%, train loss: 2.599862, norm: 2.7280\n",
            "Train Progress: 0.181296%, train loss: 2.662767, norm: 3.1380\n",
            "Train Progress: 0.181350%, train loss: 2.664436, norm: 2.5872\n",
            "Train Progress: 0.181405%, train loss: 2.593199, norm: 2.9847\n",
            "valid loss: 2.664175\n",
            "Train Progress: 0.181459%, train loss: 2.700843, norm: 2.2682\n",
            "Train Progress: 0.181514%, train loss: 2.732757, norm: 3.3568\n",
            "Train Progress: 0.181568%, train loss: 2.358798, norm: 4.0736\n",
            "Train Progress: 0.181623%, train loss: 2.637614, norm: 3.6242\n",
            "Train Progress: 0.181677%, train loss: 2.642878, norm: 3.4826\n",
            "valid loss: 2.664211\n",
            "Train Progress: 0.181732%, train loss: 2.667733, norm: 2.5983\n",
            "Train Progress: 0.181786%, train loss: 2.515130, norm: 3.1386\n",
            "Train Progress: 0.181841%, train loss: 2.766799, norm: 1.8478\n",
            "Train Progress: 0.181896%, train loss: 2.771189, norm: 3.2410\n",
            "Train Progress: 0.181950%, train loss: 2.687960, norm: 2.3222\n",
            "valid loss: 2.656762\n",
            "Train Progress: 0.182005%, train loss: 2.703086, norm: 2.5614\n",
            "Train Progress: 0.182059%, train loss: 2.267066, norm: 4.1344\n",
            "Train Progress: 0.182114%, train loss: 2.619846, norm: 2.7888\n",
            "Train Progress: 0.182168%, train loss: 2.722097, norm: 3.2586\n",
            "Train Progress: 0.182223%, train loss: 2.484630, norm: 2.4476\n",
            "valid loss: 2.651529\n",
            "Train Progress: 0.182277%, train loss: 2.239633, norm: 3.7795\n",
            "Train Progress: 0.182332%, train loss: 2.647153, norm: 2.7776\n",
            "Train Progress: 0.182386%, train loss: 2.743386, norm: 3.7340\n",
            "Train Progress: 0.182441%, train loss: 2.660819, norm: 2.7245\n",
            "Train Progress: 0.182495%, train loss: 2.730683, norm: 1.9999\n",
            "valid loss: 2.655147\n",
            "Train Progress: 0.182550%, train loss: 2.609207, norm: 3.5275\n",
            "Train Progress: 0.182605%, train loss: 2.211959, norm: 3.8832\n",
            "Train Progress: 0.182659%, train loss: 2.721318, norm: 3.1661\n",
            "Train Progress: 0.182714%, train loss: 2.714850, norm: 2.3549\n",
            "Train Progress: 0.182768%, train loss: 2.708282, norm: 2.6253\n",
            "valid loss: 2.652399\n",
            "Train Progress: 0.182823%, train loss: 2.678864, norm: 2.3392\n",
            "Train Progress: 0.182877%, train loss: 2.129715, norm: 4.5713\n",
            "Train Progress: 0.182932%, train loss: 2.590636, norm: 2.4645\n",
            "Train Progress: 0.182986%, train loss: 2.756158, norm: 2.7638\n",
            "Train Progress: 0.183041%, train loss: 2.649909, norm: 2.3362\n",
            "valid loss: 2.651904\n",
            "Train Progress: 0.183095%, train loss: 2.635272, norm: 3.3273\n",
            "Train Progress: 0.183150%, train loss: 2.654706, norm: 1.9609\n",
            "Train Progress: 0.183204%, train loss: 2.547140, norm: 2.7634\n",
            "Train Progress: 0.183259%, train loss: 2.717934, norm: 3.4330\n",
            "Train Progress: 0.183314%, train loss: 2.762223, norm: 1.8779\n",
            "valid loss: 2.652311\n",
            "Train Progress: 0.183368%, train loss: 2.593386, norm: 2.1648\n",
            "Train Progress: 0.183423%, train loss: 2.393460, norm: 3.8139\n",
            "Train Progress: 0.183477%, train loss: 2.702613, norm: 2.9922\n",
            "Train Progress: 0.183532%, train loss: 2.703261, norm: 3.0391\n",
            "Train Progress: 0.183586%, train loss: 2.444700, norm: 3.4433\n",
            "valid loss: 2.646561\n",
            "Train Progress: 0.183641%, train loss: 2.586694, norm: 3.8372\n",
            "Train Progress: 0.183695%, train loss: 2.705053, norm: 2.9611\n",
            "Train Progress: 0.183750%, train loss: 2.617783, norm: 2.2228\n",
            "Train Progress: 0.183804%, train loss: 2.751690, norm: 2.8281\n",
            "Train Progress: 0.183859%, train loss: 2.655747, norm: 2.4396\n",
            "valid loss: 2.657443\n",
            "Train Progress: 0.183913%, train loss: 2.747485, norm: 1.5494\n",
            "Train Progress: 0.183968%, train loss: 2.741646, norm: 2.3809\n",
            "Train Progress: 0.184023%, train loss: 2.317333, norm: 3.0023\n",
            "Train Progress: 0.184077%, train loss: 2.701317, norm: 2.0212\n",
            "Train Progress: 0.184132%, train loss: 2.406971, norm: 2.6222\n",
            "valid loss: 2.652135\n",
            "Train Progress: 0.184186%, train loss: 2.721566, norm: 3.1036\n",
            "Train Progress: 0.184241%, train loss: 2.741651, norm: 3.0639\n",
            "Train Progress: 0.184295%, train loss: 2.468548, norm: 3.8843\n",
            "Train Progress: 0.184350%, train loss: 2.714128, norm: 2.2232\n",
            "Train Progress: 0.184404%, train loss: 2.788734, norm: 2.1103\n",
            "valid loss: 2.655620\n",
            "Train Progress: 0.184459%, train loss: 2.538486, norm: 2.5377\n",
            "Train Progress: 0.184513%, train loss: 2.651993, norm: 2.7822\n",
            "Train Progress: 0.184568%, train loss: 2.710795, norm: 2.2953\n",
            "Train Progress: 0.184622%, train loss: 2.697821, norm: 1.8226\n",
            "Train Progress: 0.184677%, train loss: 2.550904, norm: 3.4425\n",
            "valid loss: 2.650680\n",
            "Train Progress: 0.184732%, train loss: 2.581902, norm: 2.8983\n",
            "Train Progress: 0.184786%, train loss: 2.634977, norm: 2.3369\n",
            "Train Progress: 0.184841%, train loss: 2.603409, norm: 2.4438\n",
            "Train Progress: 0.184895%, train loss: 2.556990, norm: 2.8176\n",
            "Train Progress: 0.184950%, train loss: 2.701491, norm: 4.0649\n",
            "valid loss: 2.654638\n",
            "Train Progress: 0.185004%, train loss: 2.380561, norm: 3.0754\n",
            "Train Progress: 0.185059%, train loss: 2.608229, norm: 3.1474\n",
            "Train Progress: 0.185113%, train loss: 2.390283, norm: 3.2738\n",
            "Train Progress: 0.185168%, train loss: 2.749160, norm: 3.1090\n",
            "Train Progress: 0.185222%, train loss: 2.484924, norm: 2.7801\n",
            "valid loss: 2.651029\n",
            "Train Progress: 0.185277%, train loss: 2.707187, norm: 3.2521\n",
            "Train Progress: 0.185331%, train loss: 2.655230, norm: 2.8547\n",
            "Train Progress: 0.185386%, train loss: 2.416039, norm: 3.2695\n",
            "Train Progress: 0.185441%, train loss: 2.677251, norm: 2.6878\n",
            "Train Progress: 0.185495%, train loss: 2.647319, norm: 2.5440\n",
            "valid loss: 2.654392\n",
            "Train Progress: 0.185550%, train loss: 2.650263, norm: 3.0823\n",
            "Train Progress: 0.185604%, train loss: 2.742954, norm: 2.8881\n",
            "Train Progress: 0.185659%, train loss: 2.743043, norm: 5.3848\n",
            "Train Progress: 0.185713%, train loss: 2.697253, norm: 3.9639\n",
            "Train Progress: 0.185768%, train loss: 2.504272, norm: 2.8853\n",
            "valid loss: 2.651505\n",
            "Train Progress: 0.185822%, train loss: 2.638868, norm: 3.3849\n",
            "Train Progress: 0.185877%, train loss: 2.712396, norm: 3.7015\n",
            "Train Progress: 0.185931%, train loss: 2.752554, norm: 2.2769\n",
            "Train Progress: 0.185986%, train loss: 2.627693, norm: 2.7854\n",
            "Train Progress: 0.186040%, train loss: 2.680233, norm: 3.6273\n",
            "valid loss: 2.654719\n",
            "Train Progress: 0.186095%, train loss: 2.622247, norm: 3.1202\n",
            "Train Progress: 0.186149%, train loss: 2.716745, norm: 2.9505\n",
            "Train Progress: 0.186204%, train loss: 2.757606, norm: 3.7724\n",
            "Train Progress: 0.186259%, train loss: 2.672222, norm: 3.6486\n",
            "Train Progress: 0.186313%, train loss: 2.733971, norm: 2.0066\n",
            "valid loss: 2.650326\n",
            "Train Progress: 0.186368%, train loss: 2.639174, norm: 3.9888\n",
            "Train Progress: 0.186422%, train loss: 2.686294, norm: 2.4611\n",
            "Train Progress: 0.186477%, train loss: 2.358422, norm: 3.1427\n",
            "Train Progress: 0.186531%, train loss: 2.641634, norm: 4.3593\n",
            "Train Progress: 0.186586%, train loss: 2.646095, norm: 3.2403\n",
            "valid loss: 2.647584\n",
            "Train Progress: 0.186640%, train loss: 2.645278, norm: 3.1017\n",
            "Train Progress: 0.186695%, train loss: 2.647671, norm: 3.3364\n",
            "Train Progress: 0.186749%, train loss: 2.322121, norm: 4.3210\n",
            "Train Progress: 0.186804%, train loss: 2.691531, norm: 3.1290\n",
            "Train Progress: 0.186858%, train loss: 2.588066, norm: 2.7710\n",
            "valid loss: 2.654922\n",
            "Train Progress: 0.186913%, train loss: 2.669084, norm: 2.5031\n",
            "Train Progress: 0.186968%, train loss: 2.553608, norm: 3.0943\n",
            "Train Progress: 0.187022%, train loss: 2.532311, norm: 3.1950\n",
            "Train Progress: 0.187077%, train loss: 2.698290, norm: 3.8447\n",
            "Train Progress: 0.187131%, train loss: 2.715745, norm: 2.8958\n",
            "valid loss: 2.651122\n",
            "Train Progress: 0.187186%, train loss: 2.527005, norm: 3.4417\n",
            "Train Progress: 0.187240%, train loss: 2.571350, norm: 2.8167\n",
            "Train Progress: 0.187295%, train loss: 2.548140, norm: 2.8369\n",
            "Train Progress: 0.187349%, train loss: 2.703125, norm: 2.5517\n",
            "Train Progress: 0.187404%, train loss: 2.648124, norm: 2.8544\n",
            "valid loss: 2.653099\n",
            "Train Progress: 0.187458%, train loss: 2.631278, norm: 2.8493\n",
            "Train Progress: 0.187513%, train loss: 2.722490, norm: 2.3435\n",
            "Train Progress: 0.187567%, train loss: 2.346143, norm: 3.2983\n",
            "Train Progress: 0.187622%, train loss: 2.500558, norm: 3.1724\n",
            "Train Progress: 0.187677%, train loss: 2.580923, norm: 2.7092\n",
            "valid loss: 2.655491\n",
            "Train Progress: 0.187731%, train loss: 2.667502, norm: 2.4357\n",
            "Train Progress: 0.187786%, train loss: 2.718333, norm: 3.0933\n",
            "Train Progress: 0.187840%, train loss: 2.735565, norm: 2.5956\n",
            "Train Progress: 0.187895%, train loss: 2.611572, norm: 2.6844\n",
            "Train Progress: 0.187949%, train loss: 2.600316, norm: 2.7387\n",
            "valid loss: 2.655485\n",
            "Train Progress: 0.188004%, train loss: 2.594474, norm: 3.0315\n",
            "Train Progress: 0.188058%, train loss: 2.735456, norm: 3.3785\n",
            "Train Progress: 0.188113%, train loss: 2.641419, norm: 3.6575\n",
            "Train Progress: 0.188167%, train loss: 2.721228, norm: 2.4290\n",
            "Train Progress: 0.188222%, train loss: 2.739568, norm: 2.7535\n",
            "valid loss: 2.657813\n",
            "Train Progress: 0.188276%, train loss: 2.655365, norm: 2.4544\n",
            "Train Progress: 0.188331%, train loss: 2.723427, norm: 3.0082\n",
            "Train Progress: 0.188386%, train loss: 2.584013, norm: 3.5763\n",
            "Train Progress: 0.188440%, train loss: 2.735348, norm: 4.1330\n",
            "Train Progress: 0.188495%, train loss: 2.659852, norm: 4.6142\n",
            "valid loss: 2.648789\n",
            "Train Progress: 0.188549%, train loss: 2.716372, norm: 2.8652\n",
            "Train Progress: 0.188604%, train loss: 2.642202, norm: 2.8559\n",
            "Train Progress: 0.188658%, train loss: 2.597413, norm: 3.8460\n",
            "Train Progress: 0.188713%, train loss: 2.285867, norm: 4.1862\n",
            "Train Progress: 0.188767%, train loss: 2.638469, norm: 3.1779\n",
            "valid loss: 2.648395\n",
            "Train Progress: 0.188822%, train loss: 2.683423, norm: 2.9323\n",
            "Train Progress: 0.188876%, train loss: 2.648807, norm: 2.9114\n",
            "Train Progress: 0.188931%, train loss: 2.571565, norm: 3.1423\n",
            "Train Progress: 0.188985%, train loss: 2.468315, norm: 3.6168\n",
            "Train Progress: 0.189040%, train loss: 2.631743, norm: 2.8871\n",
            "valid loss: 2.648502\n",
            "Train Progress: 0.189095%, train loss: 2.517792, norm: 3.3215\n",
            "Train Progress: 0.189149%, train loss: 2.654690, norm: 2.9632\n",
            "Train Progress: 0.189204%, train loss: 2.303321, norm: 3.6546\n",
            "Train Progress: 0.189258%, train loss: 2.513494, norm: 3.5001\n",
            "Train Progress: 0.189313%, train loss: 2.516516, norm: 3.2890\n",
            "valid loss: 2.648515\n",
            "Train Progress: 0.189367%, train loss: 2.417806, norm: 2.8910\n",
            "Train Progress: 0.189422%, train loss: 2.523515, norm: 2.9461\n",
            "Train Progress: 0.189476%, train loss: 2.704638, norm: 2.2233\n",
            "Train Progress: 0.189531%, train loss: 2.620192, norm: 4.3280\n",
            "Train Progress: 0.189585%, train loss: 2.801552, norm: 3.7104\n",
            "valid loss: 2.646920\n",
            "Train Progress: 0.189640%, train loss: 2.716425, norm: 2.2984\n",
            "Train Progress: 0.189694%, train loss: 2.299859, norm: 3.0356\n",
            "Train Progress: 0.189749%, train loss: 2.748007, norm: 1.4219\n",
            "Train Progress: 0.189804%, train loss: 2.643335, norm: 3.3859\n",
            "Train Progress: 0.189858%, train loss: 2.665026, norm: 2.6693\n",
            "valid loss: 2.653052\n",
            "Train Progress: 0.189913%, train loss: 2.585637, norm: 3.1655\n",
            "Train Progress: 0.189967%, train loss: 2.698901, norm: 2.9742\n",
            "Train Progress: 0.190022%, train loss: 2.696028, norm: 3.3176\n",
            "Train Progress: 0.190076%, train loss: 2.589649, norm: 4.2086\n",
            "Train Progress: 0.190131%, train loss: 2.704372, norm: 3.3783\n",
            "valid loss: 2.648682\n",
            "Train Progress: 0.190185%, train loss: 2.457790, norm: 3.6505\n",
            "Train Progress: 0.190240%, train loss: 2.754358, norm: 2.4267\n",
            "Train Progress: 0.190294%, train loss: 2.735501, norm: 3.3085\n",
            "Train Progress: 0.190349%, train loss: 2.514970, norm: 2.7038\n",
            "Train Progress: 0.190403%, train loss: 2.768706, norm: 3.1626\n",
            "valid loss: 2.643223\n",
            "Train Progress: 0.190458%, train loss: 2.715460, norm: 2.9135\n",
            "Train Progress: 0.190513%, train loss: 2.784992, norm: 2.2334\n",
            "Train Progress: 0.190567%, train loss: 2.579191, norm: 3.0160\n",
            "Train Progress: 0.190622%, train loss: 2.423387, norm: 3.9506\n",
            "Train Progress: 0.190676%, train loss: 2.587255, norm: 3.0525\n",
            "valid loss: 2.648201\n",
            "Train Progress: 0.190731%, train loss: 2.736728, norm: 2.2104\n",
            "Train Progress: 0.190785%, train loss: 2.543882, norm: 3.9300\n",
            "Train Progress: 0.190840%, train loss: 2.717451, norm: 4.1273\n",
            "Train Progress: 0.190894%, train loss: 2.733508, norm: 3.5646\n",
            "Train Progress: 0.190949%, train loss: 2.562460, norm: 3.9463\n",
            "valid loss: 2.647482\n",
            "Train Progress: 0.191003%, train loss: 2.569859, norm: 2.7859\n",
            "Train Progress: 0.191058%, train loss: 2.381295, norm: 2.0919\n",
            "Train Progress: 0.191112%, train loss: 2.562329, norm: 3.1662\n",
            "Train Progress: 0.191167%, train loss: 2.638471, norm: 3.0554\n",
            "Train Progress: 0.191222%, train loss: 2.716079, norm: 2.6930\n",
            "valid loss: 2.660269\n",
            "Train Progress: 0.191276%, train loss: 2.491883, norm: 3.8503\n",
            "Train Progress: 0.191331%, train loss: 2.595072, norm: 3.2354\n",
            "Train Progress: 0.191385%, train loss: 2.543728, norm: 3.5222\n",
            "Train Progress: 0.191440%, train loss: 2.681793, norm: 3.4879\n",
            "Train Progress: 0.191494%, train loss: 2.623145, norm: 3.0034\n",
            "valid loss: 2.648801\n",
            "Train Progress: 0.191549%, train loss: 2.669959, norm: 3.8765\n",
            "Train Progress: 0.191603%, train loss: 2.574155, norm: 3.9238\n",
            "Train Progress: 0.191658%, train loss: 2.670695, norm: 2.2223\n",
            "Train Progress: 0.191712%, train loss: 2.714670, norm: 2.9205\n",
            "Train Progress: 0.191767%, train loss: 2.557095, norm: 3.2051\n",
            "valid loss: 2.654085\n",
            "Train Progress: 0.191821%, train loss: 2.606795, norm: 3.5248\n",
            "Train Progress: 0.191876%, train loss: 2.398162, norm: 3.0337\n",
            "Train Progress: 0.191931%, train loss: 2.698063, norm: 2.3328\n",
            "Train Progress: 0.191985%, train loss: 2.723325, norm: 3.5103\n",
            "Train Progress: 0.192040%, train loss: 2.615538, norm: 4.7787\n",
            "valid loss: 2.649469\n",
            "Train Progress: 0.192094%, train loss: 2.726851, norm: 2.4221\n",
            "Train Progress: 0.192149%, train loss: 2.648656, norm: 3.9753\n",
            "Train Progress: 0.192203%, train loss: 2.704101, norm: 1.8026\n",
            "Train Progress: 0.192258%, train loss: 2.648502, norm: 3.1540\n",
            "Train Progress: 0.192312%, train loss: 2.510404, norm: 3.3354\n",
            "valid loss: 2.649167\n",
            "Train Progress: 0.192367%, train loss: 2.680836, norm: 2.3737\n",
            "Train Progress: 0.192421%, train loss: 2.743719, norm: 3.5176\n",
            "Train Progress: 0.192476%, train loss: 2.681193, norm: 4.2133\n",
            "Train Progress: 0.192530%, train loss: 2.739309, norm: 2.8611\n",
            "Train Progress: 0.192585%, train loss: 2.579458, norm: 3.2344\n",
            "valid loss: 2.652901\n",
            "Train Progress: 0.192640%, train loss: 2.662281, norm: 2.6618\n",
            "Train Progress: 0.192694%, train loss: 2.720424, norm: 1.6848\n",
            "Train Progress: 0.192749%, train loss: 2.712780, norm: 3.1472\n",
            "Train Progress: 0.192803%, train loss: 2.765355, norm: 2.4807\n",
            "Train Progress: 0.192858%, train loss: 2.666611, norm: 3.4183\n",
            "valid loss: 2.654585\n",
            "Train Progress: 0.192912%, train loss: 2.260766, norm: 3.5313\n",
            "Train Progress: 0.192967%, train loss: 2.655915, norm: 2.7321\n",
            "Train Progress: 0.193021%, train loss: 2.253675, norm: 4.0182\n",
            "Train Progress: 0.193076%, train loss: 2.681298, norm: 4.1010\n",
            "Train Progress: 0.193130%, train loss: 2.677683, norm: 5.0725\n",
            "valid loss: 2.643049\n",
            "Train Progress: 0.193185%, train loss: 2.719423, norm: 2.9899\n",
            "Train Progress: 0.193239%, train loss: 2.723964, norm: 3.7411\n",
            "Train Progress: 0.193294%, train loss: 2.642299, norm: 2.6101\n",
            "Train Progress: 0.193349%, train loss: 2.628596, norm: 3.5372\n",
            "Train Progress: 0.193403%, train loss: 2.606446, norm: 3.5407\n",
            "valid loss: 2.658193\n",
            "Train Progress: 0.193458%, train loss: 2.444431, norm: 2.6821\n",
            "Train Progress: 0.193512%, train loss: 2.623144, norm: 3.0989\n",
            "Train Progress: 0.193567%, train loss: 2.541728, norm: 2.5954\n",
            "Train Progress: 0.193621%, train loss: 2.667707, norm: 2.8644\n",
            "Train Progress: 0.193676%, train loss: 2.775131, norm: 3.2762\n",
            "valid loss: 2.643525\n",
            "Train Progress: 0.193730%, train loss: 2.498202, norm: 4.0767\n",
            "Train Progress: 0.193785%, train loss: 2.547888, norm: 4.1162\n",
            "Train Progress: 0.193839%, train loss: 2.388296, norm: 2.5099\n",
            "Train Progress: 0.193894%, train loss: 2.588402, norm: 4.8817\n",
            "Train Progress: 0.193948%, train loss: 2.404167, norm: 3.4036\n",
            "valid loss: 2.646917\n",
            "Train Progress: 0.194003%, train loss: 2.377019, norm: 3.2256\n",
            "Train Progress: 0.194058%, train loss: 2.690731, norm: 2.5128\n",
            "Train Progress: 0.194112%, train loss: 2.529429, norm: 4.5229\n",
            "Train Progress: 0.194167%, train loss: 2.536107, norm: 3.7821\n",
            "Train Progress: 0.194221%, train loss: 2.435755, norm: 3.2300\n",
            "valid loss: 2.646171\n",
            "Train Progress: 0.194276%, train loss: 2.557118, norm: 4.3274\n",
            "Train Progress: 0.194330%, train loss: 2.663432, norm: 2.6597\n",
            "Train Progress: 0.194385%, train loss: 2.709093, norm: 2.7815\n",
            "Train Progress: 0.194439%, train loss: 2.599976, norm: 3.3047\n",
            "Train Progress: 0.194494%, train loss: 2.521102, norm: 3.1261\n",
            "valid loss: 2.655856\n",
            "Train Progress: 0.194548%, train loss: 2.578614, norm: 2.7585\n",
            "Train Progress: 0.194603%, train loss: 2.678820, norm: 2.3582\n",
            "Train Progress: 0.194657%, train loss: 2.702950, norm: 4.2511\n",
            "Train Progress: 0.194712%, train loss: 2.733576, norm: 2.1019\n",
            "Train Progress: 0.194767%, train loss: 2.416569, norm: 2.9446\n",
            "valid loss: 2.645531\n",
            "Train Progress: 0.194821%, train loss: 2.731736, norm: 2.7080\n",
            "Train Progress: 0.194876%, train loss: 2.671716, norm: 3.1143\n",
            "Train Progress: 0.194930%, train loss: 2.623435, norm: 3.8635\n",
            "Train Progress: 0.194985%, train loss: 2.526928, norm: 3.6475\n",
            "Train Progress: 0.195039%, train loss: 2.625445, norm: 3.3080\n",
            "valid loss: 2.647605\n",
            "Train Progress: 0.195094%, train loss: 2.778843, norm: 2.3024\n",
            "Train Progress: 0.195148%, train loss: 2.591021, norm: 3.0239\n",
            "Train Progress: 0.195203%, train loss: 2.302261, norm: 3.4712\n",
            "Train Progress: 0.195257%, train loss: 2.443352, norm: 3.0743\n",
            "Train Progress: 0.195312%, train loss: 2.656783, norm: 4.2961\n",
            "valid loss: 2.646215\n",
            "Train Progress: 0.195366%, train loss: 2.588071, norm: 4.8865\n",
            "Train Progress: 0.195421%, train loss: 2.311423, norm: 4.1419\n",
            "Train Progress: 0.195476%, train loss: 2.495495, norm: 3.7893\n",
            "Train Progress: 0.195530%, train loss: 2.673050, norm: 4.5068\n",
            "Train Progress: 0.195585%, train loss: 2.568673, norm: 5.4817\n",
            "valid loss: 2.650020\n",
            "Train Progress: 0.195639%, train loss: 2.397987, norm: 3.2169\n",
            "Train Progress: 0.195694%, train loss: 2.649748, norm: 2.3011\n",
            "Train Progress: 0.195748%, train loss: 2.632017, norm: 2.4221\n",
            "Train Progress: 0.195803%, train loss: 2.616804, norm: 2.6296\n",
            "Train Progress: 0.195857%, train loss: 2.633321, norm: 2.7273\n",
            "valid loss: 2.653921\n",
            "Train Progress: 0.195912%, train loss: 2.679191, norm: 2.9922\n",
            "Train Progress: 0.195966%, train loss: 2.712417, norm: 3.9996\n",
            "Train Progress: 0.196021%, train loss: 2.697837, norm: 2.5384\n",
            "Train Progress: 0.196075%, train loss: 2.466937, norm: 3.2563\n",
            "Train Progress: 0.196130%, train loss: 2.738232, norm: 3.0480\n",
            "valid loss: 2.649909\n",
            "Train Progress: 0.196185%, train loss: 2.634652, norm: 4.5952\n",
            "Train Progress: 0.196239%, train loss: 2.637974, norm: 2.4964\n",
            "Train Progress: 0.196294%, train loss: 2.660291, norm: 2.3711\n",
            "Train Progress: 0.196348%, train loss: 2.488992, norm: 3.7062\n",
            "Train Progress: 0.196403%, train loss: 2.629804, norm: 4.0303\n",
            "valid loss: 2.651298\n",
            "Train Progress: 0.196457%, train loss: 2.657796, norm: 4.5399\n",
            "Train Progress: 0.196512%, train loss: 2.559396, norm: 3.6121\n",
            "Train Progress: 0.196566%, train loss: 2.597595, norm: 2.6058\n",
            "Train Progress: 0.196621%, train loss: 2.677643, norm: 2.9085\n",
            "Train Progress: 0.196675%, train loss: 2.641293, norm: 2.4891\n",
            "valid loss: 2.652253\n",
            "Train Progress: 0.196730%, train loss: 2.633829, norm: 2.3342\n",
            "Train Progress: 0.196784%, train loss: 2.641464, norm: 2.7251\n",
            "Train Progress: 0.196839%, train loss: 2.672797, norm: 3.2058\n",
            "Train Progress: 0.196894%, train loss: 2.656696, norm: 2.8662\n",
            "Train Progress: 0.196948%, train loss: 2.716168, norm: 3.5749\n",
            "valid loss: 2.655737\n",
            "Train Progress: 0.197003%, train loss: 2.512304, norm: 3.9596\n",
            "Train Progress: 0.197057%, train loss: 2.647779, norm: 2.1332\n",
            "Train Progress: 0.197112%, train loss: 2.710289, norm: 2.8860\n",
            "Train Progress: 0.197166%, train loss: 2.719205, norm: 3.2882\n",
            "Train Progress: 0.197221%, train loss: 2.565551, norm: 8.1687\n",
            "valid loss: 2.651466\n",
            "Train Progress: 0.197275%, train loss: 2.628762, norm: 3.5680\n",
            "Train Progress: 0.197330%, train loss: 2.606757, norm: 3.5930\n",
            "Train Progress: 0.197384%, train loss: 2.677323, norm: 2.6656\n",
            "Train Progress: 0.197439%, train loss: 2.619387, norm: 2.3696\n",
            "Train Progress: 0.197493%, train loss: 2.681579, norm: 2.2887\n",
            "valid loss: 2.658021\n",
            "Train Progress: 0.197548%, train loss: 2.488154, norm: 3.1271\n",
            "Train Progress: 0.197603%, train loss: 2.504829, norm: 3.5199\n",
            "Train Progress: 0.197657%, train loss: 2.599113, norm: 4.3956\n",
            "Train Progress: 0.197712%, train loss: 2.534989, norm: 3.3417\n",
            "Train Progress: 0.197766%, train loss: 2.511337, norm: 3.5154\n",
            "valid loss: 2.644618\n",
            "Train Progress: 0.197821%, train loss: 2.724945, norm: 3.6463\n",
            "Train Progress: 0.197875%, train loss: 2.670150, norm: 2.9116\n",
            "Train Progress: 0.197930%, train loss: 2.637093, norm: 3.6510\n",
            "Train Progress: 0.197984%, train loss: 2.407002, norm: 3.5211\n",
            "Train Progress: 0.198039%, train loss: 2.619072, norm: 2.4560\n",
            "valid loss: 2.646104\n",
            "Train Progress: 0.198093%, train loss: 2.731386, norm: 2.4586\n",
            "Train Progress: 0.198148%, train loss: 2.753008, norm: 5.3573\n",
            "Train Progress: 0.198202%, train loss: 2.782321, norm: 2.5567\n",
            "Train Progress: 0.198257%, train loss: 2.650062, norm: 2.8689\n",
            "Train Progress: 0.198311%, train loss: 2.572581, norm: 3.5140\n",
            "valid loss: 2.646911\n",
            "Train Progress: 0.198366%, train loss: 2.739561, norm: 2.2995\n",
            "Train Progress: 0.198421%, train loss: 2.577481, norm: 3.0025\n",
            "Train Progress: 0.198475%, train loss: 2.538526, norm: 3.3467\n",
            "Train Progress: 0.198530%, train loss: 2.597188, norm: 3.1699\n",
            "Train Progress: 0.198584%, train loss: 2.663987, norm: 3.9464\n",
            "valid loss: 2.651836\n",
            "Train Progress: 0.198639%, train loss: 2.411704, norm: 3.4479\n",
            "Train Progress: 0.198693%, train loss: 1.803882, norm: 6.5370\n",
            "Train Progress: 0.198748%, train loss: 2.630321, norm: 3.6857\n",
            "Train Progress: 0.198802%, train loss: 2.381867, norm: 4.0934\n",
            "Train Progress: 0.198857%, train loss: 2.554318, norm: 2.8024\n",
            "valid loss: 2.650748\n",
            "Train Progress: 0.198911%, train loss: 2.721543, norm: 2.9721\n",
            "Train Progress: 0.198966%, train loss: 2.656645, norm: 2.7006\n",
            "Train Progress: 0.199020%, train loss: 2.659061, norm: 3.7086\n",
            "Train Progress: 0.199075%, train loss: 2.705732, norm: 2.8197\n",
            "Train Progress: 0.199130%, train loss: 2.718592, norm: 2.8868\n",
            "valid loss: 2.652111\n",
            "Train Progress: 0.199184%, train loss: 2.563951, norm: 3.6726\n",
            "Train Progress: 0.199239%, train loss: 2.684932, norm: 2.5490\n",
            "Train Progress: 0.199293%, train loss: 2.614325, norm: 2.5644\n",
            "Train Progress: 0.199348%, train loss: 2.670511, norm: 1.9734\n",
            "Train Progress: 0.199402%, train loss: 2.633953, norm: 3.2095\n",
            "valid loss: 2.652569\n",
            "Train Progress: 0.199457%, train loss: 2.669740, norm: 3.0412\n",
            "Train Progress: 0.199511%, train loss: 2.713763, norm: 3.1345\n",
            "Train Progress: 0.199566%, train loss: 2.636925, norm: 4.1970\n",
            "Train Progress: 0.199620%, train loss: 2.393166, norm: 3.6529\n",
            "Train Progress: 0.199675%, train loss: 2.461380, norm: 3.7915\n",
            "valid loss: 2.651451\n",
            "Train Progress: 0.199729%, train loss: 2.745970, norm: 3.9567\n",
            "Train Progress: 0.199784%, train loss: 1.991490, norm: 3.5981\n",
            "Train Progress: 0.199839%, train loss: 2.650139, norm: 3.2641\n",
            "Train Progress: 0.199893%, train loss: 2.785568, norm: 3.9851\n",
            "Train Progress: 0.199948%, train loss: 2.712489, norm: 2.7371\n",
            "valid loss: 2.655675\n",
            "Train Progress: 0.200002%, train loss: 2.609602, norm: 3.3415\n",
            "Train Progress: 0.200057%, train loss: 2.581063, norm: 2.7413\n",
            "Train Progress: 0.200111%, train loss: 2.510521, norm: 3.3431\n",
            "Train Progress: 0.200166%, train loss: 2.614424, norm: 5.3633\n",
            "Train Progress: 0.200220%, train loss: 2.457625, norm: 3.5977\n",
            "valid loss: 2.648453\n",
            "Train Progress: 0.200275%, train loss: 2.699492, norm: 2.9405\n",
            "Train Progress: 0.200329%, train loss: 2.372349, norm: 4.2339\n",
            "Train Progress: 0.200384%, train loss: 2.685760, norm: 3.3736\n",
            "Train Progress: 0.200438%, train loss: 2.760925, norm: 2.3062\n",
            "Train Progress: 0.200493%, train loss: 2.423168, norm: 3.3094\n",
            "valid loss: 2.664510\n",
            "Train Progress: 0.200548%, train loss: 2.530986, norm: 3.0582\n",
            "Train Progress: 0.200602%, train loss: 2.727267, norm: 2.3359\n",
            "Train Progress: 0.200657%, train loss: 2.701573, norm: 1.9101\n",
            "Train Progress: 0.200711%, train loss: 2.444211, norm: 2.5303\n",
            "Train Progress: 0.200766%, train loss: 1.964714, norm: 3.6084\n",
            "valid loss: 2.651924\n",
            "Train Progress: 0.200820%, train loss: 2.627031, norm: 2.9564\n",
            "Train Progress: 0.200875%, train loss: 2.716051, norm: 2.7932\n",
            "Train Progress: 0.200929%, train loss: 2.693335, norm: 3.2686\n",
            "Train Progress: 0.200984%, train loss: 2.690727, norm: 2.6229\n",
            "Train Progress: 0.201038%, train loss: 2.757064, norm: 2.6431\n",
            "valid loss: 2.650002\n",
            "Train Progress: 0.201093%, train loss: 2.568496, norm: 2.6284\n",
            "Train Progress: 0.201147%, train loss: 2.724204, norm: 3.5773\n",
            "Train Progress: 0.201202%, train loss: 2.608330, norm: 2.5909\n",
            "Train Progress: 0.201257%, train loss: 2.675000, norm: 2.2915\n",
            "Train Progress: 0.201311%, train loss: 2.597960, norm: 2.6642\n",
            "valid loss: 2.648580\n",
            "Train Progress: 0.201366%, train loss: 2.635241, norm: 3.4357\n",
            "Train Progress: 0.201420%, train loss: 2.617872, norm: 3.0692\n",
            "Train Progress: 0.201475%, train loss: 2.724242, norm: 2.6026\n",
            "Train Progress: 0.201529%, train loss: 2.679493, norm: 2.8444\n",
            "Train Progress: 0.201584%, train loss: 2.398975, norm: 3.2359\n",
            "valid loss: 2.655046\n",
            "Train Progress: 0.201638%, train loss: 2.598187, norm: 2.7567\n",
            "Train Progress: 0.201693%, train loss: 2.671636, norm: 1.9618\n",
            "Train Progress: 0.201747%, train loss: 2.777621, norm: 2.8306\n",
            "Train Progress: 0.201802%, train loss: 2.627821, norm: 2.9762\n",
            "Train Progress: 0.201856%, train loss: 2.722611, norm: 3.5884\n",
            "valid loss: 2.652059\n",
            "Train Progress: 0.201911%, train loss: 2.734651, norm: 2.7468\n",
            "Train Progress: 0.201966%, train loss: 2.624551, norm: 4.3346\n",
            "Train Progress: 0.202020%, train loss: 2.697678, norm: 2.8047\n",
            "Train Progress: 0.202075%, train loss: 2.741834, norm: 2.8034\n",
            "Train Progress: 0.202129%, train loss: 2.622896, norm: 3.4182\n",
            "valid loss: 2.663670\n",
            "Train Progress: 0.202184%, train loss: 2.509797, norm: 4.5515\n",
            "Train Progress: 0.202238%, train loss: 2.532398, norm: 2.8266\n",
            "Train Progress: 0.202293%, train loss: 2.728386, norm: 2.6552\n",
            "Train Progress: 0.202347%, train loss: 2.578840, norm: 2.6166\n",
            "Train Progress: 0.202402%, train loss: 2.716112, norm: 3.4474\n",
            "valid loss: 2.649176\n",
            "Train Progress: 0.202456%, train loss: 2.775713, norm: 4.7828\n",
            "Train Progress: 0.202511%, train loss: 2.394462, norm: 6.3334\n",
            "Train Progress: 0.202565%, train loss: 2.557775, norm: 4.0188\n",
            "Train Progress: 0.202620%, train loss: 2.699311, norm: 3.8753\n",
            "Train Progress: 0.202675%, train loss: 2.297127, norm: 4.1117\n",
            "valid loss: 2.655506\n",
            "Train Progress: 0.202729%, train loss: 2.456792, norm: 2.6856\n",
            "Train Progress: 0.202784%, train loss: 2.665502, norm: 2.8399\n",
            "Train Progress: 0.202838%, train loss: 2.801778, norm: 2.1231\n",
            "Train Progress: 0.202893%, train loss: 2.675629, norm: 2.2732\n",
            "Train Progress: 0.202947%, train loss: 2.462834, norm: 2.8203\n",
            "valid loss: 2.640793\n",
            "Train Progress: 0.203002%, train loss: 2.653780, norm: 2.8091\n",
            "Train Progress: 0.203056%, train loss: 2.802038, norm: 3.5042\n",
            "Train Progress: 0.203111%, train loss: 2.477650, norm: 3.8512\n",
            "Train Progress: 0.203165%, train loss: 2.728066, norm: 3.1176\n",
            "Train Progress: 0.203220%, train loss: 2.752761, norm: 3.2226\n",
            "valid loss: 2.626633\n",
            "Train Progress: 0.203274%, train loss: 2.630032, norm: 3.4322\n",
            "Train Progress: 0.203329%, train loss: 2.705766, norm: 2.2212\n",
            "Train Progress: 0.203384%, train loss: 2.644402, norm: 2.8759\n",
            "Train Progress: 0.203438%, train loss: 2.708959, norm: 3.7063\n",
            "Train Progress: 0.203493%, train loss: 2.758772, norm: 2.0874\n",
            "valid loss: 2.628007\n",
            "Train Progress: 0.203547%, train loss: 2.564781, norm: 3.0344\n",
            "Train Progress: 0.203602%, train loss: 2.676537, norm: 2.9895\n",
            "Train Progress: 0.203656%, train loss: 2.438260, norm: 3.9234\n",
            "Train Progress: 0.203711%, train loss: 2.516292, norm: 3.2570\n",
            "Train Progress: 0.203765%, train loss: 2.670281, norm: 3.2582\n",
            "valid loss: 2.622196\n",
            "Train Progress: 0.203820%, train loss: 2.732734, norm: 3.7841\n",
            "Train Progress: 0.203874%, train loss: 2.689263, norm: 2.4792\n",
            "Train Progress: 0.203929%, train loss: 2.502440, norm: 3.4418\n",
            "Train Progress: 0.203983%, train loss: 2.635374, norm: 3.1115\n",
            "Train Progress: 0.204038%, train loss: 2.564976, norm: 3.4087\n",
            "valid loss: 2.630239\n",
            "Train Progress: 0.204093%, train loss: 2.749853, norm: 2.1070\n",
            "Train Progress: 0.204147%, train loss: 2.498484, norm: 3.0171\n",
            "Train Progress: 0.204202%, train loss: 2.465814, norm: 3.9274\n",
            "Train Progress: 0.204256%, train loss: 2.775533, norm: 3.4442\n",
            "Train Progress: 0.204311%, train loss: 2.597019, norm: 4.1535\n",
            "valid loss: 2.621827\n",
            "Train Progress: 0.204365%, train loss: 2.662467, norm: 3.8159\n",
            "Train Progress: 0.204420%, train loss: 2.525837, norm: 2.9213\n",
            "Train Progress: 0.204474%, train loss: 2.601082, norm: 3.4088\n",
            "Train Progress: 0.204529%, train loss: 2.722420, norm: 3.2609\n",
            "Train Progress: 0.204583%, train loss: 2.570490, norm: 2.6064\n",
            "valid loss: 2.623304\n",
            "Train Progress: 0.204638%, train loss: 2.335302, norm: 3.5860\n",
            "Train Progress: 0.204692%, train loss: 2.621619, norm: 2.7779\n",
            "Train Progress: 0.204747%, train loss: 2.573557, norm: 3.8049\n",
            "Train Progress: 0.204802%, train loss: 2.423054, norm: 4.5158\n",
            "Train Progress: 0.204856%, train loss: 2.658345, norm: 2.4698\n",
            "valid loss: 2.624269\n",
            "Train Progress: 0.204911%, train loss: 2.576531, norm: 3.0008\n",
            "Train Progress: 0.204965%, train loss: 2.619203, norm: 3.0954\n",
            "Train Progress: 0.205020%, train loss: 2.695902, norm: 2.9543\n",
            "Train Progress: 0.205074%, train loss: 2.677491, norm: 2.6186\n",
            "Train Progress: 0.205129%, train loss: 2.699806, norm: 3.6637\n",
            "valid loss: 2.627761\n",
            "Train Progress: 0.205183%, train loss: 2.692028, norm: 2.9876\n",
            "Train Progress: 0.205238%, train loss: 2.675099, norm: 2.3914\n",
            "Train Progress: 0.205292%, train loss: 2.374204, norm: 3.4048\n",
            "Train Progress: 0.205347%, train loss: 2.652282, norm: 4.7750\n",
            "Train Progress: 0.205401%, train loss: 2.529493, norm: 3.3086\n",
            "valid loss: 2.615573\n",
            "Train Progress: 0.205456%, train loss: 2.439006, norm: 3.0035\n",
            "Train Progress: 0.205511%, train loss: 2.739814, norm: 2.7551\n",
            "Train Progress: 0.205565%, train loss: 2.562978, norm: 3.0918\n",
            "Train Progress: 0.205620%, train loss: 2.618194, norm: 3.3101\n",
            "Train Progress: 0.205674%, train loss: 2.728291, norm: 2.4380\n",
            "valid loss: 2.624086\n",
            "Train Progress: 0.205729%, train loss: 2.729942, norm: 2.9073\n",
            "Train Progress: 0.205783%, train loss: 2.723341, norm: 3.0441\n",
            "Train Progress: 0.205838%, train loss: 2.568459, norm: 3.4799\n",
            "Train Progress: 0.205892%, train loss: 2.743882, norm: 2.3210\n",
            "Train Progress: 0.205947%, train loss: 2.489573, norm: 3.4803\n",
            "valid loss: 2.619975\n",
            "Train Progress: 0.206001%, train loss: 2.619852, norm: 2.5341\n",
            "Train Progress: 0.206056%, train loss: 2.628874, norm: 3.9723\n",
            "Train Progress: 0.206110%, train loss: 2.645434, norm: 2.1871\n",
            "Train Progress: 0.206165%, train loss: 2.331170, norm: 3.3185\n",
            "Train Progress: 0.206220%, train loss: 2.617682, norm: 2.7136\n",
            "valid loss: 2.623301\n",
            "Train Progress: 0.206274%, train loss: 2.671117, norm: 2.3696\n",
            "Train Progress: 0.206329%, train loss: 2.707607, norm: 3.3108\n",
            "Train Progress: 0.206383%, train loss: 2.692907, norm: 2.9693\n",
            "Train Progress: 0.206438%, train loss: 2.627177, norm: 2.5117\n",
            "Train Progress: 0.206492%, train loss: 2.626207, norm: 4.2189\n",
            "valid loss: 2.631727\n",
            "Train Progress: 0.206547%, train loss: 2.292380, norm: 2.8105\n",
            "Train Progress: 0.206601%, train loss: 2.435029, norm: 2.7519\n",
            "Train Progress: 0.206656%, train loss: 2.539164, norm: 2.9988\n",
            "Train Progress: 0.206710%, train loss: 2.622499, norm: 3.0646\n",
            "Train Progress: 0.206765%, train loss: 2.654288, norm: 3.0368\n",
            "valid loss: 2.626474\n",
            "Train Progress: 0.206819%, train loss: 2.667888, norm: 3.6990\n",
            "Train Progress: 0.206874%, train loss: 2.716933, norm: 3.4626\n",
            "Train Progress: 0.206929%, train loss: 2.681088, norm: 3.3878\n",
            "Train Progress: 0.206983%, train loss: 2.595099, norm: 3.6774\n",
            "Train Progress: 0.207038%, train loss: 2.677366, norm: 3.7436\n",
            "valid loss: 2.624524\n",
            "Train Progress: 0.207092%, train loss: 2.633233, norm: 3.4359\n",
            "Train Progress: 0.207147%, train loss: 2.671062, norm: 4.3481\n",
            "Train Progress: 0.207201%, train loss: 2.445561, norm: 3.0685\n",
            "Train Progress: 0.207256%, train loss: 2.631455, norm: 3.2698\n",
            "Train Progress: 0.207310%, train loss: 2.707062, norm: 2.5055\n",
            "valid loss: 2.643371\n",
            "Train Progress: 0.207365%, train loss: 2.487129, norm: 2.9432\n",
            "Train Progress: 0.207419%, train loss: 2.478750, norm: 3.1223\n",
            "Train Progress: 0.207474%, train loss: 2.627962, norm: 3.2305\n",
            "Train Progress: 0.207528%, train loss: 2.419617, norm: 4.3447\n",
            "Train Progress: 0.207583%, train loss: 2.492543, norm: 4.2999\n",
            "valid loss: 2.628973\n",
            "Train Progress: 0.207638%, train loss: 2.510506, norm: 4.5467\n",
            "Train Progress: 0.207692%, train loss: 2.648831, norm: 2.7556\n",
            "Train Progress: 0.207747%, train loss: 2.731369, norm: 2.9797\n",
            "Train Progress: 0.207801%, train loss: 2.541199, norm: 3.7649\n",
            "Train Progress: 0.207856%, train loss: 2.546279, norm: 2.9930\n",
            "valid loss: 2.631754\n",
            "Train Progress: 0.207910%, train loss: 2.616971, norm: 2.9341\n",
            "Train Progress: 0.207965%, train loss: 2.724098, norm: 4.2106\n",
            "Train Progress: 0.208019%, train loss: 2.714306, norm: 2.8735\n",
            "Train Progress: 0.208074%, train loss: 2.430075, norm: 4.3398\n",
            "Train Progress: 0.208128%, train loss: 2.421244, norm: 5.4792\n",
            "valid loss: 2.634799\n",
            "Train Progress: 0.208183%, train loss: 2.678798, norm: 3.9672\n",
            "Train Progress: 0.208237%, train loss: 2.635378, norm: 3.1043\n",
            "Train Progress: 0.208292%, train loss: 2.665067, norm: 4.0619\n",
            "Train Progress: 0.208347%, train loss: 2.720021, norm: 2.6580\n",
            "Train Progress: 0.208401%, train loss: 2.323639, norm: 3.5163\n",
            "valid loss: 2.629143\n",
            "Train Progress: 0.208456%, train loss: 2.399554, norm: 2.8465\n",
            "Train Progress: 0.208510%, train loss: 2.652808, norm: 4.2272\n",
            "Train Progress: 0.208565%, train loss: 2.659703, norm: 2.9130\n",
            "Train Progress: 0.208619%, train loss: 2.687102, norm: 2.5625\n",
            "Train Progress: 0.208674%, train loss: 2.722201, norm: 2.4699\n",
            "valid loss: 2.632457\n",
            "Train Progress: 0.208728%, train loss: 2.670915, norm: 2.5822\n",
            "Train Progress: 0.208783%, train loss: 2.632288, norm: 2.6727\n",
            "Train Progress: 0.208837%, train loss: 2.688017, norm: 3.0212\n",
            "Train Progress: 0.208892%, train loss: 2.759564, norm: 2.7980\n",
            "Train Progress: 0.208946%, train loss: 2.702557, norm: 2.5944\n",
            "valid loss: 2.635939\n",
            "Train Progress: 0.209001%, train loss: 2.761681, norm: 2.9369\n",
            "Train Progress: 0.209056%, train loss: 2.603211, norm: 2.4402\n",
            "Train Progress: 0.209110%, train loss: 2.702273, norm: 2.9300\n",
            "Train Progress: 0.209165%, train loss: 2.665624, norm: 2.1481\n",
            "Train Progress: 0.209219%, train loss: 2.667976, norm: 3.0709\n",
            "valid loss: 2.639078\n",
            "Train Progress: 0.209274%, train loss: 2.505800, norm: 2.6232\n",
            "Train Progress: 0.209328%, train loss: 2.561887, norm: 3.2152\n",
            "Train Progress: 0.209383%, train loss: 2.398713, norm: 3.6279\n",
            "Train Progress: 0.209437%, train loss: 2.684339, norm: 3.3249\n",
            "Train Progress: 0.209492%, train loss: 2.660424, norm: 3.0121\n",
            "valid loss: 2.639402\n",
            "Train Progress: 0.209546%, train loss: 2.528136, norm: 4.1492\n",
            "Train Progress: 0.209601%, train loss: 2.645589, norm: 3.2025\n",
            "Train Progress: 0.209655%, train loss: 2.700187, norm: 3.3903\n",
            "Train Progress: 0.209710%, train loss: 2.587622, norm: 3.5082\n",
            "Train Progress: 0.209765%, train loss: 2.651468, norm: 3.1077\n",
            "valid loss: 2.641537\n",
            "Train Progress: 0.209819%, train loss: 2.689862, norm: 2.4783\n",
            "Train Progress: 0.209874%, train loss: 2.738341, norm: 2.8795\n",
            "Train Progress: 0.209928%, train loss: 2.673602, norm: 2.6211\n",
            "Train Progress: 0.209983%, train loss: 2.610417, norm: 2.8141\n",
            "Train Progress: 0.210037%, train loss: 2.652185, norm: 2.9370\n",
            "valid loss: 2.637139\n",
            "Train Progress: 0.210092%, train loss: 2.301936, norm: 2.8672\n",
            "Train Progress: 0.210146%, train loss: 2.499098, norm: 2.8647\n",
            "Train Progress: 0.210201%, train loss: 2.663647, norm: 2.2374\n",
            "Train Progress: 0.210255%, train loss: 2.707849, norm: 2.7125\n",
            "Train Progress: 0.210310%, train loss: 2.474729, norm: 2.8409\n",
            "valid loss: 2.635809\n",
            "Train Progress: 0.210364%, train loss: 2.318304, norm: 4.7537\n",
            "Train Progress: 0.210419%, train loss: 2.663697, norm: 4.7062\n",
            "Train Progress: 0.210473%, train loss: 2.588769, norm: 2.9824\n",
            "Train Progress: 0.210528%, train loss: 2.136879, norm: 3.3600\n",
            "Train Progress: 0.210583%, train loss: 2.549758, norm: 2.2472\n",
            "valid loss: 2.639152\n",
            "Train Progress: 0.210637%, train loss: 2.664854, norm: 3.1250\n",
            "Train Progress: 0.210692%, train loss: 2.502682, norm: 3.6808\n",
            "Train Progress: 0.210746%, train loss: 2.420339, norm: 3.9776\n",
            "Train Progress: 0.210801%, train loss: 2.672723, norm: 4.1998\n",
            "Train Progress: 0.210855%, train loss: 2.534991, norm: 4.2077\n",
            "valid loss: 2.627301\n",
            "Train Progress: 0.210910%, train loss: 2.560928, norm: 4.0340\n",
            "Train Progress: 0.210964%, train loss: 2.488976, norm: 4.9266\n",
            "Train Progress: 0.211019%, train loss: 2.110447, norm: 3.5500\n",
            "Train Progress: 0.211073%, train loss: 2.593325, norm: 2.0830\n",
            "Train Progress: 0.211128%, train loss: 2.731285, norm: 3.2689\n",
            "valid loss: 2.639106\n",
            "Train Progress: 0.211182%, train loss: 2.676450, norm: 2.2232\n",
            "Train Progress: 0.211237%, train loss: 2.674711, norm: 4.0326\n",
            "Train Progress: 0.211292%, train loss: 2.690761, norm: 2.9674\n",
            "Train Progress: 0.211346%, train loss: 2.525133, norm: 3.3165\n",
            "Train Progress: 0.211401%, train loss: 2.684300, norm: 4.7738\n",
            "valid loss: 2.631544\n",
            "Train Progress: 0.211455%, train loss: 2.538995, norm: 3.9578\n",
            "Train Progress: 0.211510%, train loss: 2.722630, norm: 3.0693\n",
            "Train Progress: 0.211564%, train loss: 2.605500, norm: 2.7132\n",
            "Train Progress: 0.211619%, train loss: 2.431124, norm: 2.9413\n",
            "Train Progress: 0.211673%, train loss: 2.665909, norm: 3.8003\n",
            "valid loss: 2.629804\n",
            "Train Progress: 0.211728%, train loss: 2.480278, norm: 2.3033\n",
            "Train Progress: 0.211782%, train loss: 2.700420, norm: 3.8204\n",
            "Train Progress: 0.211837%, train loss: 2.704110, norm: 2.4687\n",
            "Train Progress: 0.211891%, train loss: 2.625219, norm: 4.2016\n",
            "Train Progress: 0.211946%, train loss: 2.744785, norm: 4.2585\n",
            "valid loss: 2.620244\n",
            "Train Progress: 0.212001%, train loss: 2.602101, norm: 3.8357\n",
            "Train Progress: 0.212055%, train loss: 2.700223, norm: 3.3157\n",
            "Train Progress: 0.212110%, train loss: 2.444021, norm: 3.3160\n",
            "Train Progress: 0.212164%, train loss: 2.694644, norm: 1.8690\n",
            "Train Progress: 0.212219%, train loss: 2.503482, norm: 2.4167\n",
            "valid loss: 2.638100\n",
            "Train Progress: 0.212273%, train loss: 2.711296, norm: 3.1615\n",
            "Train Progress: 0.212328%, train loss: 2.751003, norm: 1.8896\n",
            "Train Progress: 0.212382%, train loss: 2.643831, norm: 3.0117\n",
            "Train Progress: 0.212437%, train loss: 2.401732, norm: 3.7499\n",
            "Train Progress: 0.212491%, train loss: 2.697151, norm: 2.9525\n",
            "valid loss: 2.614330\n",
            "Train Progress: 0.212546%, train loss: 2.778303, norm: 4.3903\n",
            "Train Progress: 0.212600%, train loss: 2.686115, norm: 4.9242\n",
            "Train Progress: 0.212655%, train loss: 2.633858, norm: 4.3922\n",
            "Train Progress: 0.212710%, train loss: 2.685456, norm: 3.8495\n",
            "Train Progress: 0.212764%, train loss: 2.660845, norm: 4.4943\n",
            "valid loss: 2.622951\n",
            "Train Progress: 0.212819%, train loss: 2.613069, norm: 3.4863\n",
            "Train Progress: 0.212873%, train loss: 2.651862, norm: 2.5238\n",
            "Train Progress: 0.212928%, train loss: 2.678877, norm: 2.9158\n",
            "Train Progress: 0.212982%, train loss: 2.750957, norm: 2.6816\n",
            "Train Progress: 0.213037%, train loss: 2.494493, norm: 3.9339\n",
            "valid loss: 2.616046\n",
            "Train Progress: 0.213091%, train loss: 2.675606, norm: 3.6551\n",
            "Train Progress: 0.213146%, train loss: 2.487656, norm: 3.0347\n",
            "Train Progress: 0.213200%, train loss: 2.622930, norm: 3.1123\n",
            "Train Progress: 0.213255%, train loss: 2.328870, norm: 3.6811\n",
            "Train Progress: 0.213309%, train loss: 2.673575, norm: 3.5346\n",
            "valid loss: 2.619966\n",
            "Train Progress: 0.213364%, train loss: 2.383336, norm: 3.8643\n",
            "Train Progress: 0.213419%, train loss: 2.523122, norm: 2.9785\n",
            "Train Progress: 0.213473%, train loss: 2.649360, norm: 3.6778\n",
            "Train Progress: 0.213528%, train loss: 2.468629, norm: 3.2344\n",
            "Train Progress: 0.213582%, train loss: 2.361169, norm: 2.7906\n",
            "valid loss: 2.614433\n",
            "Train Progress: 0.213637%, train loss: 2.713290, norm: 3.2418\n",
            "Train Progress: 0.213691%, train loss: 2.628637, norm: 3.8049\n",
            "Train Progress: 0.213746%, train loss: 2.417198, norm: 3.4887\n",
            "Train Progress: 0.213800%, train loss: 2.569776, norm: 2.7793\n",
            "Train Progress: 0.213855%, train loss: 2.540350, norm: 3.4441\n",
            "valid loss: 2.623672\n",
            "Train Progress: 0.213909%, train loss: 2.389018, norm: 3.3901\n",
            "Train Progress: 0.213964%, train loss: 2.751034, norm: 3.0008\n",
            "Train Progress: 0.214018%, train loss: 2.743173, norm: 2.8630\n",
            "Train Progress: 0.214073%, train loss: 2.564379, norm: 2.9681\n",
            "Train Progress: 0.214128%, train loss: 2.545665, norm: 4.0071\n",
            "valid loss: 2.616850\n",
            "Train Progress: 0.214182%, train loss: 2.599406, norm: 2.9553\n",
            "Train Progress: 0.214237%, train loss: 2.432204, norm: 4.2254\n",
            "Train Progress: 0.214291%, train loss: 2.363926, norm: 3.4680\n",
            "Train Progress: 0.214346%, train loss: 2.598099, norm: 2.6499\n",
            "Train Progress: 0.214400%, train loss: 2.703536, norm: 2.8861\n",
            "valid loss: 2.617411\n",
            "Train Progress: 0.214455%, train loss: 2.719492, norm: 2.4414\n",
            "Train Progress: 0.214509%, train loss: 2.510697, norm: 3.6612\n",
            "Train Progress: 0.214564%, train loss: 2.618783, norm: 4.4066\n",
            "Train Progress: 0.214618%, train loss: 2.166987, norm: 5.2751\n",
            "Train Progress: 0.214673%, train loss: 2.604373, norm: 3.9627\n",
            "valid loss: 2.612985\n",
            "Train Progress: 0.214727%, train loss: 2.430536, norm: 3.7977\n",
            "Train Progress: 0.214782%, train loss: 2.646177, norm: 4.3667\n",
            "Train Progress: 0.214837%, train loss: 2.314728, norm: 3.6495\n",
            "Train Progress: 0.214891%, train loss: 2.707166, norm: 2.2735\n",
            "Train Progress: 0.214946%, train loss: 2.791053, norm: 3.9420\n",
            "valid loss: 2.616965\n",
            "Train Progress: 0.215000%, train loss: 2.541549, norm: 3.8549\n",
            "Train Progress: 0.215055%, train loss: 2.552411, norm: 3.5814\n",
            "Train Progress: 0.215109%, train loss: 2.151863, norm: 4.0433\n",
            "Train Progress: 0.215164%, train loss: 2.681849, norm: 3.1205\n",
            "Train Progress: 0.215218%, train loss: 2.602468, norm: 3.6851\n",
            "valid loss: 2.613280\n",
            "Train Progress: 0.215273%, train loss: 2.645884, norm: 3.0852\n",
            "Train Progress: 0.215327%, train loss: 2.629102, norm: 3.0181\n",
            "Train Progress: 0.215382%, train loss: 2.686514, norm: 3.8380\n",
            "Train Progress: 0.215436%, train loss: 2.701530, norm: 3.7748\n",
            "Train Progress: 0.215491%, train loss: 2.539855, norm: 3.9118\n",
            "valid loss: 2.607009\n",
            "Train Progress: 0.215546%, train loss: 2.553071, norm: 3.9963\n",
            "Train Progress: 0.215600%, train loss: 2.617116, norm: 3.6231\n",
            "Train Progress: 0.215655%, train loss: 2.428898, norm: 2.9880\n",
            "Train Progress: 0.215709%, train loss: 2.619630, norm: 2.4594\n",
            "Train Progress: 0.215764%, train loss: 2.673332, norm: 2.7484\n",
            "valid loss: 2.611806\n",
            "Train Progress: 0.215818%, train loss: 2.593394, norm: 3.3018\n",
            "Train Progress: 0.215873%, train loss: 2.483567, norm: 3.0630\n",
            "Train Progress: 0.215927%, train loss: 2.665906, norm: 3.2808\n",
            "Train Progress: 0.215982%, train loss: 2.726516, norm: 2.1916\n",
            "Train Progress: 0.216036%, train loss: 2.775666, norm: 2.5450\n",
            "valid loss: 2.614371\n",
            "Train Progress: 0.216091%, train loss: 2.505773, norm: 2.8003\n",
            "Train Progress: 0.216145%, train loss: 2.594612, norm: 3.0968\n",
            "Train Progress: 0.216200%, train loss: 2.692955, norm: 2.9805\n",
            "Train Progress: 0.216255%, train loss: 2.799043, norm: 3.3420\n",
            "Train Progress: 0.216309%, train loss: 2.748303, norm: 3.3204\n",
            "valid loss: 2.615531\n",
            "Train Progress: 0.216364%, train loss: 2.714423, norm: 3.0515\n",
            "Train Progress: 0.216418%, train loss: 2.669453, norm: 2.8721\n",
            "Train Progress: 0.216473%, train loss: 2.530253, norm: 3.4735\n",
            "Train Progress: 0.216527%, train loss: 2.523167, norm: 3.7809\n",
            "Train Progress: 0.216582%, train loss: 2.677956, norm: 2.7326\n",
            "valid loss: 2.614400\n",
            "Train Progress: 0.216636%, train loss: 2.731652, norm: 3.9494\n",
            "Train Progress: 0.216691%, train loss: 2.645395, norm: 3.1353\n",
            "Train Progress: 0.216745%, train loss: 2.552595, norm: 2.9364\n",
            "Train Progress: 0.216800%, train loss: 2.647667, norm: 4.0059\n",
            "Train Progress: 0.216854%, train loss: 2.715092, norm: 3.5007\n",
            "valid loss: 2.615251\n",
            "Train Progress: 0.216909%, train loss: 2.720052, norm: 2.4701\n",
            "Train Progress: 0.216964%, train loss: 2.346274, norm: 3.4751\n",
            "Train Progress: 0.217018%, train loss: 2.800431, norm: 2.7744\n",
            "Train Progress: 0.217073%, train loss: 2.687148, norm: 2.6922\n",
            "Train Progress: 0.217127%, train loss: 2.658246, norm: 4.2007\n",
            "valid loss: 2.621379\n",
            "Train Progress: 0.217182%, train loss: 2.752486, norm: 2.8856\n",
            "Train Progress: 0.217236%, train loss: 2.728019, norm: 2.8970\n",
            "Train Progress: 0.217291%, train loss: 2.459522, norm: 4.1112\n",
            "Train Progress: 0.217345%, train loss: 2.581290, norm: 3.6960\n",
            "Train Progress: 0.217400%, train loss: 2.364846, norm: 4.3040\n",
            "valid loss: 2.614967\n",
            "Train Progress: 0.217454%, train loss: 2.659335, norm: 3.0312\n",
            "Train Progress: 0.217509%, train loss: 2.600048, norm: 3.4660\n",
            "Train Progress: 0.217563%, train loss: 2.758788, norm: 2.9862\n",
            "Train Progress: 0.217618%, train loss: 2.460613, norm: 3.2868\n",
            "Train Progress: 0.217673%, train loss: 2.729174, norm: 1.7651\n",
            "valid loss: 2.617620\n",
            "Train Progress: 0.217727%, train loss: 2.515973, norm: 3.5264\n",
            "Train Progress: 0.217782%, train loss: 2.667859, norm: 4.0734\n",
            "Train Progress: 0.217836%, train loss: 2.643680, norm: 3.8869\n",
            "Train Progress: 0.217891%, train loss: 2.555274, norm: 2.9757\n",
            "Train Progress: 0.217945%, train loss: 2.463215, norm: 4.1375\n",
            "valid loss: 2.611439\n",
            "Train Progress: 0.218000%, train loss: 2.372836, norm: 3.5592\n",
            "Train Progress: 0.218054%, train loss: 2.631512, norm: 3.0387\n",
            "Train Progress: 0.218109%, train loss: 2.291973, norm: 3.3587\n",
            "Train Progress: 0.218163%, train loss: 2.712656, norm: 2.5507\n",
            "Train Progress: 0.218218%, train loss: 2.517383, norm: 1.9513\n",
            "valid loss: 2.614272\n",
            "Train Progress: 0.218272%, train loss: 2.576036, norm: 4.1275\n",
            "Train Progress: 0.218327%, train loss: 2.596998, norm: 3.4765\n",
            "Train Progress: 0.218382%, train loss: 2.778595, norm: 3.2507\n",
            "Train Progress: 0.218436%, train loss: 2.761771, norm: 3.2796\n",
            "Train Progress: 0.218491%, train loss: 2.246172, norm: 2.8284\n",
            "valid loss: 2.618862\n",
            "Train Progress: 0.218545%, train loss: 2.445380, norm: 3.9192\n",
            "Train Progress: 0.218600%, train loss: 2.709345, norm: 2.4178\n",
            "Train Progress: 0.218654%, train loss: 2.476305, norm: 2.6052\n",
            "Train Progress: 0.218709%, train loss: 2.674052, norm: 3.0177\n",
            "Train Progress: 0.218763%, train loss: 2.591431, norm: 3.5211\n",
            "valid loss: 2.618774\n",
            "Train Progress: 0.218818%, train loss: 2.510546, norm: 3.1758\n",
            "Train Progress: 0.218872%, train loss: 2.745252, norm: 2.6176\n",
            "Train Progress: 0.218927%, train loss: 2.536493, norm: 3.7175\n",
            "Train Progress: 0.218981%, train loss: 2.588455, norm: 3.2409\n",
            "Train Progress: 0.219036%, train loss: 2.641132, norm: 3.4087\n",
            "valid loss: 2.623271\n",
            "Train Progress: 0.219091%, train loss: 2.453431, norm: 2.9075\n",
            "Train Progress: 0.219145%, train loss: 2.387974, norm: 2.2638\n",
            "Train Progress: 0.219200%, train loss: 2.546228, norm: 2.8674\n",
            "Train Progress: 0.219254%, train loss: 2.650838, norm: 3.0165\n",
            "Train Progress: 0.219309%, train loss: 2.514858, norm: 2.6751\n",
            "valid loss: 2.625376\n",
            "Train Progress: 0.219363%, train loss: 2.759720, norm: 3.1205\n",
            "Train Progress: 0.219418%, train loss: 2.631521, norm: 4.6751\n",
            "Train Progress: 0.219472%, train loss: 2.724642, norm: 3.0484\n",
            "Train Progress: 0.219527%, train loss: 2.723917, norm: 3.8219\n",
            "Train Progress: 0.219581%, train loss: 2.651438, norm: 3.5382\n",
            "valid loss: 2.624561\n",
            "Train Progress: 0.219636%, train loss: 2.516016, norm: 2.9755\n",
            "Train Progress: 0.219690%, train loss: 2.554121, norm: 3.5670\n",
            "Train Progress: 0.219745%, train loss: 2.733887, norm: 3.2793\n",
            "Train Progress: 0.219800%, train loss: 2.665821, norm: 2.7034\n",
            "Train Progress: 0.219854%, train loss: 2.443307, norm: 5.0761\n",
            "valid loss: 2.619979\n",
            "Train Progress: 0.219909%, train loss: 2.701730, norm: 2.5510\n",
            "Train Progress: 0.219963%, train loss: 2.391102, norm: 2.9220\n",
            "Train Progress: 0.220018%, train loss: 2.521371, norm: 2.5610\n",
            "Train Progress: 0.220072%, train loss: 2.701229, norm: 1.9126\n",
            "Train Progress: 0.220127%, train loss: 2.613911, norm: 3.9540\n",
            "valid loss: 2.620547\n",
            "Train Progress: 0.220181%, train loss: 2.759261, norm: 4.4199\n",
            "Train Progress: 0.220236%, train loss: 2.719129, norm: 3.8814\n",
            "Train Progress: 0.220290%, train loss: 2.466491, norm: 4.2277\n",
            "Train Progress: 0.220345%, train loss: 1.995474, norm: 4.4410\n",
            "Train Progress: 0.220399%, train loss: 2.672429, norm: 2.3804\n",
            "valid loss: 2.624325\n",
            "Train Progress: 0.220454%, train loss: 2.612902, norm: 2.7173\n",
            "Train Progress: 0.220509%, train loss: 2.702963, norm: 2.2312\n",
            "Train Progress: 0.220563%, train loss: 2.512149, norm: 2.9174\n",
            "Train Progress: 0.220618%, train loss: 2.742912, norm: 2.4174\n",
            "Train Progress: 0.220672%, train loss: 2.341144, norm: 3.6189\n",
            "valid loss: 2.623537\n",
            "Train Progress: 0.220727%, train loss: 2.209703, norm: 3.7577\n",
            "Train Progress: 0.220781%, train loss: 2.650316, norm: 3.1700\n",
            "Train Progress: 0.220836%, train loss: 2.741716, norm: 2.6840\n",
            "Train Progress: 0.220890%, train loss: 2.754361, norm: 2.7436\n",
            "Train Progress: 0.220945%, train loss: 2.687850, norm: 4.4302\n",
            "valid loss: 2.626253\n",
            "Train Progress: 0.220999%, train loss: 2.693693, norm: 2.4628\n",
            "Train Progress: 0.221054%, train loss: 2.626171, norm: 3.9957\n",
            "Train Progress: 0.221108%, train loss: 2.630953, norm: 3.6239\n",
            "Train Progress: 0.221163%, train loss: 2.612312, norm: 4.1073\n",
            "Train Progress: 0.221218%, train loss: 2.569669, norm: 2.9566\n",
            "valid loss: 2.625380\n",
            "Train Progress: 0.221272%, train loss: 2.710270, norm: 3.2962\n",
            "Train Progress: 0.221327%, train loss: 2.358031, norm: 3.7232\n",
            "Train Progress: 0.221381%, train loss: 2.643721, norm: 3.0063\n",
            "Train Progress: 0.221436%, train loss: 2.627445, norm: 3.5644\n",
            "Train Progress: 0.221490%, train loss: 2.263008, norm: 3.9000\n",
            "valid loss: 2.620867\n",
            "Train Progress: 0.221545%, train loss: 2.383894, norm: 3.6048\n",
            "Train Progress: 0.221599%, train loss: 2.655909, norm: 2.3447\n",
            "Train Progress: 0.221654%, train loss: 2.545897, norm: 3.2860\n",
            "Train Progress: 0.221708%, train loss: 2.733255, norm: 2.5962\n",
            "Train Progress: 0.221763%, train loss: 2.478382, norm: 3.2097\n",
            "valid loss: 2.621540\n",
            "Train Progress: 0.221817%, train loss: 2.493336, norm: 3.5414\n",
            "Train Progress: 0.221872%, train loss: 2.606991, norm: 2.6475\n",
            "Train Progress: 0.221927%, train loss: 2.730640, norm: 2.7675\n",
            "Train Progress: 0.221981%, train loss: 2.529208, norm: 2.7473\n",
            "Train Progress: 0.222036%, train loss: 2.702228, norm: 3.0448\n",
            "valid loss: 2.623606\n",
            "Train Progress: 0.222090%, train loss: 2.652850, norm: 2.9289\n",
            "Train Progress: 0.222145%, train loss: 2.649959, norm: 4.2384\n",
            "Train Progress: 0.222199%, train loss: 2.498132, norm: 3.3507\n",
            "Train Progress: 0.222254%, train loss: 2.659836, norm: 4.1732\n",
            "Train Progress: 0.222308%, train loss: 2.593932, norm: 4.4643\n",
            "valid loss: 2.613561\n",
            "Train Progress: 0.222363%, train loss: 2.529023, norm: 3.5910\n",
            "Train Progress: 0.222417%, train loss: 2.650586, norm: 3.8807\n",
            "Train Progress: 0.222472%, train loss: 2.610356, norm: 2.8593\n",
            "Train Progress: 0.222526%, train loss: 2.573303, norm: 2.7740\n",
            "Train Progress: 0.222581%, train loss: 2.702743, norm: 3.0821\n",
            "valid loss: 2.624501\n",
            "Train Progress: 0.222635%, train loss: 2.722031, norm: 2.9525\n",
            "Train Progress: 0.222690%, train loss: 2.690904, norm: 3.0961\n",
            "Train Progress: 0.222745%, train loss: 2.727011, norm: 3.1777\n",
            "Train Progress: 0.222799%, train loss: 2.579289, norm: 2.8805\n",
            "Train Progress: 0.222854%, train loss: 2.729080, norm: 5.0414\n",
            "valid loss: 2.614615\n",
            "Train Progress: 0.222908%, train loss: 2.657906, norm: 3.3037\n",
            "Train Progress: 0.222963%, train loss: 2.606148, norm: 2.9470\n",
            "Train Progress: 0.223017%, train loss: 2.666952, norm: 2.8915\n",
            "Train Progress: 0.223072%, train loss: 2.636219, norm: 2.3186\n",
            "Train Progress: 0.223126%, train loss: 2.546460, norm: 3.9540\n",
            "valid loss: 2.611070\n",
            "Train Progress: 0.223181%, train loss: 2.692590, norm: 3.5528\n",
            "Train Progress: 0.223235%, train loss: 2.562814, norm: 3.0265\n",
            "Train Progress: 0.223290%, train loss: 2.560885, norm: 4.1479\n",
            "Train Progress: 0.223344%, train loss: 2.705239, norm: 2.8052\n",
            "Train Progress: 0.223399%, train loss: 2.637970, norm: 2.4543\n",
            "valid loss: 2.612800\n",
            "Train Progress: 0.223454%, train loss: 2.709471, norm: 2.4721\n",
            "Train Progress: 0.223508%, train loss: 2.710361, norm: 3.1345\n",
            "Train Progress: 0.223563%, train loss: 2.740283, norm: 2.8202\n",
            "Train Progress: 0.223617%, train loss: 2.635481, norm: 3.5236\n",
            "Train Progress: 0.223672%, train loss: 2.618165, norm: 2.7756\n",
            "valid loss: 2.611541\n",
            "Train Progress: 0.223726%, train loss: 2.624314, norm: 2.8271\n",
            "Train Progress: 0.223781%, train loss: 2.410430, norm: 4.3620\n",
            "Train Progress: 0.223835%, train loss: 2.577885, norm: 5.7752\n",
            "Train Progress: 0.223890%, train loss: 2.742485, norm: 2.2288\n",
            "Train Progress: 0.223944%, train loss: 2.718086, norm: 2.7043\n",
            "valid loss: 2.613272\n",
            "Train Progress: 0.223999%, train loss: 2.294952, norm: 3.4253\n",
            "Train Progress: 0.224053%, train loss: 2.674767, norm: 2.6415\n",
            "Train Progress: 0.224108%, train loss: 2.646243, norm: 3.4068\n",
            "Train Progress: 0.224163%, train loss: 2.666622, norm: 3.1483\n",
            "Train Progress: 0.224217%, train loss: 2.444557, norm: 3.3453\n",
            "valid loss: 2.610460\n",
            "Train Progress: 0.224272%, train loss: 2.604612, norm: 2.9095\n",
            "Train Progress: 0.224326%, train loss: 2.402527, norm: 3.2288\n",
            "Train Progress: 0.224381%, train loss: 2.710167, norm: 2.0374\n",
            "Train Progress: 0.224435%, train loss: 2.528674, norm: 3.3484\n",
            "Train Progress: 0.224490%, train loss: 2.655982, norm: 2.6136\n",
            "valid loss: 2.615861\n",
            "Train Progress: 0.224544%, train loss: 2.234575, norm: 2.6061\n",
            "Train Progress: 0.224599%, train loss: 2.638995, norm: 3.6186\n",
            "Train Progress: 0.224653%, train loss: 2.655989, norm: 3.0204\n",
            "Train Progress: 0.224708%, train loss: 2.531792, norm: 4.0993\n",
            "Train Progress: 0.224762%, train loss: 2.193853, norm: 2.6700\n",
            "valid loss: 2.612953\n",
            "Train Progress: 0.224817%, train loss: 2.541202, norm: 3.0812\n",
            "Train Progress: 0.224872%, train loss: 2.488749, norm: 3.5126\n",
            "Train Progress: 0.224926%, train loss: 2.687525, norm: 3.2835\n",
            "Train Progress: 0.224981%, train loss: 2.601134, norm: 2.4794\n",
            "Train Progress: 0.225035%, train loss: 2.682927, norm: 3.2289\n",
            "valid loss: 2.624936\n",
            "Train Progress: 0.225090%, train loss: 2.697159, norm: 3.0074\n",
            "Train Progress: 0.225144%, train loss: 2.305238, norm: 4.5504\n",
            "Train Progress: 0.225199%, train loss: 2.452559, norm: 4.5924\n",
            "Train Progress: 0.225253%, train loss: 2.691630, norm: 3.4725\n",
            "Train Progress: 0.225308%, train loss: 2.597127, norm: 4.4932\n",
            "valid loss: 2.614345\n",
            "Train Progress: 0.225362%, train loss: 2.415640, norm: 3.8455\n",
            "Train Progress: 0.225417%, train loss: 2.730197, norm: 2.8163\n",
            "Train Progress: 0.225471%, train loss: 2.579467, norm: 3.5379\n",
            "Train Progress: 0.225526%, train loss: 2.659313, norm: 3.7660\n",
            "Train Progress: 0.225581%, train loss: 2.548302, norm: 2.9674\n",
            "valid loss: 2.616205\n",
            "Train Progress: 0.225635%, train loss: 2.538904, norm: 2.7770\n",
            "Train Progress: 0.225690%, train loss: 2.668074, norm: 2.7050\n",
            "Train Progress: 0.225744%, train loss: 2.624305, norm: 3.2478\n",
            "Train Progress: 0.225799%, train loss: 2.625120, norm: 3.3766\n",
            "Train Progress: 0.225853%, train loss: 2.626119, norm: 3.1361\n",
            "valid loss: 2.618017\n",
            "Train Progress: 0.225908%, train loss: 2.735398, norm: 2.6952\n",
            "Train Progress: 0.225962%, train loss: 2.739504, norm: 3.1355\n",
            "Train Progress: 0.226017%, train loss: 2.646319, norm: 3.0509\n",
            "Train Progress: 0.226071%, train loss: 2.545280, norm: 3.7237\n",
            "Train Progress: 0.226126%, train loss: 2.449925, norm: 4.1813\n",
            "valid loss: 2.617033\n",
            "Train Progress: 0.226180%, train loss: 2.464768, norm: 3.7592\n",
            "Train Progress: 0.226235%, train loss: 2.660199, norm: 2.8719\n",
            "Train Progress: 0.226290%, train loss: 2.628506, norm: 3.5544\n",
            "Train Progress: 0.226344%, train loss: 2.586567, norm: 3.6538\n",
            "Train Progress: 0.226399%, train loss: 2.643990, norm: 2.8788\n",
            "valid loss: 2.616801\n",
            "Train Progress: 0.226453%, train loss: 2.335149, norm: 2.6685\n",
            "Train Progress: 0.226508%, train loss: 2.510444, norm: 3.6915\n",
            "Train Progress: 0.226562%, train loss: 2.420449, norm: 3.6284\n",
            "Train Progress: 0.226617%, train loss: 2.698339, norm: 3.8815\n",
            "Train Progress: 0.226671%, train loss: 2.663384, norm: 3.9883\n",
            "valid loss: 2.618180\n",
            "Train Progress: 0.226726%, train loss: 2.462986, norm: 4.0019\n",
            "Train Progress: 0.226780%, train loss: 2.535549, norm: 4.2553\n",
            "Train Progress: 0.226835%, train loss: 2.571656, norm: 2.5627\n",
            "Train Progress: 0.226889%, train loss: 2.697381, norm: 3.6609\n",
            "Train Progress: 0.226944%, train loss: 2.615800, norm: 2.7879\n",
            "valid loss: 2.613834\n",
            "Train Progress: 0.226999%, train loss: 2.721459, norm: 3.4972\n",
            "Train Progress: 0.227053%, train loss: 2.388286, norm: 3.0797\n",
            "Train Progress: 0.227108%, train loss: 2.317887, norm: 3.8065\n",
            "Train Progress: 0.227162%, train loss: 2.612883, norm: 3.4524\n",
            "Train Progress: 0.227217%, train loss: 2.514216, norm: 4.1989\n",
            "valid loss: 2.618761\n",
            "Train Progress: 0.227271%, train loss: 2.641401, norm: 3.1021\n",
            "Train Progress: 0.227326%, train loss: 2.620456, norm: 3.3916\n",
            "Train Progress: 0.227380%, train loss: 2.715244, norm: 3.3754\n",
            "Train Progress: 0.227435%, train loss: 2.639632, norm: 2.8295\n",
            "Train Progress: 0.227489%, train loss: 2.745638, norm: 2.3477\n",
            "valid loss: 2.616138\n",
            "Train Progress: 0.227544%, train loss: 2.584565, norm: 2.8025\n",
            "Train Progress: 0.227598%, train loss: 2.701394, norm: 3.6043\n",
            "Train Progress: 0.227653%, train loss: 2.686520, norm: 2.7763\n",
            "Train Progress: 0.227708%, train loss: 2.614424, norm: 2.7823\n",
            "Train Progress: 0.227762%, train loss: 2.486022, norm: 3.5888\n",
            "valid loss: 2.619963\n",
            "Train Progress: 0.227817%, train loss: 2.723455, norm: 3.7763\n",
            "Train Progress: 0.227871%, train loss: 2.619792, norm: 4.7096\n",
            "Train Progress: 0.227926%, train loss: 2.578504, norm: 4.2425\n",
            "Train Progress: 0.227980%, train loss: 2.281359, norm: 4.9463\n",
            "Train Progress: 0.228035%, train loss: 2.601211, norm: 3.6644\n",
            "valid loss: 2.627985\n",
            "Train Progress: 0.228089%, train loss: 2.665885, norm: 2.7274\n",
            "Train Progress: 0.228144%, train loss: 2.719247, norm: 3.0754\n",
            "Train Progress: 0.228198%, train loss: 2.395075, norm: 3.1868\n",
            "Train Progress: 0.228253%, train loss: 2.714262, norm: 3.1676\n",
            "Train Progress: 0.228307%, train loss: 2.665223, norm: 4.3214\n",
            "valid loss: 2.620489\n",
            "Train Progress: 0.228362%, train loss: 2.745152, norm: 2.2141\n",
            "Train Progress: 0.228417%, train loss: 2.590987, norm: 3.3811\n",
            "Train Progress: 0.228471%, train loss: 2.659760, norm: 4.3572\n",
            "Train Progress: 0.228526%, train loss: 2.516867, norm: 3.9109\n",
            "Train Progress: 0.228580%, train loss: 2.672118, norm: 2.2678\n",
            "valid loss: 2.621420\n",
            "Train Progress: 0.228635%, train loss: 2.619562, norm: 3.8528\n",
            "Train Progress: 0.228689%, train loss: 2.469530, norm: 3.2452\n",
            "Train Progress: 0.228744%, train loss: 2.338208, norm: 3.3034\n",
            "Train Progress: 0.228798%, train loss: 2.723414, norm: 2.9936\n",
            "Train Progress: 0.228853%, train loss: 2.523622, norm: 2.6782\n",
            "valid loss: 2.623080\n",
            "Train Progress: 0.228907%, train loss: 2.698649, norm: 3.4255\n",
            "Train Progress: 0.228962%, train loss: 2.631899, norm: 3.3683\n",
            "Train Progress: 0.229016%, train loss: 2.701102, norm: 4.1507\n",
            "Train Progress: 0.229071%, train loss: 2.540465, norm: 3.0586\n",
            "Train Progress: 0.229126%, train loss: 2.628335, norm: 3.3086\n",
            "valid loss: 2.625451\n",
            "Train Progress: 0.229180%, train loss: 2.494677, norm: 3.7931\n",
            "Train Progress: 0.229235%, train loss: 2.024593, norm: 4.9261\n",
            "Train Progress: 0.229289%, train loss: 2.718253, norm: 2.3245\n",
            "Train Progress: 0.229344%, train loss: 2.236581, norm: 3.2201\n",
            "Train Progress: 0.229398%, train loss: 2.647325, norm: 3.8470\n",
            "valid loss: 2.628249\n",
            "Train Progress: 0.229453%, train loss: 2.685247, norm: 3.2694\n",
            "Train Progress: 0.229507%, train loss: 2.683208, norm: 3.1094\n",
            "Train Progress: 0.229562%, train loss: 2.692222, norm: 3.0922\n",
            "Train Progress: 0.229616%, train loss: 2.706094, norm: 3.0839\n",
            "Train Progress: 0.229671%, train loss: 2.304130, norm: 3.6449\n",
            "valid loss: 2.634422\n",
            "Train Progress: 0.229725%, train loss: 2.230341, norm: 4.5696\n",
            "Train Progress: 0.229780%, train loss: 2.167349, norm: 4.8345\n",
            "Train Progress: 0.229835%, train loss: 2.684965, norm: 3.2546\n",
            "Train Progress: 0.229889%, train loss: 2.460707, norm: 4.3118\n",
            "Train Progress: 0.229944%, train loss: 2.698410, norm: 2.8368\n",
            "valid loss: 2.625308\n",
            "Train Progress: 0.229998%, train loss: 2.733381, norm: 3.6957\n",
            "Train Progress: 0.230053%, train loss: 2.567023, norm: 3.6258\n",
            "Train Progress: 0.230107%, train loss: 2.706103, norm: 3.4172\n",
            "Train Progress: 0.230162%, train loss: 2.652140, norm: 4.5603\n",
            "Train Progress: 0.230216%, train loss: 2.301481, norm: 3.7082\n",
            "valid loss: 2.627429\n",
            "Train Progress: 0.230271%, train loss: 2.614316, norm: 3.5086\n",
            "Train Progress: 0.230325%, train loss: 2.621542, norm: 3.2407\n",
            "Train Progress: 0.230380%, train loss: 2.591634, norm: 3.7791\n",
            "Train Progress: 0.230434%, train loss: 2.470100, norm: 4.1060\n",
            "Train Progress: 0.230489%, train loss: 2.640081, norm: 2.2313\n",
            "valid loss: 2.630073\n",
            "Train Progress: 0.230544%, train loss: 2.663039, norm: 3.1088\n",
            "Train Progress: 0.230598%, train loss: 2.663675, norm: 3.3942\n",
            "Train Progress: 0.230653%, train loss: 2.353700, norm: 3.3110\n",
            "Train Progress: 0.230707%, train loss: 2.444357, norm: 3.4276\n",
            "Train Progress: 0.230762%, train loss: 2.713702, norm: 3.0356\n",
            "valid loss: 2.625169\n",
            "Train Progress: 0.230816%, train loss: 2.641364, norm: 2.0581\n",
            "Train Progress: 0.230871%, train loss: 2.751765, norm: 4.3006\n",
            "Train Progress: 0.230925%, train loss: 2.565100, norm: 2.9061\n",
            "Train Progress: 0.230980%, train loss: 2.721425, norm: 2.8242\n",
            "Train Progress: 0.231034%, train loss: 2.567430, norm: 3.5050\n",
            "valid loss: 2.626681\n",
            "Train Progress: 0.231089%, train loss: 2.705177, norm: 3.1219\n",
            "Train Progress: 0.231143%, train loss: 2.748228, norm: 3.9706\n",
            "Train Progress: 0.231198%, train loss: 2.693293, norm: 3.5221\n",
            "Train Progress: 0.231253%, train loss: 2.619399, norm: 4.2366\n",
            "Train Progress: 0.231307%, train loss: 2.680554, norm: 3.6073\n",
            "valid loss: 2.626292\n",
            "Train Progress: 0.231362%, train loss: 2.339329, norm: 3.7306\n",
            "Train Progress: 0.231416%, train loss: 2.470839, norm: 2.8080\n",
            "Train Progress: 0.231471%, train loss: 2.582896, norm: 2.4547\n",
            "Train Progress: 0.231525%, train loss: 2.742046, norm: 3.5613\n",
            "Train Progress: 0.231580%, train loss: 2.666057, norm: 3.9087\n",
            "valid loss: 2.623299\n",
            "Train Progress: 0.231634%, train loss: 2.766858, norm: 2.8605\n",
            "Train Progress: 0.231689%, train loss: 2.475467, norm: 5.0578\n",
            "Train Progress: 0.231743%, train loss: 2.728446, norm: 3.8039\n",
            "Train Progress: 0.231798%, train loss: 2.630049, norm: 4.0032\n",
            "Train Progress: 0.231852%, train loss: 2.687436, norm: 3.6752\n",
            "valid loss: 2.627093\n",
            "Train Progress: 0.231907%, train loss: 2.663486, norm: 3.0995\n",
            "Train Progress: 0.231962%, train loss: 2.680054, norm: 3.6485\n",
            "Train Progress: 0.232016%, train loss: 2.433057, norm: 4.0524\n",
            "Train Progress: 0.232071%, train loss: 2.652420, norm: 3.5426\n",
            "Train Progress: 0.232125%, train loss: 2.374813, norm: 3.3356\n",
            "valid loss: 2.630519\n",
            "Train Progress: 0.232180%, train loss: 2.621629, norm: 3.0386\n",
            "Train Progress: 0.232234%, train loss: 2.363571, norm: 3.4645\n",
            "Train Progress: 0.232289%, train loss: 2.755107, norm: 4.0237\n",
            "Train Progress: 0.232343%, train loss: 2.709961, norm: 4.5854\n",
            "Train Progress: 0.232398%, train loss: 2.394701, norm: 3.4954\n",
            "valid loss: 2.626527\n",
            "Train Progress: 0.232452%, train loss: 2.344764, norm: 3.2371\n",
            "Train Progress: 0.232507%, train loss: 2.199631, norm: 2.7026\n",
            "Train Progress: 0.232561%, train loss: 2.715500, norm: 3.2620\n",
            "Train Progress: 0.232616%, train loss: 2.644009, norm: 2.2905\n",
            "Train Progress: 0.232671%, train loss: 2.550552, norm: 3.0354\n",
            "valid loss: 2.633262\n",
            "Train Progress: 0.232725%, train loss: 2.456096, norm: 3.9522\n",
            "Train Progress: 0.232780%, train loss: 2.664592, norm: 3.6058\n",
            "Train Progress: 0.232834%, train loss: 2.576125, norm: 3.3495\n",
            "Train Progress: 0.232889%, train loss: 2.662186, norm: 3.0062\n",
            "Train Progress: 0.232943%, train loss: 2.622127, norm: 3.3949\n",
            "valid loss: 2.625675\n",
            "Train Progress: 0.232998%, train loss: 2.381027, norm: 4.4122\n",
            "Train Progress: 0.233052%, train loss: 2.746032, norm: 2.9547\n",
            "Train Progress: 0.233107%, train loss: 2.670547, norm: 3.0661\n",
            "Train Progress: 0.233161%, train loss: 2.626401, norm: 3.3545\n",
            "Train Progress: 0.233216%, train loss: 2.598997, norm: 4.1121\n",
            "valid loss: 2.627184\n",
            "Train Progress: 0.233270%, train loss: 2.653417, norm: 2.7975\n",
            "Train Progress: 0.233325%, train loss: 2.595310, norm: 3.2993\n",
            "Train Progress: 0.233380%, train loss: 2.630368, norm: 3.5128\n",
            "Train Progress: 0.233434%, train loss: 2.748651, norm: 2.5234\n",
            "Train Progress: 0.233489%, train loss: 2.710047, norm: 3.2422\n",
            "valid loss: 2.635275\n",
            "Train Progress: 0.233543%, train loss: 2.658087, norm: 2.8357\n",
            "Train Progress: 0.233598%, train loss: 2.680847, norm: 3.0763\n",
            "Train Progress: 0.233652%, train loss: 2.643453, norm: 2.8868\n",
            "Train Progress: 0.233707%, train loss: 2.716709, norm: 1.9609\n",
            "Train Progress: 0.233761%, train loss: 2.667873, norm: 3.8473\n",
            "valid loss: 2.637659\n",
            "Train Progress: 0.233816%, train loss: 2.415307, norm: 3.4200\n",
            "Train Progress: 0.233870%, train loss: 2.556082, norm: 2.9693\n",
            "Train Progress: 0.233925%, train loss: 2.712426, norm: 2.6914\n",
            "Train Progress: 0.233979%, train loss: 2.307384, norm: 3.3235\n",
            "Train Progress: 0.234034%, train loss: 2.599965, norm: 3.7808\n",
            "valid loss: 2.628871\n",
            "Train Progress: 0.234089%, train loss: 2.633224, norm: 4.6394\n",
            "Train Progress: 0.234143%, train loss: 2.617395, norm: 3.0668\n",
            "Train Progress: 0.234198%, train loss: 2.469549, norm: 3.2655\n",
            "Train Progress: 0.234252%, train loss: 2.746300, norm: 2.1444\n",
            "Train Progress: 0.234307%, train loss: 2.496967, norm: 3.4754\n",
            "valid loss: 2.633688\n",
            "Train Progress: 0.234361%, train loss: 2.511513, norm: 4.0358\n",
            "Train Progress: 0.234416%, train loss: 2.394330, norm: 3.5303\n",
            "Train Progress: 0.234470%, train loss: 2.587241, norm: 4.4731\n",
            "Train Progress: 0.234525%, train loss: 2.622392, norm: 4.0108\n",
            "Train Progress: 0.234579%, train loss: 2.767144, norm: 4.4801\n",
            "valid loss: 2.624003\n",
            "Train Progress: 0.234634%, train loss: 2.769078, norm: 3.7323\n",
            "Train Progress: 0.234688%, train loss: 2.559545, norm: 2.5936\n",
            "Train Progress: 0.234743%, train loss: 2.767715, norm: 2.8225\n",
            "Train Progress: 0.234797%, train loss: 2.445609, norm: 3.1216\n",
            "Train Progress: 0.234852%, train loss: 2.621490, norm: 3.4566\n",
            "valid loss: 2.621835\n",
            "Train Progress: 0.234907%, train loss: 2.617719, norm: 2.7088\n",
            "Train Progress: 0.234961%, train loss: 2.555233, norm: 3.4782\n",
            "Train Progress: 0.235016%, train loss: 2.526201, norm: 3.1994\n",
            "Train Progress: 0.235070%, train loss: 2.509539, norm: 4.2790\n",
            "Train Progress: 0.235125%, train loss: 2.709586, norm: 3.3823\n",
            "valid loss: 2.624113\n",
            "Train Progress: 0.235179%, train loss: 2.407309, norm: 5.1431\n",
            "Train Progress: 0.235234%, train loss: 2.574000, norm: 3.7588\n",
            "Train Progress: 0.235288%, train loss: 2.736142, norm: 3.5944\n",
            "Train Progress: 0.235343%, train loss: 2.520831, norm: 4.4695\n",
            "Train Progress: 0.235397%, train loss: 2.673366, norm: 2.6304\n",
            "valid loss: 2.615732\n",
            "Train Progress: 0.235452%, train loss: 2.581293, norm: 4.1833\n",
            "Train Progress: 0.235506%, train loss: 2.653503, norm: 3.7402\n",
            "Train Progress: 0.235561%, train loss: 2.700158, norm: 3.2549\n",
            "Train Progress: 0.235616%, train loss: 2.574174, norm: 4.4983\n",
            "Train Progress: 0.235670%, train loss: 2.173264, norm: 3.4285\n",
            "valid loss: 2.614955\n",
            "Train Progress: 0.235725%, train loss: 2.345783, norm: 3.1053\n",
            "Train Progress: 0.235779%, train loss: 2.684012, norm: 3.4695\n",
            "Train Progress: 0.235834%, train loss: 2.737318, norm: 2.9356\n",
            "Train Progress: 0.235888%, train loss: 2.714381, norm: 3.4241\n",
            "Train Progress: 0.235943%, train loss: 2.394803, norm: 2.9249\n",
            "valid loss: 2.608798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vl_losses_track"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4clSkkQU1TlU",
        "outputId": "81197aff-b07d-4860-a3ba-9fafc8d637d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 5.950642552587727, tensor(24211102): 2.712953734397888}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('./drive/MyDrive/esm/vl_losses_lora.json', 'w') as f:\n",
        "    json.dump(vl_losses_all, f)\n"
      ],
      "metadata": {
        "id": "PphjGjyTv6eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = None\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "h3_G0oFd1jCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "MM_WSUosJKBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "vl_losses = []\n",
        "total_iters = len(valid_dl)\n",
        "with torch.no_grad():\n",
        "    # Do a validation pass for 20 epochs and calculate loss\n",
        "    for ite, vl_batch in enumerate(valid_dl):\n",
        "        outputs = model(vl_batch['input_ids'].to(device),\n",
        "                        y = vl_batch['labels'].to(device),\n",
        "                        attention_mask = vl_batch['attention_mask'].to(device))\n",
        "        vl_losses.append(outputs['loss'].item())\n",
        "        progress = ((ite + 1) / total_iters) * 100\n",
        "        print(f\"\\rProgress: {progress:.2f}%, loss: {vl_losses[-1]:.6f}\", end='')\n",
        "\n",
        "    print(f'Validation Loss: {np.mean(vl_losses)}')"
      ],
      "metadata": {
        "id": "FeIAb2YdwDyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Validation Loss: {np.mean(vl_losses)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6e3NMUR0yCO",
        "outputId": "f0266ad1-4324-440f-b396-56a7135c2a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0027819751310439694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('vl_losses.json', 'w') as f:\n",
        "    json.dump(vl_losses, f)"
      ],
      "metadata": {
        "id": "DrLQZBhUxLEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation"
      ],
      "metadata": {
        "id": "Mb0BbRd8myAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ds['train']['text']\n",
        "train_seqs, valid_seqs = train_test_split(sequences, test_size = 0.05, shuffle = True)"
      ],
      "metadata": {
        "id": "Y28nEGO2r4fB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('model_finetune_v1.pt', map_location='cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuNMna0juuck",
        "outputId": "22d410f4-249a-4958-b32a-801fca565c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-5d4fc81c59d3>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = torch.load('model_finetune_v1.pt', map_location='cpu')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "cUNlFVwMqP5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "EFa-xM-XDBQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_rng = torch.Generator(device = device)\n",
        "sample_rng.manual_seed(42)\n",
        "\n",
        "seqs = valid_seqs[:4]\n",
        "max_length = 128\n",
        "tokenizer = get_tokenizer()\n",
        "tokens = [tokenizer.encode(i[:15]) for i in seqs]\n",
        "tokens = torch.tensor(tokens, dtype=torch.long)\n",
        "attn_mask = torch.ones_like(tokens, dtype = torch.long)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "xgen = tokens.to(device)\n",
        "attn_mask = attn_mask.to(device)\n",
        "\n",
        "c = 0\n",
        "while xgen.size(1) < max_length:\n",
        "    with torch.no_grad():\n",
        "        out = model(xgen, attention_mask = attn_mask)\n",
        "        logits = out['logits']\n",
        "        logits = logits[:, -1, :]\n",
        "        probs = F.softmax(logits, dim = -1)\n",
        "        topk_probs, topk_indices = torch.topk(probs, 10, dim = -1)\n",
        "        ix = torch.multinomial(topk_probs, 1, generator = sample_rng) # (B, 1)\n",
        "        xcol = torch.gather(topk_indices, -1, ix) # (B, 1)\n",
        "        xgen = torch.cat((xgen, xcol), dim = 1)\n",
        "\n",
        "        mask_new = xcol.to(torch.long) != 1\n",
        "        attn_mask = torch.cat((attn_mask, mask_new), dim = 1)\n",
        "        c += 1\n",
        "        progress = (c/max_length)*100\n",
        "        print(f\"\\rProgress: {progress:.2f}%\", end='')\n",
        "        # if c > 10: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pGHFJnpnVi3",
        "outputId": "7c69ee0a-41a2-4ffa-c8b8-4e3e27d6d9e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 87.50%"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgen.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eBY5SYkrvVB",
        "outputId": "a46ba295-f6f3-4265-9f67-44dc618e0ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgen[:, 10:30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYaqLMZn0yqF",
        "outputId": "7b330fb8-d88b-419a-db0b-c2fad6d441fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 71,  87,  74,  86,  74,   1,  65,   1,   1,   1,   1,  80,  80,  80,\n",
              "          80,  80,  80,  80,  78,  78],\n",
              "        [ 78,  86,  83,  78,  83,   1,  72,  72,  72,  72,  72,  72,  72,  72,\n",
              "          72,  72,  72,  72,  72,  84],\n",
              "        [ 68,  86,  89,  68,  89,   1,  75,  75,  75,  75,  75,  75,  75,  75,\n",
              "          85,   1,   1,   1,   1,   1],\n",
              "        [ 74,  87,  85,  86,  78,   1,   1,   1,   1,   1,   1, 144,   1,  87,\n",
              "          87,  87,  87,  87,  87,  87]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded = [tokenizer.decode(i) for i in xgen]"
      ],
      "metadata": {
        "id": "l3cujO7ivESp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[i[:128] for i in seqs]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW6bQ7QhEVfg",
        "outputId": "e574a488-f651-48af-95ac-d724b4d603cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sequence<MDTGSGGGGGGGGGGGGTSIHITALDGIVNVNSLFTLAAFIGLAWRPSADGPELAGGADRLGSACAAGDRVESDLVLFHVLAFACFLFSSIVALCLKQIVRTHPHYRLRSGGGGGSAVS',\n",
              " 'Sequence<MKSPKPPNLSDKSLKPNFFHGHRKPSQNRPTVYGGLFSNRQSIPRVSPQPQSNSLAHRTPFDLRKWDPETHLPPPSPPSHSTVISAASERLSPIARFVLDAFRKNRNHWGPSVVSELNK',\n",
              " 'Sequence<MASVAVEPQLSVVTRVANLPLVSSTYDLVSSAYISRKDQYPYLKSLCEMAEKGMKTITSVAVTSALPIIQKLEPQIAVANTYACKGLDRIEEKLPILNQPTNQVVANAKGAMTGAKDAV',\n",
              " 'Sequence<MGTRSKRAQDVLIGGRFRIQERLGGGAFGEVFRGVELNSGHPVAMKMELTKDGHRSHLNLENRIYKKFNECPVTVGIPKSYYCGRVGDYTVMVMDLLGPCLDDLFEVCHRKFSFKTVCM']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNZbNye9EETm",
        "outputId": "b25eda09-c10d-4799-81fa-d14fe1f03bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sequence<MDTGSG</s>></s></s></s></s>MMMMMMMKKKKKKKKKKKKKKK</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>WWWWWWW</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>',\n",
              " 'Sequence<MKSPKP</s>EEEEEEEEEEEEEQQHHHNNNNNNNNNNNNNNNNNNNNNNNNNNNNN</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>',\n",
              " 'Sequence<MASVAV</s>HHHHHHHHR</s></s></s></s></s></s></s></s></s></s>HHHHHH</s></s></s></s></s></s></s></s></s></s></s></s>M</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>></s></s></s></s></s></s></s></s></s></s>></s></s></s></s></s></s></s></s></s>HHHHQ></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>',\n",
              " 'Sequence<MGTRSK</s></s></s></s></s></s></s>TTTTTTTTTTTTTTTT></s></s>TTTTTTTTTTKKKKKKKKQQQQQQQHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, valid_ds = ProtDS(train_seqs), ProtDS(valid_seqs)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size= 4, collate_fn = seq_collate_fn)\n",
        "valid_dl = DataLoader(valid_ds, batch_size= 4, collate_fn = seq_collate_fn)"
      ],
      "metadata": {
        "id": "Loq8g4kV0KaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in valid_dl: break\n",
        "model = model.cpu()\n",
        "out = model(batch['input_ids'], attention_mask = batch['attention_mask'], y = batch['labels'])"
      ],
      "metadata": {
        "id": "tI-qaYsH0Cwd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out['loss'], out['logits'].shape, batch['labels'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO7b3ckI0hWE",
        "outputId": "1a285bda-8ce9-4d0d-f1e6-c9ccf10e0f18"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1.1915, grad_fn=<NllLossBackward0>),\n",
              " torch.Size([4, 1026, 384]),\n",
              " torch.Size([4, 1026]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = out['logits'].view((-1, out['logits'].size(-1)))\n",
        "targets = batch['labels'].view(-1)"
      ],
      "metadata": {
        "id": "wMnKBJeY26la"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert logits.size(0) == targets.size(0)"
      ],
      "metadata": {
        "id": "ztwVegEh3Sec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F.cross_entropy(logits, targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQRcGjja0lBO",
        "outputId": "a0f2b18a-56e6-49af-c91f-b6385f088255"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.1915, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask = batch['attention_mask']"
      ],
      "metadata": {
        "id": "KOHGhcyeTvYY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits.shape, targets.shape, attention_mask.shape"
      ],
      "metadata": {
        "id": "IWnE8MePTpQV",
        "outputId": "ab0d2e54-5021-4f59-e265-26783fbc5b8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4104, 384]), torch.Size([4104]), torch.Size([4, 1026]))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "op = logits[:1026, :]; targ = targets[:1026]; attention_mask = attention_mask[0]"
      ],
      "metadata": {
        "id": "8yU4zF6bTpWx"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(op.argmax(dim = 1) == targ)[:341].sum()"
      ],
      "metadata": {
        "id": "urW9DNL7Tpbi",
        "outputId": "49473ecb-3750-42d8-a61d-ba4eb1837874",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(58)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qf-AlfgXTpfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I1m3tmcqTpi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pjsA_IrVTpmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7XctbUtxTpp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DeBugging\n"
      ],
      "metadata": {
        "id": "NXJS8Mu0M-ZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = torch.load('model_finetune_v1.pt', map_location = 'cpu')"
      ],
      "metadata": {
        "id": "qjXdfYqy2YO6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c927ed0-ed6b-4647-af4f-2353472ba0f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-6c0fe0aa42ec>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = torch.load('model_finetune_v1.pt', map_location = 'cpu')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "N7TLTFs8nZjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ds['train']['text']\n",
        "train_seqs, valid_seqs = train_test_split(sequences, test_size = 0.05, shuffle = True)\n",
        "train_ds, valid_ds = ProtDS(train_seqs), ProtDS(valid_seqs)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size= 4, collate_fn = seq_collate_fn)\n",
        "valid_dl = DataLoader(valid_ds, batch_size= 4, collate_fn = seq_collate_fn)\n"
      ],
      "metadata": {
        "id": "laBFNLsdM9yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dl: break"
      ],
      "metadata": {
        "id": "aRYNfmsInvgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = batch['input_ids'][:, :50]\n",
        "attention_mask = batch['attention_mask'][:, :50]\n",
        "labels = batch['labels'][:, :50]"
      ],
      "metadata": {
        "id": "VCf_t3j3ZJSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = model(input_ids, attention_mask = attention_mask)"
      ],
      "metadata": {
        "id": "38KEJ4dBZMK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out['logits'].shape, batch['labels'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DCj9e7lZbw3",
        "outputId": "b278ccce-9b9f-4b8b-e7b8-1a4c3837db7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 50, 384]), torch.Size([4, 1026]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = F.cross_entropy(out['logits'].view(-1, 384), labels.reshape(-1))\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMEZGPotZdkN",
        "outputId": "54ca1227-91ba-422e-c018-a299b1e7ede7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4464, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = out['logits'].argmax(dim = 2)\n",
        "predicted_labels[0] == labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARTIG_o9Zq3Z",
        "outputId": "a122827d-6194-4644-ea42-05092b259708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids.shape, attention_mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2VYZhj3bn7n",
        "outputId": "6638e777-99f0-4c6b-936f-23d9f6ba11d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 1026]), torch.Size([4, 1026]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in batch.items():\n",
        "    batch[k] = v.to(device)"
      ],
      "metadata": {
        "id": "0yeA_Hxgn7M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# So now, lets go to the original problem statement\n",
        "offset = 30\n",
        "input_ids = batch['input_ids'][:, :offset]\n",
        "attention_mask = batch['attention_mask'][:, :offset]\n",
        "\n",
        "for i in range(10):\n",
        "    out = model(input_ids, attention_mask = attention_mask)\n",
        "    logits = out['logits']\n",
        "    last_logits = logits[:, -1, :]\n",
        "    last_tokens = last_logits.argmax(-1)\n",
        "    print(f\"predicted tokens: {last_tokens}, actual_tokens: {batch['labels'][:, offset + i]}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MGTYCVyaFp3",
        "outputId": "69cdb7b7-960d-4c40-e1af-6ddd80c19c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted tokens: tensor([1, 1, 1, 1], device='cuda:0'), actual_tokens: tensor([86, 81, 85, 92], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_output = out['encoder_output']"
      ],
      "metadata": {
        "id": "A0HqbzMrbg0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI6XlyvsocdX",
        "outputId": "6879ffac-51d3-42fb-eee8-3a9b02f31cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 30, 640])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Experiments"
      ],
      "metadata": {
        "id": "789p_BM1KFT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_for_grad_update = 30000\n",
        "epochs = 1\n",
        "batch_size = 8\n",
        "grad_accum_steps = 20\n",
        "\n",
        "sequences = ds['train']['text']\n",
        "train_seqs, valid_seqs = train_test_split(sequences, test_size = 0.05, shuffle = True)\n",
        "train_ds, valid_ds = ProtDS(train_seqs), ProtDS(valid_seqs)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size = batch_size, collate_fn = seq_collate_fn)\n",
        "valid_dl = DataLoader(valid_ds, batch_size = batch_size, collate_fn = seq_collate_fn)\n",
        "iterations = epochs * len(train_dl) + 5"
      ],
      "metadata": {
        "id": "pZwnI8puReMI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = None\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Finetune the model with LoRA\n",
        "model = ESM.from_pretrained(LoRAConfig(lora_r = 64, lora_key = True, lora_mlp = True, lora_projection = True, lora_alpha = 32), 'esm2_t30_150M_UR50D', use_final_proj= True)\n",
        "\n",
        "# Full finetune the model\n",
        "# model = ESM.from_pretrained(LoRAConfig(lora_r = 64, lora_key = False, lora_mlp = False, lora_projection = False, lora_query = False, lora_value = False, lora_alpha = 32), 'esm2_t30_150M_UR50D', use_final_proj= False)\n",
        "# for i in model.parameters():\n",
        "#     i.requires_grad_(True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "CqNTOD1GofoY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb1767ba-2708-4a55-a64c-e1753e8b705a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading weights from pretrained gpt: esm2_t30_150M_UR50D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t30_150M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch.optim import AdamW\n",
        "opt = AdamW(model.parameters(), lr = 3e-04, betas = (0.9, 0.98), eps = 1e-08, fused = True)\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr = 3e-04, total_steps = iterations, final_div_factor=10.0)\n",
        "\n",
        "# Use this line if you are starting from a checkpoint, else use oneCycle LR schedule\n",
        "# lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, iterations)"
      ],
      "metadata": {
        "id": "mcnDiRq5KMu-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_processed_after_gradstep = 0\n",
        "total_tokens_trained = 0\n",
        "loss = None\n",
        "losses = []\n",
        "vl_losses_track = {0: -np.log(1/384)} # Ideal loss at epoch 0 before any finetuning\n",
        "vl_losses_all = []\n",
        "\n",
        "c = 0"
      ],
      "metadata": {
        "id": "mNU205_6rns0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(epochs):\n",
        "    for iter, batch in enumerate(train_dl):\n",
        "\n",
        "        outputs = model(batch['input_ids'].to(device), y = batch['labels'].to(device), attention_mask = batch['attention_mask'].to(device))\n",
        "        total_tokens_trained += batch['attention_mask'].sum()\n",
        "\n",
        "        losses.append(outputs['loss'].item())\n",
        "        outputs['loss'] = outputs['loss']/grad_accum_steps\n",
        "        outputs['loss'].backward()\n",
        "        steps_processed_after_gradstep += 1\n",
        "\n",
        "        if steps_processed_after_gradstep == grad_accum_steps:\n",
        "            # Do a backward pass and optimizer step\n",
        "            norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            opt.step()\n",
        "            lr_scheduler.step()\n",
        "\n",
        "            steps_processed_after_gradstep = 0\n",
        "            current_iter = iter + i*len(train_dl)\n",
        "            progress = (current_iter/(epochs * len(train_dl)))*100\n",
        "            print(f\"Train Progress: {progress:.6f}%, train loss: {losses[-1]:.6f}, norm: {norm:.4f}\")\n",
        "            c += 1\n",
        "\n",
        "        if c >= 5: # approximately for every 400k tokens trained on, lets calculate the validation loss\n",
        "            c = 0\n",
        "            vl_losses = []\n",
        "            v_iter = 0\n",
        "            with torch.no_grad():\n",
        "                for vl_batch in valid_dl:\n",
        "                    vl_outputs = model(vl_batch['input_ids'].to(device), y = vl_batch['labels'].to(device), attention_mask = vl_batch['attention_mask'].to(device))\n",
        "                    vl_losses.append(vl_outputs['loss'].item())\n",
        "                    v_iter += 1\n",
        "\n",
        "                    if v_iter%10 == 0: break\n",
        "\n",
        "            vl_losses_all += vl_losses\n",
        "            vl_losses_track[total_tokens_trained] = np.mean(vl_losses)\n",
        "            print(f\"valid loss: {np.mean(vl_losses):.6f}\")"
      ],
      "metadata": {
        "id": "73s6YyHXKE0W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "37841201-0b42-499e-ad31-d89acb351dd3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Progress: 0.020724%, train loss: 7.051702, norm: 349.6781\n",
            "Train Progress: 0.042540%, train loss: 3.494651, norm: 236.1152\n",
            "Train Progress: 0.064355%, train loss: 2.779933, norm: 161.1556\n",
            "Train Progress: 0.086170%, train loss: 2.139847, norm: 158.5917\n",
            "Train Progress: 0.107985%, train loss: 2.125065, norm: 39.4309\n",
            "valid loss: 1.990202\n",
            "Train Progress: 0.129801%, train loss: 0.905093, norm: 28.3206\n",
            "Train Progress: 0.151616%, train loss: 1.909704, norm: 25.0398\n",
            "Train Progress: 0.173431%, train loss: 1.413715, norm: 29.3756\n",
            "Train Progress: 0.195246%, train loss: 1.701517, norm: 24.0761\n",
            "Train Progress: 0.217062%, train loss: 1.427284, norm: 26.6865\n",
            "valid loss: 1.331987\n",
            "Train Progress: 0.238877%, train loss: 1.347812, norm: 20.0725\n",
            "Train Progress: 0.260692%, train loss: 0.970921, norm: 14.3599\n",
            "Train Progress: 0.282507%, train loss: 1.165850, norm: 13.1454\n",
            "Train Progress: 0.304323%, train loss: 1.005583, norm: 12.8414\n",
            "Train Progress: 0.326138%, train loss: 0.811773, norm: 9.4141\n",
            "valid loss: 1.122653\n",
            "Train Progress: 0.347953%, train loss: 0.788493, norm: 8.5098\n",
            "Train Progress: 0.369768%, train loss: 1.633428, norm: 9.1345\n",
            "Train Progress: 0.391584%, train loss: 0.881627, norm: 8.8902\n",
            "Train Progress: 0.413399%, train loss: 0.975376, norm: 8.7749\n",
            "Train Progress: 0.435214%, train loss: 0.819580, norm: 10.2654\n",
            "valid loss: 1.055227\n",
            "Train Progress: 0.457029%, train loss: 1.064616, norm: 6.7901\n",
            "Train Progress: 0.478845%, train loss: 1.395513, norm: 8.0371\n",
            "Train Progress: 0.500660%, train loss: 0.874353, norm: 8.6450\n",
            "Train Progress: 0.522475%, train loss: 0.836577, norm: 7.1146\n",
            "Train Progress: 0.544290%, train loss: 0.714963, norm: 7.9225\n",
            "valid loss: 1.029129\n",
            "Train Progress: 0.566106%, train loss: 0.681577, norm: 7.8524\n",
            "Train Progress: 0.587921%, train loss: 0.817701, norm: 7.6363\n",
            "Train Progress: 0.609736%, train loss: 1.003111, norm: 8.9941\n",
            "Train Progress: 0.631551%, train loss: 1.011556, norm: 7.9719\n",
            "Train Progress: 0.653367%, train loss: 0.557644, norm: 5.2084\n",
            "valid loss: 1.018668\n",
            "Train Progress: 0.675182%, train loss: 1.119746, norm: 9.7009\n",
            "Train Progress: 0.696997%, train loss: 0.923261, norm: 9.7642\n",
            "Train Progress: 0.718812%, train loss: 1.160451, norm: 5.1560\n",
            "Train Progress: 0.740628%, train loss: 0.748309, norm: 8.0543\n",
            "Train Progress: 0.762443%, train loss: 0.685971, norm: 8.7473\n",
            "valid loss: 1.013761\n",
            "Train Progress: 0.784258%, train loss: 0.933983, norm: 9.1021\n",
            "Train Progress: 0.806073%, train loss: 0.533059, norm: 7.1417\n",
            "Train Progress: 0.827889%, train loss: 1.065921, norm: 5.6386\n",
            "Train Progress: 0.849704%, train loss: 0.706621, norm: 6.6757\n",
            "Train Progress: 0.871519%, train loss: 0.813780, norm: 6.8778\n",
            "valid loss: 1.007678\n",
            "Train Progress: 0.893334%, train loss: 0.678901, norm: 6.0500\n",
            "Train Progress: 0.915150%, train loss: 0.643997, norm: 5.9896\n",
            "Train Progress: 0.936965%, train loss: 0.801661, norm: 6.4448\n",
            "Train Progress: 0.958780%, train loss: 0.587522, norm: 5.4194\n",
            "Train Progress: 0.980595%, train loss: 0.984632, norm: 7.1680\n",
            "valid loss: 1.007480\n",
            "Train Progress: 1.002411%, train loss: 1.040663, norm: 7.2057\n",
            "Train Progress: 1.024226%, train loss: 1.258222, norm: 4.9881\n",
            "Train Progress: 1.046041%, train loss: 0.811878, norm: 6.7087\n",
            "Train Progress: 1.067856%, train loss: 0.842049, norm: 6.0513\n",
            "Train Progress: 1.089672%, train loss: 0.979715, norm: 6.3750\n",
            "valid loss: 1.009112\n",
            "Train Progress: 1.111487%, train loss: 0.917333, norm: 7.6868\n",
            "Train Progress: 1.133302%, train loss: 0.807908, norm: 7.7020\n",
            "Train Progress: 1.155117%, train loss: 0.940883, norm: 6.3667\n",
            "Train Progress: 1.176933%, train loss: 1.055428, norm: 5.6065\n",
            "Train Progress: 1.198748%, train loss: 0.952884, norm: 6.7661\n",
            "valid loss: 1.004089\n",
            "Train Progress: 1.220563%, train loss: 0.829245, norm: 5.2205\n",
            "Train Progress: 1.242378%, train loss: 1.393788, norm: 6.0953\n",
            "Train Progress: 1.264194%, train loss: 0.983748, norm: 7.3072\n",
            "Train Progress: 1.286009%, train loss: 0.897932, norm: 6.3303\n",
            "Train Progress: 1.307824%, train loss: 0.986671, norm: 5.0179\n",
            "valid loss: 1.003477\n",
            "Train Progress: 1.329639%, train loss: 1.343965, norm: 6.2719\n",
            "Train Progress: 1.351455%, train loss: 1.375970, norm: 5.9874\n",
            "Train Progress: 1.373270%, train loss: 1.090013, norm: 5.6377\n",
            "Train Progress: 1.395085%, train loss: 1.119343, norm: 5.5404\n",
            "Train Progress: 1.416900%, train loss: 0.605576, norm: 5.1760\n",
            "valid loss: 1.001811\n",
            "Train Progress: 1.438716%, train loss: 1.221229, norm: 5.3495\n",
            "Train Progress: 1.460531%, train loss: 0.820287, norm: 5.8662\n",
            "Train Progress: 1.482346%, train loss: 0.949679, norm: 5.9633\n",
            "Train Progress: 1.504161%, train loss: 0.795558, norm: 5.7928\n",
            "Train Progress: 1.525977%, train loss: 0.999423, norm: 4.5115\n",
            "valid loss: 0.997753\n",
            "Train Progress: 1.547792%, train loss: 0.812289, norm: 4.3484\n",
            "Train Progress: 1.569607%, train loss: 0.977273, norm: 5.1928\n",
            "Train Progress: 1.591422%, train loss: 1.260658, norm: 5.3994\n",
            "Train Progress: 1.613237%, train loss: 1.141038, norm: 5.1210\n",
            "Train Progress: 1.635053%, train loss: 0.865681, norm: 6.3701\n",
            "valid loss: 1.001599\n",
            "Train Progress: 1.656868%, train loss: 0.772668, norm: 5.5016\n",
            "Train Progress: 1.678683%, train loss: 0.955569, norm: 4.6355\n",
            "Train Progress: 1.700498%, train loss: 0.811553, norm: 5.3167\n",
            "Train Progress: 1.722314%, train loss: 1.066500, norm: 5.3517\n",
            "Train Progress: 1.744129%, train loss: 0.543868, norm: 6.5930\n",
            "valid loss: 0.997260\n",
            "Train Progress: 1.765944%, train loss: 0.791428, norm: 6.1264\n",
            "Train Progress: 1.787759%, train loss: 1.009965, norm: 3.8690\n",
            "Train Progress: 1.809575%, train loss: 1.287431, norm: 5.9667\n",
            "Train Progress: 1.831390%, train loss: 0.998593, norm: 6.7290\n",
            "Train Progress: 1.853205%, train loss: 0.973663, norm: 6.8983\n",
            "valid loss: 1.000056\n",
            "Train Progress: 1.875020%, train loss: 1.363339, norm: 5.8920\n",
            "Train Progress: 1.896836%, train loss: 0.710902, norm: 6.4696\n",
            "Train Progress: 1.918651%, train loss: 1.290013, norm: 5.8123\n",
            "Train Progress: 1.940466%, train loss: 1.372835, norm: 5.4007\n",
            "Train Progress: 1.962281%, train loss: 0.759341, norm: 4.8482\n",
            "valid loss: 0.995992\n",
            "Train Progress: 1.984097%, train loss: 0.772699, norm: 5.3085\n",
            "Train Progress: 2.005912%, train loss: 1.119839, norm: 6.2226\n",
            "Train Progress: 2.027727%, train loss: 1.062207, norm: 5.6506\n",
            "Train Progress: 2.049542%, train loss: 1.126951, norm: 6.1360\n",
            "Train Progress: 2.071358%, train loss: 1.453916, norm: 5.9882\n",
            "valid loss: 0.994942\n",
            "Train Progress: 2.093173%, train loss: 0.786476, norm: 5.4429\n",
            "Train Progress: 2.114988%, train loss: 0.989175, norm: 5.9805\n",
            "Train Progress: 2.136803%, train loss: 1.092099, norm: 6.7474\n",
            "Train Progress: 2.158619%, train loss: 0.965919, norm: 4.5512\n",
            "Train Progress: 2.180434%, train loss: 0.856425, norm: 3.9452\n",
            "valid loss: 0.999066\n",
            "Train Progress: 2.202249%, train loss: 0.917823, norm: 7.7485\n",
            "Train Progress: 2.224064%, train loss: 1.309256, norm: 7.7560\n",
            "Train Progress: 2.245880%, train loss: 0.737846, norm: 6.2076\n",
            "Train Progress: 2.267695%, train loss: 1.043173, norm: 3.8584\n",
            "Train Progress: 2.289510%, train loss: 0.872881, norm: 5.1565\n",
            "valid loss: 0.995425\n",
            "Train Progress: 2.311325%, train loss: 1.075266, norm: 6.2588\n",
            "Train Progress: 2.333141%, train loss: 0.714881, norm: 7.2963\n",
            "Train Progress: 2.354956%, train loss: 0.702827, norm: 6.3075\n",
            "Train Progress: 2.376771%, train loss: 1.024378, norm: 4.6171\n",
            "Train Progress: 2.398586%, train loss: 0.630432, norm: 4.8698\n",
            "valid loss: 0.993381\n",
            "Train Progress: 2.420402%, train loss: 0.760971, norm: 5.4078\n",
            "Train Progress: 2.442217%, train loss: 0.875676, norm: 5.9443\n",
            "Train Progress: 2.464032%, train loss: 1.122550, norm: 7.1203\n",
            "Train Progress: 2.485847%, train loss: 0.809329, norm: 6.1879\n",
            "Train Progress: 2.507663%, train loss: 0.589262, norm: 4.6422\n",
            "valid loss: 0.990656\n",
            "Train Progress: 2.529478%, train loss: 1.039508, norm: 4.9154\n",
            "Train Progress: 2.551293%, train loss: 0.968501, norm: 6.2610\n",
            "Train Progress: 2.573108%, train loss: 1.069411, norm: 5.9629\n",
            "Train Progress: 2.594924%, train loss: 0.898261, norm: 5.8832\n",
            "Train Progress: 2.616739%, train loss: 1.089555, norm: 5.3866\n",
            "valid loss: 0.991813\n",
            "Train Progress: 2.638554%, train loss: 0.762435, norm: 5.6136\n",
            "Train Progress: 2.660369%, train loss: 0.693399, norm: 5.6048\n",
            "Train Progress: 2.682185%, train loss: 0.749159, norm: 6.3965\n",
            "Train Progress: 2.704000%, train loss: 0.853914, norm: 6.7193\n",
            "Train Progress: 2.725815%, train loss: 0.688230, norm: 5.5861\n",
            "valid loss: 0.991491\n",
            "Train Progress: 2.747630%, train loss: 0.639729, norm: 4.9623\n",
            "Train Progress: 2.769446%, train loss: 0.878039, norm: 6.1377\n",
            "Train Progress: 2.791261%, train loss: 1.027418, norm: 5.4897\n",
            "Train Progress: 2.813076%, train loss: 0.804244, norm: 5.1975\n",
            "Train Progress: 2.834891%, train loss: 0.766298, norm: 6.0464\n",
            "valid loss: 0.988859\n",
            "Train Progress: 2.856707%, train loss: 1.196970, norm: 4.7677\n",
            "Train Progress: 2.878522%, train loss: 0.955872, norm: 4.3855\n",
            "Train Progress: 2.900337%, train loss: 1.010364, norm: 5.7155\n",
            "Train Progress: 2.922152%, train loss: 0.790051, norm: 6.2933\n",
            "Train Progress: 2.943968%, train loss: 0.885310, norm: 5.8782\n",
            "valid loss: 0.991097\n",
            "Train Progress: 2.965783%, train loss: 0.676752, norm: 5.6611\n",
            "Train Progress: 2.987598%, train loss: 1.375462, norm: 5.0966\n",
            "Train Progress: 3.009413%, train loss: 0.617754, norm: 4.5686\n",
            "Train Progress: 3.031229%, train loss: 0.681657, norm: 4.8433\n",
            "Train Progress: 3.053044%, train loss: 0.944441, norm: 4.7391\n",
            "valid loss: 0.990761\n",
            "Train Progress: 3.074859%, train loss: 1.315762, norm: 5.1956\n",
            "Train Progress: 3.096674%, train loss: 0.969828, norm: 5.6183\n",
            "Train Progress: 3.118490%, train loss: 0.987032, norm: 5.2780\n",
            "Train Progress: 3.140305%, train loss: 0.774326, norm: 3.6571\n",
            "Train Progress: 3.162120%, train loss: 1.089284, norm: 4.0127\n",
            "valid loss: 0.987690\n",
            "Train Progress: 3.183935%, train loss: 1.290815, norm: 5.2794\n",
            "Train Progress: 3.205750%, train loss: 0.846759, norm: 4.9831\n",
            "Train Progress: 3.227566%, train loss: 0.732603, norm: 5.7349\n",
            "Train Progress: 3.249381%, train loss: 1.368001, norm: 6.6743\n",
            "Train Progress: 3.271196%, train loss: 0.743240, norm: 6.4166\n",
            "valid loss: 0.986512\n",
            "Train Progress: 3.293011%, train loss: 0.788729, norm: 4.8830\n",
            "Train Progress: 3.314827%, train loss: 0.739671, norm: 3.4199\n",
            "Train Progress: 3.336642%, train loss: 1.016540, norm: 3.3107\n",
            "Train Progress: 3.358457%, train loss: 0.769730, norm: 4.7427\n",
            "Train Progress: 3.380272%, train loss: 1.246179, norm: 6.5163\n",
            "valid loss: 0.994094\n",
            "Train Progress: 3.402088%, train loss: 1.006769, norm: 6.9989\n",
            "Train Progress: 3.423903%, train loss: 0.815229, norm: 6.0409\n",
            "Train Progress: 3.445718%, train loss: 0.503483, norm: 5.5243\n",
            "Train Progress: 3.467533%, train loss: 0.995610, norm: 4.3704\n",
            "Train Progress: 3.489349%, train loss: 0.878027, norm: 4.1340\n",
            "valid loss: 0.985725\n",
            "Train Progress: 3.511164%, train loss: 1.085090, norm: 4.7626\n",
            "Train Progress: 3.532979%, train loss: 0.952321, norm: 5.2278\n",
            "Train Progress: 3.554794%, train loss: 0.718532, norm: 6.0458\n",
            "Train Progress: 3.576610%, train loss: 0.850676, norm: 6.7595\n",
            "Train Progress: 3.598425%, train loss: 0.987995, norm: 6.5629\n",
            "valid loss: 0.990391\n",
            "Train Progress: 3.620240%, train loss: 0.577566, norm: 6.0902\n",
            "Train Progress: 3.642055%, train loss: 1.214079, norm: 4.6521\n",
            "Train Progress: 3.663871%, train loss: 0.558797, norm: 3.9825\n",
            "Train Progress: 3.685686%, train loss: 0.816091, norm: 4.8083\n",
            "Train Progress: 3.707501%, train loss: 0.927087, norm: 5.9369\n",
            "valid loss: 0.987955\n",
            "Train Progress: 3.729316%, train loss: 1.504444, norm: 5.3897\n",
            "Train Progress: 3.751132%, train loss: 1.116615, norm: 4.5669\n",
            "Train Progress: 3.772947%, train loss: 0.350239, norm: 4.5496\n",
            "Train Progress: 3.794762%, train loss: 0.665903, norm: 6.3623\n",
            "Train Progress: 3.816577%, train loss: 0.737508, norm: 5.4919\n",
            "valid loss: 0.987356\n",
            "Train Progress: 3.838393%, train loss: 0.932128, norm: 4.3877\n",
            "Train Progress: 3.860208%, train loss: 0.665468, norm: 4.3599\n",
            "Train Progress: 3.882023%, train loss: 0.665800, norm: 5.1189\n",
            "Train Progress: 3.903838%, train loss: 1.040708, norm: 5.1941\n",
            "Train Progress: 3.925654%, train loss: 0.930632, norm: 4.5483\n",
            "valid loss: 0.989539\n",
            "Train Progress: 3.947469%, train loss: 1.151472, norm: 5.2942\n",
            "Train Progress: 3.969284%, train loss: 1.233048, norm: 6.9767\n",
            "Train Progress: 3.991099%, train loss: 1.002581, norm: 7.2181\n",
            "Train Progress: 4.012915%, train loss: 0.952791, norm: 6.0433\n",
            "Train Progress: 4.034730%, train loss: 1.008669, norm: 4.1621\n",
            "valid loss: 0.982925\n",
            "Train Progress: 4.056545%, train loss: 0.998625, norm: 2.6955\n",
            "Train Progress: 4.078360%, train loss: 1.044334, norm: 4.5527\n",
            "Train Progress: 4.100176%, train loss: 0.886131, norm: 5.7914\n",
            "Train Progress: 4.121991%, train loss: 1.061825, norm: 5.3701\n",
            "Train Progress: 4.143806%, train loss: 0.831266, norm: 4.6383\n",
            "valid loss: 0.989907\n",
            "Train Progress: 4.165621%, train loss: 0.987913, norm: 4.8193\n",
            "Train Progress: 4.187437%, train loss: 0.867382, norm: 5.7720\n",
            "Train Progress: 4.209252%, train loss: 0.696316, norm: 6.6152\n",
            "Train Progress: 4.231067%, train loss: 0.940199, norm: 5.6170\n",
            "Train Progress: 4.252882%, train loss: 0.931884, norm: 3.3913\n",
            "valid loss: 0.982995\n",
            "Train Progress: 4.274698%, train loss: 0.560702, norm: 3.0450\n",
            "Train Progress: 4.296513%, train loss: 1.124887, norm: 6.1143\n",
            "Train Progress: 4.318328%, train loss: 0.937854, norm: 7.4349\n",
            "Train Progress: 4.340143%, train loss: 0.774433, norm: 6.9232\n",
            "Train Progress: 4.361959%, train loss: 0.800225, norm: 5.6971\n",
            "valid loss: 0.986167\n",
            "Train Progress: 4.383774%, train loss: 1.304771, norm: 4.4223\n",
            "Train Progress: 4.405589%, train loss: 0.950893, norm: 5.2358\n",
            "Train Progress: 4.427404%, train loss: 1.009272, norm: 5.6814\n",
            "Train Progress: 4.449220%, train loss: 0.946465, norm: 5.7054\n",
            "Train Progress: 4.471035%, train loss: 0.611057, norm: 4.9950\n",
            "valid loss: 0.984741\n",
            "Train Progress: 4.492850%, train loss: 0.695709, norm: 4.0676\n",
            "Train Progress: 4.514665%, train loss: 0.918238, norm: 5.0355\n",
            "Train Progress: 4.536481%, train loss: 0.614081, norm: 5.7664\n",
            "Train Progress: 4.558296%, train loss: 0.945487, norm: 6.1371\n",
            "Train Progress: 4.580111%, train loss: 1.071440, norm: 5.1576\n",
            "valid loss: 0.984450\n",
            "Train Progress: 4.601926%, train loss: 1.050823, norm: 4.1723\n",
            "Train Progress: 4.623742%, train loss: 0.797199, norm: 3.3075\n",
            "Train Progress: 4.645557%, train loss: 0.824539, norm: 4.5202\n",
            "Train Progress: 4.667372%, train loss: 1.219353, norm: 5.7295\n",
            "Train Progress: 4.689187%, train loss: 0.853170, norm: 6.2067\n",
            "valid loss: 0.987008\n",
            "Train Progress: 4.711003%, train loss: 0.938331, norm: 5.2130\n",
            "Train Progress: 4.732818%, train loss: 0.726212, norm: 4.1641\n",
            "Train Progress: 4.754633%, train loss: 0.559814, norm: 3.7770\n",
            "Train Progress: 4.776448%, train loss: 1.235503, norm: 5.7812\n",
            "Train Progress: 4.798264%, train loss: 0.736398, norm: 6.9588\n",
            "valid loss: 0.987592\n",
            "Train Progress: 4.820079%, train loss: 0.962764, norm: 6.1505\n",
            "Train Progress: 4.841894%, train loss: 0.889805, norm: 5.1721\n",
            "Train Progress: 4.863709%, train loss: 0.994918, norm: 3.9846\n",
            "Train Progress: 4.885524%, train loss: 0.941285, norm: 2.7707\n",
            "Train Progress: 4.907340%, train loss: 0.966613, norm: 4.1951\n",
            "valid loss: 0.986871\n",
            "Train Progress: 4.929155%, train loss: 0.671432, norm: 5.2654\n",
            "Train Progress: 4.950970%, train loss: 0.734217, norm: 5.2924\n",
            "Train Progress: 4.972785%, train loss: 1.026253, norm: 4.6965\n",
            "Train Progress: 4.994601%, train loss: 0.502109, norm: 4.6578\n",
            "Train Progress: 5.016416%, train loss: 0.746697, norm: 4.2959\n",
            "valid loss: 0.984726\n",
            "Train Progress: 5.038231%, train loss: 1.062346, norm: 3.9688\n",
            "Train Progress: 5.060046%, train loss: 0.852857, norm: 3.7774\n",
            "Train Progress: 5.081862%, train loss: 1.181595, norm: 4.3237\n",
            "Train Progress: 5.103677%, train loss: 0.824812, norm: 4.4120\n",
            "Train Progress: 5.125492%, train loss: 0.862636, norm: 4.4434\n",
            "valid loss: 0.984359\n",
            "Train Progress: 5.147307%, train loss: 1.010475, norm: 4.4248\n",
            "Train Progress: 5.169123%, train loss: 0.972031, norm: 4.3902\n",
            "Train Progress: 5.190938%, train loss: 1.013522, norm: 4.3860\n",
            "Train Progress: 5.212753%, train loss: 1.121752, norm: 4.9697\n",
            "Train Progress: 5.234568%, train loss: 1.283346, norm: 3.9990\n",
            "valid loss: 0.984358\n",
            "Train Progress: 5.256384%, train loss: 1.074347, norm: 3.7511\n",
            "Train Progress: 5.278199%, train loss: 0.952142, norm: 3.8627\n",
            "Train Progress: 5.300014%, train loss: 0.779112, norm: 4.1468\n",
            "Train Progress: 5.321829%, train loss: 0.919648, norm: 4.9941\n",
            "Train Progress: 5.343645%, train loss: 1.074382, norm: 4.6317\n",
            "valid loss: 0.984830\n",
            "Train Progress: 5.365460%, train loss: 1.062974, norm: 4.3911\n",
            "Train Progress: 5.387275%, train loss: 0.966984, norm: 3.7880\n",
            "Train Progress: 5.409090%, train loss: 1.156978, norm: 3.2195\n",
            "Train Progress: 5.430906%, train loss: 0.563348, norm: 2.7695\n",
            "Train Progress: 5.452721%, train loss: 1.182128, norm: 4.3276\n",
            "valid loss: 0.987174\n",
            "Train Progress: 5.474536%, train loss: 0.598417, norm: 6.0153\n",
            "Train Progress: 5.496351%, train loss: 1.149827, norm: 7.0351\n",
            "Train Progress: 5.518167%, train loss: 0.958391, norm: 5.5016\n",
            "Train Progress: 5.539982%, train loss: 0.714959, norm: 4.0391\n",
            "Train Progress: 5.561797%, train loss: 1.020836, norm: 3.2941\n",
            "valid loss: 0.982371\n",
            "Train Progress: 5.583612%, train loss: 0.948423, norm: 3.5773\n",
            "Train Progress: 5.605428%, train loss: 0.949544, norm: 4.1834\n",
            "Train Progress: 5.627243%, train loss: 0.808026, norm: 4.7028\n",
            "Train Progress: 5.649058%, train loss: 1.369695, norm: 3.9251\n",
            "Train Progress: 5.670873%, train loss: 1.136287, norm: 4.1618\n",
            "valid loss: 0.984071\n",
            "Train Progress: 5.692689%, train loss: 1.237050, norm: 3.9142\n",
            "Train Progress: 5.714504%, train loss: 0.616295, norm: 3.7393\n",
            "Train Progress: 5.736319%, train loss: 0.801396, norm: 3.8081\n",
            "Train Progress: 5.758134%, train loss: 0.986795, norm: 4.1376\n",
            "Train Progress: 5.779950%, train loss: 0.952082, norm: 4.8015\n",
            "valid loss: 0.984604\n",
            "Train Progress: 5.801765%, train loss: 1.110861, norm: 4.5049\n",
            "Train Progress: 5.823580%, train loss: 0.733200, norm: 4.0845\n",
            "Train Progress: 5.845395%, train loss: 1.196598, norm: 3.5446\n",
            "Train Progress: 5.867211%, train loss: 1.021150, norm: 3.7030\n",
            "Train Progress: 5.889026%, train loss: 1.026570, norm: 4.0808\n",
            "valid loss: 0.984644\n",
            "Train Progress: 5.910841%, train loss: 0.737845, norm: 4.6233\n",
            "Train Progress: 5.932656%, train loss: 0.633073, norm: 4.9380\n",
            "Train Progress: 5.954472%, train loss: 0.911865, norm: 5.2705\n",
            "Train Progress: 5.976287%, train loss: 0.528606, norm: 4.6923\n",
            "Train Progress: 5.998102%, train loss: 1.102389, norm: 3.4945\n",
            "valid loss: 0.983689\n",
            "Train Progress: 6.019917%, train loss: 0.752903, norm: 3.7223\n",
            "Train Progress: 6.041733%, train loss: 0.820356, norm: 4.7623\n",
            "Train Progress: 6.063548%, train loss: 1.087471, norm: 4.8409\n",
            "Train Progress: 6.085363%, train loss: 0.918299, norm: 4.2616\n",
            "Train Progress: 6.107178%, train loss: 0.675624, norm: 3.3948\n",
            "valid loss: 0.979498\n",
            "Train Progress: 6.128994%, train loss: 1.055112, norm: 3.3150\n",
            "Train Progress: 6.150809%, train loss: 1.135474, norm: 3.9411\n",
            "Train Progress: 6.172624%, train loss: 0.544904, norm: 4.0454\n",
            "Train Progress: 6.194439%, train loss: 1.141308, norm: 4.9644\n",
            "Train Progress: 6.216255%, train loss: 0.665495, norm: 4.6042\n",
            "valid loss: 0.983766\n",
            "Train Progress: 6.238070%, train loss: 0.917858, norm: 4.5030\n",
            "Train Progress: 6.259885%, train loss: 1.238601, norm: 3.9987\n",
            "Train Progress: 6.281700%, train loss: 1.097806, norm: 3.6122\n",
            "Train Progress: 6.303516%, train loss: 0.812280, norm: 3.5070\n",
            "Train Progress: 6.325331%, train loss: 0.821565, norm: 3.4371\n",
            "valid loss: 0.980565\n",
            "Train Progress: 6.347146%, train loss: 1.172730, norm: 3.5641\n",
            "Train Progress: 6.368961%, train loss: 0.543972, norm: 4.0369\n",
            "Train Progress: 6.390777%, train loss: 0.777328, norm: 4.6106\n",
            "Train Progress: 6.412592%, train loss: 0.978515, norm: 4.5636\n",
            "Train Progress: 6.434407%, train loss: 1.162500, norm: 3.6873\n",
            "valid loss: 0.982812\n",
            "Train Progress: 6.456222%, train loss: 0.894468, norm: 3.6522\n",
            "Train Progress: 6.478038%, train loss: 0.969126, norm: 4.2917\n",
            "Train Progress: 6.499853%, train loss: 1.155284, norm: 4.2409\n",
            "Train Progress: 6.521668%, train loss: 0.725370, norm: 4.3250\n",
            "Train Progress: 6.543483%, train loss: 1.044757, norm: 3.9455\n",
            "valid loss: 0.981551\n",
            "Train Progress: 6.565298%, train loss: 0.891589, norm: 4.1693\n",
            "Train Progress: 6.587114%, train loss: 0.823421, norm: 4.2798\n",
            "Train Progress: 6.608929%, train loss: 0.763667, norm: 4.0282\n",
            "Train Progress: 6.630744%, train loss: 1.562790, norm: 4.8275\n",
            "Train Progress: 6.652559%, train loss: 0.868836, norm: 4.1476\n",
            "valid loss: 0.980647\n",
            "Train Progress: 6.674375%, train loss: 0.918233, norm: 3.5884\n",
            "Train Progress: 6.696190%, train loss: 1.018754, norm: 4.1773\n",
            "Train Progress: 6.718005%, train loss: 1.308888, norm: 4.3843\n",
            "Train Progress: 6.739820%, train loss: 1.063641, norm: 4.6169\n",
            "Train Progress: 6.761636%, train loss: 1.296439, norm: 3.8662\n",
            "valid loss: 0.981148\n",
            "Train Progress: 6.783451%, train loss: 0.845527, norm: 3.4069\n",
            "Train Progress: 6.805266%, train loss: 1.220947, norm: 3.4643\n",
            "Train Progress: 6.827081%, train loss: 1.095472, norm: 3.8304\n",
            "Train Progress: 6.848897%, train loss: 0.860792, norm: 3.7824\n",
            "Train Progress: 6.870712%, train loss: 0.818739, norm: 4.5097\n",
            "valid loss: 0.983390\n",
            "Train Progress: 6.892527%, train loss: 0.583975, norm: 4.4444\n",
            "Train Progress: 6.914342%, train loss: 0.947932, norm: 4.4880\n",
            "Train Progress: 6.936158%, train loss: 0.775809, norm: 3.9721\n",
            "Train Progress: 6.957973%, train loss: 1.083141, norm: 4.3760\n",
            "Train Progress: 6.979788%, train loss: 1.260680, norm: 4.0829\n",
            "valid loss: 0.980514\n",
            "Train Progress: 7.001603%, train loss: 0.924036, norm: 4.3825\n",
            "Train Progress: 7.023419%, train loss: 0.812607, norm: 4.5316\n",
            "Train Progress: 7.045234%, train loss: 0.992404, norm: 3.8174\n",
            "Train Progress: 7.067049%, train loss: 0.460401, norm: 3.3616\n",
            "Train Progress: 7.088864%, train loss: 1.022889, norm: 4.2093\n",
            "valid loss: 0.983248\n",
            "Train Progress: 7.110680%, train loss: 0.757900, norm: 4.9702\n",
            "Train Progress: 7.132495%, train loss: 0.689020, norm: 4.9230\n",
            "Train Progress: 7.154310%, train loss: 0.728928, norm: 4.2373\n",
            "Train Progress: 7.176125%, train loss: 1.097654, norm: 3.3049\n",
            "Train Progress: 7.197941%, train loss: 1.137424, norm: 2.7926\n",
            "valid loss: 0.979809\n",
            "Train Progress: 7.219756%, train loss: 0.677536, norm: 3.5679\n",
            "Train Progress: 7.241571%, train loss: 0.803108, norm: 5.1287\n",
            "Train Progress: 7.263386%, train loss: 1.191750, norm: 5.9786\n",
            "Train Progress: 7.285202%, train loss: 0.907387, norm: 5.1393\n",
            "Train Progress: 7.307017%, train loss: 0.948612, norm: 3.8988\n",
            "valid loss: 0.978543\n",
            "Train Progress: 7.328832%, train loss: 0.980590, norm: 3.4309\n",
            "Train Progress: 7.350647%, train loss: 0.867118, norm: 3.7162\n",
            "Train Progress: 7.372463%, train loss: 0.958666, norm: 4.6707\n",
            "Train Progress: 7.394278%, train loss: 0.782646, norm: 5.0545\n",
            "Train Progress: 7.416093%, train loss: 0.840025, norm: 4.5771\n",
            "valid loss: 0.979504\n",
            "Train Progress: 7.437908%, train loss: 0.917890, norm: 4.4038\n",
            "Train Progress: 7.459724%, train loss: 1.074427, norm: 3.4494\n",
            "Train Progress: 7.481539%, train loss: 0.709638, norm: 3.2526\n",
            "Train Progress: 7.503354%, train loss: 0.906163, norm: 3.4546\n",
            "Train Progress: 7.525169%, train loss: 0.948868, norm: 4.1327\n",
            "valid loss: 0.983148\n",
            "Train Progress: 7.546985%, train loss: 0.572140, norm: 4.6179\n",
            "Train Progress: 7.568800%, train loss: 0.773414, norm: 5.1804\n",
            "Train Progress: 7.590615%, train loss: 0.721450, norm: 4.1634\n",
            "Train Progress: 7.612430%, train loss: 0.760534, norm: 3.8179\n",
            "Train Progress: 7.634246%, train loss: 0.917334, norm: 3.5341\n",
            "valid loss: 0.976903\n",
            "Train Progress: 7.656061%, train loss: 1.191127, norm: 3.4579\n",
            "Train Progress: 7.677876%, train loss: 0.967932, norm: 3.7953\n",
            "Train Progress: 7.699691%, train loss: 1.103239, norm: 4.1773\n",
            "Train Progress: 7.721507%, train loss: 0.694351, norm: 3.9850\n",
            "Train Progress: 7.743322%, train loss: 1.097989, norm: 4.0973\n",
            "valid loss: 0.983021\n",
            "Train Progress: 7.765137%, train loss: 1.154623, norm: 4.0007\n",
            "Train Progress: 7.786952%, train loss: 0.764082, norm: 4.2094\n",
            "Train Progress: 7.808768%, train loss: 1.031699, norm: 4.2684\n",
            "Train Progress: 7.830583%, train loss: 1.047901, norm: 3.7439\n",
            "Train Progress: 7.852398%, train loss: 1.262917, norm: 2.8138\n",
            "valid loss: 0.978856\n",
            "Train Progress: 7.874213%, train loss: 0.867943, norm: 3.3879\n",
            "Train Progress: 7.896029%, train loss: 0.605706, norm: 4.3154\n",
            "Train Progress: 7.917844%, train loss: 0.790417, norm: 5.3228\n",
            "Train Progress: 7.939659%, train loss: 0.910144, norm: 4.7204\n",
            "Train Progress: 7.961474%, train loss: 0.814384, norm: 4.4615\n",
            "valid loss: 0.980710\n",
            "Train Progress: 7.983290%, train loss: 0.857578, norm: 4.2692\n",
            "Train Progress: 8.005105%, train loss: 0.644288, norm: 3.9194\n",
            "Train Progress: 8.026920%, train loss: 0.773093, norm: 3.7031\n",
            "Train Progress: 8.048735%, train loss: 0.716701, norm: 3.4760\n",
            "Train Progress: 8.070551%, train loss: 0.799272, norm: 3.5607\n",
            "valid loss: 0.980444\n",
            "Train Progress: 8.092366%, train loss: 0.912409, norm: 4.5731\n",
            "Train Progress: 8.114181%, train loss: 0.564875, norm: 4.9674\n",
            "Train Progress: 8.135996%, train loss: 0.510765, norm: 4.2814\n",
            "Train Progress: 8.157811%, train loss: 0.861498, norm: 3.5819\n",
            "Train Progress: 8.179627%, train loss: 0.869219, norm: 3.3586\n",
            "valid loss: 0.978815\n",
            "Train Progress: 8.201442%, train loss: 0.949718, norm: 4.0326\n",
            "Train Progress: 8.223257%, train loss: 1.072715, norm: 3.8334\n",
            "Train Progress: 8.245072%, train loss: 0.740027, norm: 3.8947\n",
            "Train Progress: 8.266888%, train loss: 1.214398, norm: 3.7434\n",
            "Train Progress: 8.288703%, train loss: 0.812233, norm: 3.4805\n",
            "valid loss: 0.978857\n",
            "Train Progress: 8.310518%, train loss: 1.233249, norm: 3.3284\n",
            "Train Progress: 8.332333%, train loss: 1.019129, norm: 3.7295\n",
            "Train Progress: 8.354149%, train loss: 0.775516, norm: 3.7538\n",
            "Train Progress: 8.375964%, train loss: 1.323101, norm: 3.2471\n",
            "Train Progress: 8.397779%, train loss: 1.077155, norm: 3.1511\n",
            "valid loss: 0.977614\n",
            "Train Progress: 8.419594%, train loss: 1.127735, norm: 3.7408\n",
            "Train Progress: 8.441410%, train loss: 0.974043, norm: 3.4859\n",
            "Train Progress: 8.463225%, train loss: 1.273304, norm: 3.0898\n",
            "Train Progress: 8.485040%, train loss: 0.759251, norm: 2.9651\n",
            "Train Progress: 8.506855%, train loss: 0.882179, norm: 3.8657\n",
            "valid loss: 0.978402\n",
            "Train Progress: 8.528671%, train loss: 1.199767, norm: 4.5973\n",
            "Train Progress: 8.550486%, train loss: 0.896668, norm: 4.0830\n",
            "Train Progress: 8.572301%, train loss: 0.805417, norm: 3.8678\n",
            "Train Progress: 8.594116%, train loss: 1.118024, norm: 2.9042\n",
            "Train Progress: 8.615932%, train loss: 0.890993, norm: 2.7275\n",
            "valid loss: 0.978083\n",
            "Train Progress: 8.637747%, train loss: 0.858180, norm: 3.4632\n",
            "Train Progress: 8.659562%, train loss: 0.844179, norm: 3.9076\n",
            "Train Progress: 8.681377%, train loss: 1.033331, norm: 4.3901\n",
            "Train Progress: 8.703193%, train loss: 0.900335, norm: 4.3750\n",
            "Train Progress: 8.725008%, train loss: 0.709345, norm: 3.6317\n",
            "valid loss: 0.978832\n",
            "Train Progress: 8.746823%, train loss: 1.022012, norm: 3.3488\n",
            "Train Progress: 8.768638%, train loss: 0.968066, norm: 4.0289\n",
            "Train Progress: 8.790454%, train loss: 0.871636, norm: 3.8944\n",
            "Train Progress: 8.812269%, train loss: 0.758889, norm: 3.3398\n",
            "Train Progress: 8.834084%, train loss: 0.738077, norm: 2.8228\n",
            "valid loss: 0.974716\n",
            "Train Progress: 8.855899%, train loss: 0.741191, norm: 2.9760\n",
            "Train Progress: 8.877715%, train loss: 0.739745, norm: 3.4189\n",
            "Train Progress: 8.899530%, train loss: 0.770818, norm: 4.1974\n",
            "Train Progress: 8.921345%, train loss: 1.272282, norm: 3.7868\n",
            "Train Progress: 8.943160%, train loss: 0.808394, norm: 3.9688\n",
            "valid loss: 0.979400\n",
            "Train Progress: 8.964976%, train loss: 0.980575, norm: 3.5485\n",
            "Train Progress: 8.986791%, train loss: 0.964625, norm: 3.5712\n",
            "Train Progress: 9.008606%, train loss: 0.910396, norm: 3.3362\n",
            "Train Progress: 9.030421%, train loss: 0.993831, norm: 3.2305\n",
            "Train Progress: 9.052237%, train loss: 0.973011, norm: 3.5164\n",
            "valid loss: 0.977057\n",
            "Train Progress: 9.074052%, train loss: 0.995133, norm: 3.4172\n",
            "Train Progress: 9.095867%, train loss: 0.755807, norm: 3.0332\n",
            "Train Progress: 9.117682%, train loss: 0.917617, norm: 3.4942\n",
            "Train Progress: 9.139498%, train loss: 1.163982, norm: 3.5574\n",
            "Train Progress: 9.161313%, train loss: 0.826568, norm: 3.5300\n",
            "valid loss: 0.978194\n",
            "Train Progress: 9.183128%, train loss: 0.659341, norm: 3.3999\n",
            "Train Progress: 9.204943%, train loss: 0.870679, norm: 3.0832\n",
            "Train Progress: 9.226759%, train loss: 1.021905, norm: 3.5277\n",
            "Train Progress: 9.248574%, train loss: 1.117595, norm: 3.8711\n",
            "Train Progress: 9.270389%, train loss: 1.231145, norm: 3.1751\n",
            "valid loss: 0.973085\n",
            "Train Progress: 9.292204%, train loss: 0.828840, norm: 2.7787\n",
            "Train Progress: 9.314020%, train loss: 0.898209, norm: 2.4849\n",
            "Train Progress: 9.335835%, train loss: 0.791509, norm: 3.3316\n",
            "Train Progress: 9.357650%, train loss: 0.991548, norm: 3.8904\n",
            "Train Progress: 9.379465%, train loss: 0.722046, norm: 4.4895\n",
            "valid loss: 0.979606\n",
            "Train Progress: 9.401281%, train loss: 0.922597, norm: 4.2575\n",
            "Train Progress: 9.423096%, train loss: 1.032190, norm: 3.7347\n",
            "Train Progress: 9.444911%, train loss: 0.664130, norm: 2.9969\n",
            "Train Progress: 9.466726%, train loss: 1.047332, norm: 2.4972\n",
            "Train Progress: 9.488542%, train loss: 0.883394, norm: 3.0859\n",
            "valid loss: 0.977968\n",
            "Train Progress: 9.510357%, train loss: 0.914084, norm: 3.5191\n",
            "Train Progress: 9.532172%, train loss: 0.554030, norm: 3.7932\n",
            "Train Progress: 9.553987%, train loss: 0.572790, norm: 3.8392\n",
            "Train Progress: 9.575803%, train loss: 0.750524, norm: 3.3589\n",
            "Train Progress: 9.597618%, train loss: 0.972954, norm: 3.1938\n",
            "valid loss: 0.977152\n",
            "Train Progress: 9.619433%, train loss: 1.046022, norm: 3.5782\n",
            "Train Progress: 9.641248%, train loss: 1.015028, norm: 3.8158\n",
            "Train Progress: 9.663064%, train loss: 1.347610, norm: 4.2454\n",
            "Train Progress: 9.684879%, train loss: 0.743383, norm: 3.9830\n",
            "Train Progress: 9.706694%, train loss: 1.204350, norm: 3.4205\n",
            "valid loss: 0.974783\n",
            "Train Progress: 9.728509%, train loss: 1.229607, norm: 2.9553\n",
            "Train Progress: 9.750325%, train loss: 1.128769, norm: 3.0435\n",
            "Train Progress: 9.772140%, train loss: 1.023399, norm: 3.7197\n",
            "Train Progress: 9.793955%, train loss: 0.950032, norm: 4.6007\n",
            "Train Progress: 9.815770%, train loss: 0.994410, norm: 4.0516\n",
            "valid loss: 0.976787\n",
            "Train Progress: 9.837585%, train loss: 1.055978, norm: 3.8330\n",
            "Train Progress: 9.859401%, train loss: 0.940251, norm: 3.2628\n",
            "Train Progress: 9.881216%, train loss: 1.188381, norm: 3.3464\n",
            "Train Progress: 9.903031%, train loss: 0.580513, norm: 3.2769\n",
            "Train Progress: 9.924846%, train loss: 0.969347, norm: 3.6148\n",
            "valid loss: 0.975372\n",
            "Train Progress: 9.946662%, train loss: 0.678857, norm: 3.2519\n",
            "Train Progress: 9.968477%, train loss: 1.021609, norm: 3.3656\n",
            "Train Progress: 9.990292%, train loss: 0.681669, norm: 3.3347\n",
            "Train Progress: 10.012107%, train loss: 0.934887, norm: 3.7601\n",
            "Train Progress: 10.033923%, train loss: 0.916569, norm: 3.4189\n",
            "valid loss: 0.976219\n",
            "Train Progress: 10.055738%, train loss: 0.930724, norm: 3.3524\n",
            "Train Progress: 10.077553%, train loss: 0.862115, norm: 3.3611\n",
            "Train Progress: 10.099368%, train loss: 0.896695, norm: 3.4604\n",
            "Train Progress: 10.121184%, train loss: 1.089475, norm: 3.4740\n",
            "Train Progress: 10.142999%, train loss: 1.103097, norm: 3.4843\n",
            "valid loss: 0.976721\n",
            "Train Progress: 10.164814%, train loss: 0.744493, norm: 3.6705\n",
            "Train Progress: 10.186629%, train loss: 1.138265, norm: 3.8117\n",
            "Train Progress: 10.208445%, train loss: 0.640283, norm: 3.5639\n",
            "Train Progress: 10.230260%, train loss: 0.871300, norm: 3.1536\n",
            "Train Progress: 10.252075%, train loss: 0.982544, norm: 3.0579\n",
            "valid loss: 0.973554\n",
            "Train Progress: 10.273890%, train loss: 1.115602, norm: 3.2932\n",
            "Train Progress: 10.295706%, train loss: 0.797411, norm: 3.3398\n",
            "Train Progress: 10.317521%, train loss: 1.031552, norm: 3.1038\n",
            "Train Progress: 10.339336%, train loss: 1.151382, norm: 3.3303\n",
            "Train Progress: 10.361151%, train loss: 1.233240, norm: 3.5117\n",
            "valid loss: 0.979107\n",
            "Train Progress: 10.382967%, train loss: 0.830704, norm: 4.1589\n",
            "Train Progress: 10.404782%, train loss: 0.946586, norm: 4.3898\n",
            "Train Progress: 10.426597%, train loss: 0.567674, norm: 4.0275\n",
            "Train Progress: 10.448412%, train loss: 0.652556, norm: 3.1232\n",
            "Train Progress: 10.470228%, train loss: 0.947250, norm: 2.5141\n",
            "valid loss: 0.973279\n",
            "Train Progress: 10.492043%, train loss: 1.431243, norm: 2.5856\n",
            "Train Progress: 10.513858%, train loss: 0.887028, norm: 3.6046\n",
            "Train Progress: 10.535673%, train loss: 1.406228, norm: 4.3450\n",
            "Train Progress: 10.557489%, train loss: 0.776420, norm: 4.5862\n",
            "Train Progress: 10.579304%, train loss: 1.025602, norm: 4.0809\n",
            "valid loss: 0.974704\n",
            "Train Progress: 10.601119%, train loss: 1.240558, norm: 3.5255\n",
            "Train Progress: 10.622934%, train loss: 0.478010, norm: 2.7008\n",
            "Train Progress: 10.644750%, train loss: 0.912215, norm: 3.1752\n",
            "Train Progress: 10.666565%, train loss: 0.717191, norm: 3.3268\n",
            "Train Progress: 10.688380%, train loss: 0.965201, norm: 3.9116\n",
            "valid loss: 0.977091\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0dd7395cc51e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mgrad_accum_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0msteps_processed_after_gradstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.esm.final_proj[0].lin.weight, model.esm.final_proj[0].lin.bias"
      ],
      "metadata": {
        "id": "6A1mp3dzU80S",
        "outputId": "4989431b-265e-4c64-f8a5-a74c1e42c055",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = model.esm.final_proj[0].ln(x)\n",
        "out = model.esm.final_proj[0].act(out)\n",
        "out = model.esm.final_proj[0].lin(out)"
      ],
      "metadata": {
        "id": "9trJhwujQnih"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrKsACGRQo6F",
        "outputId": "c5fe8005-c4a2-4367-c272-4177f3b009c5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1026, 2560])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.esm.final_proj[0].lin.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNA84ms5Q9WB",
        "outputId": "f2077038-8397-40e2-dc7f-b23317b13c76"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "HeP1LUm3Zqay"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(vl_losses_all)"
      ],
      "metadata": {
        "id": "On3_ZRDQJhU_",
        "outputId": "5406a628-5c5e-406e-f13a-b251cb863f6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7c5beebde1d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(vl_losses_all[-500:])"
      ],
      "metadata": {
        "id": "qZSl1Cb8JiYn",
        "outputId": "419a30a7-ae30-4fb9-e622-38a08359531c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.979497195482254"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Ai8SW-GTFgO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}